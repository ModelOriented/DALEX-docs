Hi

This is the Explanatory Model Analysis podcast about various techniques for explainable artificial intelligence. I describe methods for visualization, exploration and explanation of machine learning models.
This episode is about the Break-Down method.


In this episode, I will show you how to use the Break-Down method implemented in the lately published DALEX package for the Python language.
If you are interested in examples for R or other XAI methods you can find other episodes at http://tiny.cc/DALEX webpage.




Before we jump into the Python code, let me remind you what Break Down is for. 

Break Down is the ‘model agnostic’ method. It means that it works for any model without assuming anything of its internal structure. It can be used for neural networks, random forest, tree boosting or linear models.

It is also an 'instance-specific' method. It means that it explains the result of the model for a single observation. For the example related to the sinking of the Titanic, the break-down method explains model results at the level of predictions for individual passengers.

The purpose of this method is to break down the model result in components that can be attributed to individual variables. 
In this slide, we have an example for a single passenger, the 8-year-old boy from the first class. The model prediction for him is 0.81 and it is higher than the average result of the model, which is 0.32.
The break-down method analyzed the model and assigned to a young age, i.e. age equal 8, a positive effect of 0.36, to the first class a positive effect of 0.21 and the sex a negative effect of -0.03. Effects of other variables are listed below. The effects of all variables sum up to the prediction for this person, so the sum is equal to 0.81.

Such decomposition is very useful. We can read which variables have the largest contributions to the final prediction of the model, but we also have an assessment of how big these contributions are.

Let's see how to do such break-down in Python.


This episode is focused on the software. If you want to learn more about this method you will find its description on pbiecek.github.io/ema

In this example, I will use the titanic data. Probably you have heard about it before. It has only a few variables like age, gender, class and so on. Some continuous some categorical. Each one is easy to understand. 

We will drop rows with missing values to simplify the model and encode target variable to 0s and 1s, where 1 is `survived`. Find more about this dataset in the EMA ebook.

To explain a model first we need to have one. Due to categorical variables in the dataset, we need to include some preprocessing in our model. We split preprocessing into two parts, first one hot encode categorical variables, second scale numerical ones. Then we combine this in pipeline with actual model - gradient boosting machine. All used in construction algorithms are taken from the scikit-learn package. Note that the break-down method is model agnostic, so you can try any other model you wish.

The model is trained to predict the chances of survival based on eight variables. 

Different models have different structures. So if we want to be model agnostic we need to create a wrapper around the model that has a uniform interface for the model. 

Here we construct the Explainer object from dalex package.

The first argument is the model, then optionally we can specify the data, target variable and the label for the model. The label will appear on plots.
The break-down method works on the instance level. So we need an observation for which we can generate the explanation.

Here we create a pandas data frame with a single row that corresponds to an eight years old boy from 1st class. Note that this has to be a pandas data frame, not series or numpy array.

The model prediction for this boy is 0.81.


Once we have the model and the instance of interest, we are ready for the break-down method.

Here we use the `predict_parts` method of the Explainer object.
The name of the method means that we decompose a prediction into parts that can be attributed to a specific variables.
The predict_parts method calculates different types of variable attributions. We will use this function also in the next episodes.

In the basic settings, this method expects two arguments. The new observation and the type of attribution. By default, the type is equal to `ibreak-down` that will be covered in the future episodes. However, we will put type as `break_down`.
The result is a newly constructed object of the `BreakDown` class with field called `result` which is a data frame with attributions for each variable in the model.


In most cases, a plot is easier to read than a table with numbers. You can use the `plot` method of this new object to create an interactive waterfall plot that summarises variable attributions.


In the break-down method, the important element is the order of variables. By default a greedy heuristic is used to determine the best order from the most important to the least important variable. But you can specify a fixed order with the `order’ argument.

In this example we forced the order to be class, age, gender, fare, parch, sibsp, embarked, country.
Note that the break-down method is order specific. So for different orders, you may get different attributions. This issue is addressed in the method section in the documentation and also I will address it in the next episodes.



Other useful argument in the plot() method is the `max_vars`. You can specify how many of the most important variables shall be presented in the plot. It is useful for models with dozens or hundreds of variables.


The general workflow with the Break-Down method is summarised in this sequence diagram. 
Once you have a model you need to create a wrapper around the model with the explainer from the DALEX package. All other methods from this package are included in such objects.

To calculate break down attributions you can use the predict_parts method with the type = break down.
The result can be further processed with the plot method.

Find more examples and mode details in the Exploratory Model Analysis ebook.