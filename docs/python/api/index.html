<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.2" />
<title>dalex API documentation</title>
<meta name="description" content="[dalex: Responsible Machine Learning in Python](http://dalex.drwhy.ai/python) â€¦" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
<style>.homelink{display:block;font-size:2em;font-weight:bold;color:#555;padding-bottom:.5em;border-bottom:1px solid silver}.homelink:hover{color:inherit}.homelink img{max-width:50%;max-height:6em;margin:auto;margin-bottom:.3em}</style>
<link rel="canonical" href="https://dalex.drwhy.ai/python/api/dalex/">
<link rel="icon" type="image/png" href="https://dalex.drwhy.ai/favicon.svg"/>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Package <code>dalex</code></h1>
</header>
<section id="section-intro">
<p><a href="http://dalex.drwhy.ai/python">dalex: Responsible Machine Learning in Python</a></p>
<p><a href="https://github.com/ModelOriented/DALEX/actions?query=workflow%3APython-check"><img alt="Python-check" src="https://github.com/ModelOriented/DALEX/workflows/Python-check/badge.svg"></a>
<a href="https://pypi.org/project/dalex/"><img alt="Supported Python
versions" src="https://img.shields.io/pypi/pyversions/dalex.svg"></a>
<a href="https://badge.fury.io/py/dalex"><img alt="PyPI version" src="https://badge.fury.io/py/dalex.svg"></a>
<a href="https://pepy.tech/project/dalex"><img alt="Downloads" src="https://pepy.tech/badge/dalex"></a></p>
<h2 id="overview">Overview</h2>
<p>Unverified black box model is the path to the failure. Opaqueness leads to distrust. Distrust leads to ignoration. Ignoration leads to rejection.</p>
<p>The <code><a title="dalex" href="#dalex">dalex</a></code> package xrays any model and helps to explore and explain its behaviour, helps to understand how complex models are working.
The main <code><a title="dalex.Explainer" href="#dalex.Explainer">Explainer</a></code> object creates a wrapper around a predictive model. Wrapped models may then be explored and compared with a collection of model-level and predict-level explanations. Moreover, there are fairness methods and interactive exploration dashboards available to the user.</p>
<p>The philosophy behind <code><a title="dalex" href="#dalex">dalex</a></code> explanations is described in the <a href="https://pbiecek.github.io/ema/">Explanatory Model Analysis</a> e-book.</p>
<p><img alt="" src="https://raw.githubusercontent.com/ModelOriented/DALEX-docs/master/dalex/dalex-diagram.png"></p>
<h2 id="installation">Installation</h2>
<p>The <code><a title="dalex" href="#dalex">dalex</a></code> package is available <a href="https://pypi.org/project/dalex/">on PyPI</a></p>
<pre><code class="language-console">pip install dalex -U
</code></pre>
<h2 id="examples">Examples</h2>
<ul>
<li>Introduction to the <code><a title="dalex" href="#dalex">dalex</a></code> package: <a href="https://dalex.drwhy.ai/python-dalex-titanic.html">Titanic: tutorial and examples</a></li>
<li>Key features explained: <a href="https://dalex.drwhy.ai/python-dalex-fifa.html">FIFA20: explain default vs tuned model with dalex</a></li>
<li>How to use dalex with: <a href="https://dalex.drwhy.ai/python-dalex-xgboost.html">xgboost</a>, <a href="https://dalex.drwhy.ai/python-dalex-tensorflow.html">tensorflow</a>, <a href="https://dalex.drwhy.ai/python-dalex-h2o.html">h2o (feat. autokeras, catboost, lightgbm)</a></li>
<li>More explanations: <a href="https://dalex.drwhy.ai/python-dalex-new.html">residuals, shap, lime</a></li>
<li>Introduction to the <a href="https://dalex.drwhy.ai/python-dalex-fairness.html">Fairness module in dalex</a></li>
<li>Tutorial <a href="https://dalex.drwhy.ai/python-dalex-fairness2.html">on bias detection with dalex</a></li>
<li>Introduction to the <a href="https://dalex.drwhy.ai/python-dalex-arena.html">Arena module in dalex</a></li>
<li>Arena documentation: <a href="https://arena.drwhy.ai/docs/guide/basic-concepts/">Getting Started &amp; Demos</a></li>
<li>Code in the form of <a href="https://github.com/ModelOriented/DALEX-docs/tree/master/jupyter-notebooks">jupyter notebook</a></li>
</ul>
<h2 id="plots">Plots</h2>
<p>This package uses <a href="https://plotly.com/python/">plotly</a> to render the plots:</p>
<ul>
<li>Install extensions to use <code>plotly</code> in <strong>JupyterLab</strong>:&emsp;<a href="https://plot.ly/python/getting-started/#jupyterlab-support-python-35">Getting Started</a>&emsp;<a href="https://plot.ly/python/troubleshooting/#jupyterlab-problems">Troubleshooting</a></li>
<li>Use <code>show=False</code> parameter in <code>plot</code> method to return <code>plotly Figure</code> object</li>
<li>It is possible to <a href="https://plotly.com/python/#fundamentals">edit the figures</a> and <a href="https://plotly.com/python/static-image-export/">save them</a></li>
</ul>
<h2 id="citation">Citation</h2>
<p>If you use <code><a title="dalex" href="#dalex">dalex</a></code>, please cite <a href="https://arxiv.org/abs/2012.14406">our paper</a>:</p>
<pre><code class="language-html">@article{dalex,
  title={{dalex: Responsible Machine Learning with Interactive
          Explainability and Fairness in Python}},
  author={Hubert Baniecki and Wojciech Kretowicz and Piotr Piatyszek
          and Jakub Wisniewski and Przemyslaw Biecek},
  year={2020},
  journal={arXiv:2012.14406},
  url={https://arxiv.org/abs/2012.14406}
}
</code></pre>
<h2 id="developer">Developer</h2>
<h3 id="class-diagram">Class diagram</h3>
<p><img alt="" src="https://raw.githubusercontent.com/ModelOriented/DALEX-docs/master/dalex/dalex-class.png"></p>
<h3 id="folder-structure">Folder structure</h3>
<p><img alt="" src="https://raw.githubusercontent.com/ModelOriented/DALEX-docs/master/dalex/dalex-tree.png" width="70%"></p>
<hr>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/ModelOriented/DALEX/blob/2441c55e88b740295d874c46c88f5edce8139e7f/dalex\__init__.py#L0-L26" class="git-link">Browse git</a>
</summary>
<pre><code class="python">&#34;&#34;&#34;
.. include:: ./documentation.md
&#34;&#34;&#34;


from . import datasets
from ._explainer.object import Explainer
from .arena.object import Arena

__version__ = &#39;1.1.0&#39;

__all__ = [
    &#34;Arena&#34;,
    &#34;datasets&#34;,
    &#34;Explainer&#34;,
    &#34;fairness&#34;
]

# specify autocompletion in IPython
# see comment: https://github.com/ska-telescope/katpoint/commit/ed7e8b9e389ee035073c62c2394975fe71031f88
# __dir__ docs (Python 3.7!): https://docs.python.org/3.7/library/functions.html#dir 

def __dir__():
    &#34;&#34;&#34;IPython tab completion seems to respect this.&#34;&#34;&#34;
    return __all__ +  [&#39;__all__&#39;, &#39;__builtins__&#39;, &#39;__cached__&#39;, &#39;__doc__&#39;, &#39;__file__&#39;,
                       &#39;__loader__&#39;, &#39;__name__&#39;, &#39;__package__&#39;, &#39;__path__&#39;, &#39;__spec__&#39;,
                       &#39;__version__&#39;]</code></pre>
</details>
</section>
<section>
<h2 class="section-title" id="header-submodules">Sub-modules</h2>
<dl>
<dt><code class="name"><a title="dalex.arena" href="arena/index.html">dalex.arena</a></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt><code class="name"><a title="dalex.datasets" href="datasets/index.html">dalex.datasets</a></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt><code class="name"><a title="dalex.fairness" href="fairness/index.html">dalex.fairness</a></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt><code class="name"><a title="dalex.model_explanations" href="model_explanations/index.html">dalex.model_explanations</a></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt><code class="name"><a title="dalex.predict_explanations" href="predict_explanations/index.html">dalex.predict_explanations</a></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt><code class="name"><a title="dalex.wrappers" href="wrappers/index.html">dalex.wrappers</a></code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="dalex.Arena"><code class="flex name class">
<span>class <span class="ident">Arena</span></span>
<span>(</span><span>precalculate=False, enable_attributes=True, enable_custom_params=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Creates Arena object</p>
<p>This class should be used to create Python connector for Arena dashboard. Initialized
object can work both in static and live mode. Use <code>push_*</code> methods to add your
models, observations and datasets.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>precalculate</code></strong> :&ensp;<code>bool</code></dt>
<dd>Enables precalculating plots after using each <code>push_*</code> method.</dd>
<dt><strong><code>enable_attributes</code></strong> :&ensp;<code>bool</code></dt>
<dd>Enables attributes of observations and variables. Attributes are required to
display details of observation in Arena, but it also increases generated
file size.</dd>
<dt><strong><code>enable_custom_params</code></strong> :&ensp;<code>bool</code></dt>
<dd>Enables modififying observations in dashboard. It requires attributes and works
only in live version.</dd>
</dl>
<h2 id="attributes">Attributes</h2>
<dl>
<dt><strong><code>models</code></strong> :&ensp;<code>list</code> of <code>ModelParam objects</code></dt>
<dd>List of pushed models encapsulated in ModelParam class</dd>
<dt><strong><code>observations</code></strong> :&ensp;<code>list</code> of <code>ObservationParam objects</code></dt>
<dd>List of pushed observations encapsulated in ObservationParam class</dd>
<dt><strong><code>datasets</code></strong> :&ensp;<code>list</code> of <code>DatasetParam objects</code></dt>
<dd>List of pushed datasets encapsulated in DatasetParam class</dd>
<dt><strong><code>variables_cache</code></strong> :&ensp;<code>list</code> of <code>VariableParam objects</code></dt>
<dd>Cached list of VariableParam objects generated using pushed models and datasets</dd>
<dt><strong><code>server_thread</code></strong> :&ensp;<code>threading.Thread</code></dt>
<dd>Thread of running server or None otherwise</dd>
<dt><strong><code>precalculate</code></strong> :&ensp;<code>bool</code></dt>
<dd>if plots should be precalculated</dd>
<dt><strong><code>enable_attributes</code></strong> :&ensp;<code>bool</code></dt>
<dd>if attributes are enabled</dd>
<dt><strong><code>enable_custom_params</code></strong> :&ensp;<code>bool</code></dt>
<dd>if modifying observations is enabled</dd>
<dt><strong><code>timestamp</code></strong> :&ensp;<code>float</code></dt>
<dd>timestamp of last modification</dd>
<dt><strong><code>cache</code></strong> :&ensp;<code>list</code> of <code>PlotContainer objects</code></dt>
<dd>List of already calculated plots</dd>
<dt><strong><code>mutex</code></strong> :&ensp;<code>_thread.lock</code></dt>
<dd>Mutex for params and cache</dd>
<dt><strong><code>plots</code></strong> :&ensp;<code>list</code> of <code>classes extending PlotContainer</code></dt>
<dd>List of enabled plots</dd>
<dt><strong><code>options</code></strong> :&ensp;<code>dict</code></dt>
<dd>Options for plots</dd>
</dl>
<h2 id="notes">Notes</h2>
<p>For tutorial look at <a href="https://arena.drwhy.ai/docs/guide/first-datasource">https://arena.drwhy.ai/docs/guide/first-datasource</a></p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/ModelOriented/DALEX/blob/2441c55e88b740295d874c46c88f5edce8139e7f/dalex\arena\object.py#L15-L729" class="git-link">Browse git</a>
</summary>
<pre><code class="python">class Arena:
    &#34;&#34;&#34; Creates Arena object

    This class should be used to create Python connector for Arena dashboard. Initialized
    object can work both in static and live mode. Use `push_*` methods to add your
    models, observations and datasets.

    Parameters
    ----------
    precalculate : bool
        Enables precalculating plots after using each `push_*` method.
    enable_attributes : bool
        Enables attributes of observations and variables. Attributes are required to
        display details of observation in Arena, but it also increases generated
        file size.
    enable_custom_params : bool
        Enables modififying observations in dashboard. It requires attributes and works
        only in live version.

    Attributes
    --------
    models : list of ModelParam objects
        List of pushed models encapsulated in ModelParam class
    observations : list of ObservationParam objects
        List of pushed observations encapsulated in ObservationParam class
    datasets : list of DatasetParam objects
        List of pushed datasets encapsulated in DatasetParam class
    variables_cache : list of VariableParam objects
        Cached list of VariableParam objects generated using pushed models and datasets
    server_thread : threading.Thread
        Thread of running server or None otherwise
    precalculate : bool
        if plots should be precalculated
    enable_attributes : bool
        if attributes are enabled
    enable_custom_params : bool
        if modifying observations is enabled
    timestamp : float
        timestamp of last modification
    cache : list of PlotContainer objects
        List of already calculated plots
    mutex : _thread.lock
        Mutex for params and cache
    plots : list of classes extending PlotContainer
        List of enabled plots
    options : dict
        Options for plots

    Notes
    --------
    For tutorial look at https://arena.drwhy.ai/docs/guide/first-datasource

    &#34;&#34;&#34;
    def __init__(self, precalculate=False, enable_attributes=True, enable_custom_params=True):
        self.models = []
        self.observations = []
        self.datasets = []
        self.variables_cache = []
        self.server_thread = None
        self.precalculate = bool(precalculate)
        self.enable_attributes = bool(enable_attributes)
        self.enable_custom_params = bool(enable_custom_params)
        self.timestamp = datetime.timestamp(datetime.now())
        self.cache = []
        self.mutex = threading.Lock()
        self.plots = [
            ShapleyValuesContainer,
            FeatureImportanceContainer,
            PartialDependenceContainer,
            AccumulatedDependenceContainer,
            CeterisParibusContainer,
            BreakDownContainer,
            MetricsContainer,
            ROCContainer,
            FairnessCheckContainer
        ]
        self.options = {}
        for plot in self.plots:
            options = {}
            for o in plot.options.keys():
                options[o] = plot.options.get(o).get(&#39;default&#39;)
            self.options[plot.info.get(&#39;plotType&#39;)] = options

    def get_supported_plots(self):
        &#34;&#34;&#34;Returns plots classes that can produce at least one valid chart for this Arena.

        Returns
        -----------
        List of classes extending PlotContainer
        &#34;&#34;&#34;
        return [plot for plot in self.plots if plot.test_arena(self)]

    def run_server(self,
                   host=&#39;127.0.0.1&#39;,
                   port=8181,
                   append_data=False,
                   arena_url=&#39;https://arena.drwhy.ai/&#39;,
                   disable_logs=True):
        &#34;&#34;&#34;Starts server for live mode of Arena

        Parameters
        -----------
        host : str
            ip or hostname for the server
        port : int
            port number for the server
        append_data : bool
            if generated link should append data to already existing Arena window.
        arena_url : str
            URl of Arena dhasboard
        disable_logs : str
            if logs should be muted

        Notes
        --------
        Read more about data sources https://arena.drwhy.ai/docs/guide/basic-concepts

        Returns
        -----------
        Link to Arena
        &#34;&#34;&#34;
        if self.server_thread:
            raise Exception(&#39;Server is already running. To stop ip use arena.stop_server().&#39;)
        global_check_import(&#39;flask&#39;)
        global_check_import(&#39;flask_cors&#39;)
        global_check_import(&#39;requests&#39;)
        self.server_thread = threading.Thread(target=start_server, args=(self, host, port, disable_logs))
        self.server_thread.start()
        if append_data:
            print(arena_url + &#39;?append=http://&#39; + host + &#39;:&#39; + str(port) + &#39;/&#39;)
        else:
            print(arena_url + &#39;?data=http://&#39; + host + &#39;:&#39; + str(port) + &#39;/&#39;)

    def stop_server(self):
        &#34;&#34;&#34;Stops running server&#34;&#34;&#34;
        if not self.server_thread:
            raise Exception(&#39;Server is not running&#39;)
        self._stop_server()
        self.server_thread.join()
        self.server_thread = None

    def update_timestamp(self):
        &#34;&#34;&#34;Updates timestamp

        Notes
        -------
        This function must be called from mutex context
        &#34;&#34;&#34;
        now = datetime.now()
        self.timestamp = datetime.timestamp(now)

    def clear_cache(self, plot_type=None):
        &#34;&#34;&#34;Clears cache
        
        Parameters
        -----------
        plot_type : str or None
            If None all cache is cleared. Otherwise only plots with
            provided plot_type are removed.

        Notes
        -------
        This function must be called from mutex context
        &#34;&#34;&#34;
        if plot_type is None:
            self.cache = []
        else:
            self.cache = list(filter(lambda p: p.plot_type != plot_type, self.cache))
        self.update_timestamp()

    def find_in_cache(self, plot_type, params):
        &#34;&#34;&#34;Function searches for cached plot

        Parameters
        -----------
        plot_type : str
            Value of plot_type field, that requested plot must have
        params : dict
            Keys of this dict are params types (model, observation, variable, dataset)
            and values are corresponding params labels. Requested plot must have equal
            params field.

        Returns
        --------
        PlotContainer or None
        &#34;&#34;&#34;

        _filter = lambda p: p.plot_type == plot_type and params == p.params
        with self.mutex:
            return next(filter(_filter, self.cache), None)
    
    def put_to_cache(self, plot_container):
        &#34;&#34;&#34;Puts new plot to cache

        Parameters
        -----------
        plot_container : PlotContainer
        &#34;&#34;&#34;
        if not isinstance(plot_container, PlotContainer):
            raise Exception(&#39;Invalid plot container&#39;)
        with self.mutex:
            self.cache.append(plot_container)

    def fill_cache(self, fixed_params={}):
        &#34;&#34;&#34;Generates all available plots and cache them

        This function tries to generate all plots that are not cached already and
        put them to cache. Range of generated plots can be narrow using `fixed_params`

        Parameters
        -----------
        fixed_params : dict
            This dict specifies which plots should be generated. Only those with
            all keys from `fixed_params` present and having the same value will be
            calculated.
        &#34;&#34;&#34;
        if not isinstance(fixed_params, dict):
            raise Exception(&#39;Params argument must be a dict&#39;)
        for plot_class in self.get_supported_plots():
            required_params = plot_class.info.get(&#39;requiredParams&#39;)
            # Test if all params fixed by user are used in this plot. If not, then skip it.
            # This list contains fixed params&#39; types, that are not required by plot.
            # Loop will be skipped if this list is not empty.
            if len([k for k in fixed_params.keys() if not k in required_params]) &gt; 0:
                continue
            available_params = self.get_available_params()
            iteration_pools = map(lambda p: available_params.get(p) if fixed_params.get(p) is None else [fixed_params.get(p)], required_params)
            combinations = [[]]
            for pool in iteration_pools:
                combinations = [x + [y] for x in combinations for y in pool]
            for params_values in combinations:
                params = dict(zip(required_params, params_values))
                self.get_plot(plot_type=plot_class.info.get(&#39;plotType&#39;), params_values=params)

    def push_model(self, explainer, precalculate=None):
        &#34;&#34;&#34;Adds model to Arena

        This method encapsulate explainer in ModelParam object and
        save appends models fields. When precalculation is enabled
        triggers filling cache.

        Parameters
        -----------
        explainer : dalex.Explainer
            Explainer created using dalex package
        precalculate : bool or None
            Overrides constructor `precalculate` parameter when it is not None.
            If true, then only plots using this model will be precalculated.
        &#34;&#34;&#34;
        if not isinstance(explainer, Explainer):
            raise Exception(&#39;Invalid Explainer argument&#39;)
        if explainer.label in self.list_params(&#39;model&#39;):
            raise Exception(&#39;Explainer with the same label was already added&#39;)
        precalculate = self.precalculate if precalculate is None else bool(precalculate)
        param = ModelParam(explainer)
        with self.mutex:
            self.update_timestamp()
            self.models.append(param)
            self.variables_cache = []
        if precalculate:
            self.fill_cache({&#39;model&#39;: param})

    def push_observations(self, observations, precalculate=None):
        &#34;&#34;&#34;Adds observations to Arena

        Pushed observations will be used to local explainations. Function
        creates ObservationParam object for each row of pushed dataset. Label
        for each observation is taken from row name. When precalculation
        is enabled triggers filling cache.

        Parameters
        -----------
        observations : pandas.DataFrame
            Data frame of observations to be explained using instance level plots.
            Label for each observation is taken from row name.
        precalculate : bool or None
            Overrides constructor `precalculate` parameter when it is not None.
            If true, then only plots using thease observations will be precalculated.
        &#34;&#34;&#34;
        if not isinstance(observations, DataFrame):
            raise Exception(&#39;Observations argument is not a pandas DataFrame&#39;)
        if len(observations.index.names) != 1:
            raise Exception(&#39;Observations argument need to have only one index&#39;)
        if not observations.index.is_unique:
            raise Exception(&#39;Observations argument need to have unique indexes&#39;)
        precalculate = self.precalculate if precalculate is None else bool(precalculate)
        old_observations = self.list_params(&#39;observation&#39;)
        observations = observations.set_index(observations.index.astype(str))
        params_objects = []
        for x in observations.index:
            if x in old_observations:
                raise Exception(&#39;Indexes of observations need to be unique across all observations&#39;)
            params_objects.append(ObservationParam(dataset=observations, index=x))
        with self.mutex:
            self.update_timestamp()
            self.observations.extend(params_objects)
        if precalculate:
            for obs in params_objects:
                self.fill_cache({&#39;observation&#39;: obs})

    def push_dataset(self, dataset, target, label, precalculate=None):
        &#34;&#34;&#34;Adds dataset to Arena

        Pushed dataset will visualised using exploratory data analysis plots.
        Function creates DatasetParam object with specified label and target name.
        When precalculation is enabled triggers filling cache.

        Parameters
        -----------
        dataset : pandas.DataFrame
            Data frame to be visualised using EDA plots. This
            dataset should contain target variable.
        target : str
            Name of target column
        label : str
            Label for this dataset
        precalculate : bool or None
            Overrides constructor `precalculate` parameter when it is not None.
            If true, then only plots using this model will be precalculated.
        &#34;&#34;&#34;
        if not isinstance(dataset, DataFrame):
            raise Exception(&#39;Dataset argument is not a pandas DataFrame&#39;)
        if len(dataset.columns.names) != 1:
            raise Exception(&#39;Dataset argument need to have only one level column names&#39;)
        precalculate = self.precalculate if precalculate is None else bool(precalculate)
        target = str(target)
        if target not in dataset.columns:
            raise Exception(&#39;Target is not a column from dataset&#39;)
        if (not isinstance(label, str)) or (len(label) == 0):
            raise Exception(&#39;Label need to be at least one letter&#39;)
        if label in self.list_params(&#39;dataset&#39;):
            raise Exception(&#39;Labels need to be unique&#39;)
        param = DatasetParam(dataset=dataset, label=label, target=target)
        with self.mutex:
            self.update_timestamp()
            self.datasets.append(param)
            self.variables_cache = []
        if precalculate:
            self.fill_cache({&#39;dataset&#39;: param})

    def get_params(self, param_type):
        &#34;&#34;&#34;Returns list of available params

        Parameters
        -----------
        param_type : str
            One of [&#39;model&#39;, &#39;variable&#39;, &#39;observation&#39;, &#39;dataset&#39;]. Params of this type
            will be returned

        Notes
        --------
        Information about params https://arena.drwhy.ai/docs/guide/params

        Returns
        --------
        List of Param objects
        &#34;&#34;&#34;
        if param_type == &#39;observation&#39;:
            with self.mutex:
                return self.observations
        elif param_type == &#39;variable&#39;:
            with self.mutex:
                if not self.variables_cache:
                    # Extract column names from every dataset in self.dataset list and flatten it
                    result_datasets = [col for dataset in self.datasets for col in dataset.variables]
                    # Extract column names from every model in self.models list and flatten it
                    result_explainers = [col for model in self.models for col in model.variables]
                    result_str = np.unique(result_datasets + result_explainers).tolist()
                    self.variables_cache = [VariableParam(x) for x in result_str]
                    if self.enable_attributes:
                        for var in self.variables_cache:
                            try:
                                for dataset in self.datasets:
                                    if var.variable in dataset.variables:
                                        var.update_attributes(dataset.dataset[var.variable])
                                for model in self.models:
                                    if var.variable in model.variables:
                                        var.update_attributes(model.explainer.data[var.variable])
                            except:
                                var.clear_attributes()
                return self.variables_cache
        elif param_type == &#39;model&#39;:
            with self.mutex:
                return self.models
        elif param_type == &#39;dataset&#39;:
            with self.mutex:
                return self.datasets
        else:
            raise Exception(&#39;Invalid param type&#39;)

    def list_params(self, param_type):
        &#34;&#34;&#34;Returns list of available params&#39;s labels

        Parameters
        -----------
        param_type : str
            One of [&#39;model&#39;, &#39;variable&#39;, &#39;observation&#39;, &#39;dataset&#39;]. Labels of params
            of this type will be returned

        Notes
        --------
        Information about params https://arena.drwhy.ai/docs/guide/params

        Returns
        --------
        List of str
        &#34;&#34;&#34;
        return [x.get_label() for x in self.get_params(param_type)]

    def get_available_params(self):
        &#34;&#34;&#34;Returns dict containing available params of all types

        This method collect result of `get_params` method for each param type into
        a dict. Keys are param types and values are lists of Param objects.

        Notes
        --------
        Information about params https://arena.drwhy.ai/docs/guide/params

        Returns
        --------
        dict
        &#34;&#34;&#34;
        result = {}
        for param_type in [&#39;model&#39;, &#39;observation&#39;, &#39;variable&#39;, &#39;dataset&#39;]:
            result[param_type] = self.get_params(param_type)
        return result

    def list_available_params(self):
        &#34;&#34;&#34;Returns dict containing labels of available params of all types

        This methods collect result of `list_params` for each param type into
        a dict. Keys are param types and values are list of labels.

        Notes
        --------
        Information about params https://arena.drwhy.ai/docs/guide/params

        Returns
        --------
        dict
        &#34;&#34;&#34;
        result = {}
        for param_type in [&#39;model&#39;, &#39;observation&#39;, &#39;variable&#39;, &#39;dataset&#39;]:
            result[param_type] = self.list_params(param_type)
        return result
    
    def find_param_value(self, param_type, param_label):
        &#34;&#34;&#34;Searches for Param object with specified label

        Parameters
        -----------
        param_type : str
            One of [&#39;model&#39;, &#39;variable&#39;, &#39;observation&#39;, &#39;dataset&#39;].
        param_label : str
            Label of searched param

        Notes
        --------
        Information about params https://arena.drwhy.ai/docs/guide/params

        Returns
        --------
        Param or None
        &#34;&#34;&#34;
        if param_label is None or not isinstance(param_label, str):
            return None
        return next((x for x in self.get_params(param_type) if x.get_label() == param_label), None)

    def print_options(self, plot_type=None):
        &#34;&#34;&#34;Prints available options for plots

        Parameters
        -----------
        plot_type : str or None
            When not None, then only options for plots with this plot_type will
            be printed.

        Notes
        --------
        List of plots with described options for each one https://arena.drwhy.ai/docs/guide/observation-level
        &#34;&#34;&#34;

        plot = next((x for x in self.plots if x.info.get(&#39;plotType&#39;) == plot_type), None)
        if plot_type is None or plot is None:
            for plot in self.plots:
                self.print_options(plot.info.get(&#39;plotType&#39;))
            return
        print(&#39;\n\033[1m&#39; + plot.info.get(&#39;plotType&#39;) + &#39;\033[0m&#39;)
        print(&#39;---------------------------------&#39;)
        for o in plot.options.keys():
            option = plot.options.get(o)
            value = self.options.get(plot_type).get(o)
            print(o + &#39;: &#39; + str(value) + &#39;   #&#39; + option.get(&#39;desc&#39;))

    def get_option(self, plot_type, option):
        &#34;&#34;&#34;Returns value of specified option

        Parameters
        -----------
        plot_type : str
           Type of plot, the option is corresponding to.
        option : str
            Name of the option

        Notes
        --------
        List of plots with described options for each one https://arena.drwhy.ai/docs/guide/observation-level

        Returns
        --------
        None or value of option
        &#34;&#34;&#34;
        options = self.options.get(plot_type)
        if options is None:
            raise Exception(&#39;Invalid plot_type&#39;)
        if not option in options.keys():
            return
        with self.mutex:
            return self.options.get(plot_type).get(option)

    def set_option(self, plot_type, option, value):
        &#34;&#34;&#34;Sets value for the plot option

        Parameters
        -----------
        plot_type : str
            When None, then value will be set for each plot with
            option of name from `option` argument. Otherwise only
            for plots with specified type.
        option : str
            Name of the option
        value : *
            Value to be set

        Notes
        --------
        List of plots with described options for each one https://arena.drwhy.ai/docs/guide/observation-level
        &#34;&#34;&#34;
        if plot_type is None:
            for plot in self.plots:
                self.set_option(plot.info.get(&#39;plotType&#39;), option, value)
            return
        options = self.options.get(plot_type)
        if options is None:
            raise Exception(&#39;Invalid plot_type&#39;)
        if not option in options.keys():
            return
        with self.mutex:
            self.options.get(plot_type)[option] = value
            self.clear_cache(plot_type)
        if self.precalculate:
            self.fill_cache()

    def get_plot(self, plot_type, params_values, cache=True):
        &#34;&#34;&#34;Returns plot for specified type and params

        Function serches for plot in cache, when not present creates
        requested plot and put it to cache.

        Parameters
        -----------
        plot_type : str
            Type of plot to be generated
        params_values : dict
            Dict for param types as keys and Param objects as values
        cache : bool
            If serach for plot in cache and put calculated plot into cache.

        Returns
        --------
        PlotContainer
        &#34;&#34;&#34;
        plot_class = next((c for c in self.plots if c.info.get(&#39;plotType&#39;) == plot_type), None)
        if plot_class is None:
            raise Exception(&#39;Not supported plot type&#39;)
        plot_type = plot_class.info.get(&#39;plotType&#39;)
        required_params_values = {}
        required_params_labels = {}
        for p in plot_class.info.get(&#39;requiredParams&#39;):
            if params_values.get(p) is None:
                raise Exception(&#39;Required param is missing&#39;)
            required_params_values[p] = params_values.get(p)
            required_params_labels[p] = params_values.get(p).get_label()
        result = self.find_in_cache(plot_type, required_params_labels) if cache else None
        if result is None:
            result = plot_class(self).fit(required_params_values)
            if cache:
                self.put_to_cache(result)
        return result

    def get_params_attributes(self, param_type=None):
        &#34;&#34;&#34;Returns attributes for all params

        When `param_type` is not None, then function returns list of dicts. Each dict represents
        one of available attribute for specified param type. Field `name` is attribute name
        and field `values` is mapped list of available params to list of value of attribute.
        When `param_type` is None, then function returns dict with keys for each param type and
        values are lists described above.

        Parameters
        -----------
        param_type : str or None
            One of [&#39;model&#39;, &#39;variable&#39;, &#39;observation&#39;, &#39;dataset&#39;] or None. Specifies
            attributes of which params should be returned.

        Notes
        --------
        Attribused are used for dynamicly modifying observations https://arena.drwhy.ai/docs/guide/modifying-observations

        Returns
        --------
        dict or list
        &#34;&#34;&#34;

        if param_type is None:
            obj = {}
            for p in [&#39;model&#39;, &#39;observation&#39;, &#39;variable&#39;, &#39;dataset&#39;]:
                obj[p] = self.get_params_attributes(p)
            return obj
        if not self.enable_attributes:
            return []
        attrs = Param.get_param_class(param_type).list_attributes(self)
        array = []
        for attr in attrs:
            array.append({
                &#39;name&#39;: attr,
                &#39;values&#39;: [param.get_attributes().get(attr) for param in self.get_params(param_type)]
            })
        return array

    def get_param_attributes(self, param_type, param_label):
        &#34;&#34;&#34;Returns attributes for one param

        Function searches for param with specified type and label and
        returns it&#39;s attributes.

        Parameters
        -----------
        param_type : str
            One of [&#39;model&#39;, &#39;variable&#39;, &#39;observation&#39;, &#39;dataset&#39;].
        param_label : str
            Label of param

        Notes
        --------
        Attribused are used for dynamicly modifying observations https://arena.drwhy.ai/docs/guide/modifying-observations

        Returns
        --------
        dict
        &#34;&#34;&#34;

        if not self.enable_attributes:
            return {}
        param_value = self.find_param_value(param_type=param_type, param_label=param_label)
        if param_value:
            return param_value.get_attributes()
        else:
            return {}

    def save(self, filename=&#34;datasource.json&#34;):
        &#34;&#34;&#34;Generate all plots and saves them to JSON file

        Function generates only not cached plots.

        Parameters
        -----------
        filename : str
            Path or filename to output file

        Notes
        --------
        Read more about data sources https://arena.drwhy.ai/docs/guide/basic-concepts

        Returns
        --------
        None
        &#34;&#34;&#34;
        with open(filename, &#39;w&#39;) as file:
            file.write(get_json(self))

    def upload(self, token=None, arena_url=&#39;https://arena.drwhy.ai/&#39;, open_browser=True):
        &#34;&#34;&#34;Generate all plots and uploads them to GitHub Gist

        Function generates only not cached plots. If token is not provided
        then function uses OAuth to open GitHub authorization page.

        Parameters
        -----------
        token : str or None
            GitHub personal access token. If token is None, then OAuth is used.
        arena_url : str
            Address of Arena dashboard instance
        open_browser : bool
            Whether to open Arena after upload.

        Notes
        --------
        Read more about data sources https://arena.drwhy.ai/docs/guide/basic-concepts

        Returns
        --------
        Link to the Arena
        &#34;&#34;&#34;
        global_check_import(&#39;requests&#39;)
        if token is None:
            global_check_import(&#39;flask&#39;)
            global_check_import(&#39;flask_cors&#39;)
            token = generate_token()
        data_url = upload_arena(self, token)
        url = arena_url + &#39;?data=&#39; + data_url
        if open_browser:
            webbrowser.open(url)
        return url</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="dalex.Arena.clear_cache"><code class="name flex">
<span>def <span class="ident">clear_cache</span></span>(<span>self, plot_type=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Clears cache</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>plot_type</code></strong> :&ensp;<code>str</code> or <code>None</code></dt>
<dd>If None all cache is cleared. Otherwise only plots with
provided plot_type are removed.</dd>
</dl>
<h2 id="notes">Notes</h2>
<p>This function must be called from mutex context</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/ModelOriented/DALEX/blob/2441c55e88b740295d874c46c88f5edce8139e7f/dalex\arena\object.py#L166-L183" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def clear_cache(self, plot_type=None):
    &#34;&#34;&#34;Clears cache
    
    Parameters
    -----------
    plot_type : str or None
        If None all cache is cleared. Otherwise only plots with
        provided plot_type are removed.

    Notes
    -------
    This function must be called from mutex context
    &#34;&#34;&#34;
    if plot_type is None:
        self.cache = []
    else:
        self.cache = list(filter(lambda p: p.plot_type != plot_type, self.cache))
    self.update_timestamp()</code></pre>
</details>
</dd>
<dt id="dalex.Arena.fill_cache"><code class="name flex">
<span>def <span class="ident">fill_cache</span></span>(<span>self, fixed_params={})</span>
</code></dt>
<dd>
<div class="desc"><p>Generates all available plots and cache them</p>
<p>This function tries to generate all plots that are not cached already and
put them to cache. Range of generated plots can be narrow using <code>fixed_params</code></p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>fixed_params</code></strong> :&ensp;<code>dict</code></dt>
<dd>This dict specifies which plots should be generated. Only those with
all keys from <code>fixed_params</code> present and having the same value will be
calculated.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/ModelOriented/DALEX/blob/2441c55e88b740295d874c46c88f5edce8139e7f/dalex\arena\object.py#L218-L247" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def fill_cache(self, fixed_params={}):
    &#34;&#34;&#34;Generates all available plots and cache them

    This function tries to generate all plots that are not cached already and
    put them to cache. Range of generated plots can be narrow using `fixed_params`

    Parameters
    -----------
    fixed_params : dict
        This dict specifies which plots should be generated. Only those with
        all keys from `fixed_params` present and having the same value will be
        calculated.
    &#34;&#34;&#34;
    if not isinstance(fixed_params, dict):
        raise Exception(&#39;Params argument must be a dict&#39;)
    for plot_class in self.get_supported_plots():
        required_params = plot_class.info.get(&#39;requiredParams&#39;)
        # Test if all params fixed by user are used in this plot. If not, then skip it.
        # This list contains fixed params&#39; types, that are not required by plot.
        # Loop will be skipped if this list is not empty.
        if len([k for k in fixed_params.keys() if not k in required_params]) &gt; 0:
            continue
        available_params = self.get_available_params()
        iteration_pools = map(lambda p: available_params.get(p) if fixed_params.get(p) is None else [fixed_params.get(p)], required_params)
        combinations = [[]]
        for pool in iteration_pools:
            combinations = [x + [y] for x in combinations for y in pool]
        for params_values in combinations:
            params = dict(zip(required_params, params_values))
            self.get_plot(plot_type=plot_class.info.get(&#39;plotType&#39;), params_values=params)</code></pre>
</details>
</dd>
<dt id="dalex.Arena.find_in_cache"><code class="name flex">
<span>def <span class="ident">find_in_cache</span></span>(<span>self, plot_type, params)</span>
</code></dt>
<dd>
<div class="desc"><p>Function searches for cached plot</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>plot_type</code></strong> :&ensp;<code>str</code></dt>
<dd>Value of plot_type field, that requested plot must have</dd>
<dt><strong><code>params</code></strong> :&ensp;<code>dict</code></dt>
<dd>Keys of this dict are params types (model, observation, variable, dataset)
and values are corresponding params labels. Requested plot must have equal
params field.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>PlotContainer</code> or <code>None</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/ModelOriented/DALEX/blob/2441c55e88b740295d874c46c88f5edce8139e7f/dalex\arena\object.py#L185-L204" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def find_in_cache(self, plot_type, params):
    &#34;&#34;&#34;Function searches for cached plot

    Parameters
    -----------
    plot_type : str
        Value of plot_type field, that requested plot must have
    params : dict
        Keys of this dict are params types (model, observation, variable, dataset)
        and values are corresponding params labels. Requested plot must have equal
        params field.

    Returns
    --------
    PlotContainer or None
    &#34;&#34;&#34;

    _filter = lambda p: p.plot_type == plot_type and params == p.params
    with self.mutex:
        return next(filter(_filter, self.cache), None)</code></pre>
</details>
</dd>
<dt id="dalex.Arena.find_param_value"><code class="name flex">
<span>def <span class="ident">find_param_value</span></span>(<span>self, param_type, param_label)</span>
</code></dt>
<dd>
<div class="desc"><p>Searches for Param object with specified label</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>param_type</code></strong> :&ensp;<code>str</code></dt>
<dd>One of ['model', 'variable', 'observation', 'dataset'].</dd>
<dt><strong><code>param_label</code></strong> :&ensp;<code>str</code></dt>
<dd>Label of searched param</dd>
</dl>
<h2 id="notes">Notes</h2>
<p>Information about params <a href="https://arena.drwhy.ai/docs/guide/params">https://arena.drwhy.ai/docs/guide/params</a></p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>Param</code> or <code>None</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/ModelOriented/DALEX/blob/2441c55e88b740295d874c46c88f5edce8139e7f/dalex\arena\object.py#L462-L482" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def find_param_value(self, param_type, param_label):
    &#34;&#34;&#34;Searches for Param object with specified label

    Parameters
    -----------
    param_type : str
        One of [&#39;model&#39;, &#39;variable&#39;, &#39;observation&#39;, &#39;dataset&#39;].
    param_label : str
        Label of searched param

    Notes
    --------
    Information about params https://arena.drwhy.ai/docs/guide/params

    Returns
    --------
    Param or None
    &#34;&#34;&#34;
    if param_label is None or not isinstance(param_label, str):
        return None
    return next((x for x in self.get_params(param_type) if x.get_label() == param_label), None)</code></pre>
</details>
</dd>
<dt id="dalex.Arena.get_available_params"><code class="name flex">
<span>def <span class="ident">get_available_params</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Returns dict containing available params of all types</p>
<p>This method collect result of <code>get_params</code> method for each param type into
a dict. Keys are param types and values are lists of Param objects.</p>
<h2 id="notes">Notes</h2>
<p>Information about params <a href="https://arena.drwhy.ai/docs/guide/params">https://arena.drwhy.ai/docs/guide/params</a></p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>dict</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/ModelOriented/DALEX/blob/2441c55e88b740295d874c46c88f5edce8139e7f/dalex\arena\object.py#L424-L441" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def get_available_params(self):
    &#34;&#34;&#34;Returns dict containing available params of all types

    This method collect result of `get_params` method for each param type into
    a dict. Keys are param types and values are lists of Param objects.

    Notes
    --------
    Information about params https://arena.drwhy.ai/docs/guide/params

    Returns
    --------
    dict
    &#34;&#34;&#34;
    result = {}
    for param_type in [&#39;model&#39;, &#39;observation&#39;, &#39;variable&#39;, &#39;dataset&#39;]:
        result[param_type] = self.get_params(param_type)
    return result</code></pre>
</details>
</dd>
<dt id="dalex.Arena.get_option"><code class="name flex">
<span>def <span class="ident">get_option</span></span>(<span>self, plot_type, option)</span>
</code></dt>
<dd>
<div class="desc"><p>Returns value of specified option</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>plot_type</code></strong> :&ensp;<code>str</code></dt>
<dd>&nbsp;</dd>
<dt>Type of plot, the option is corresponding to.</dt>
<dt><strong><code>option</code></strong> :&ensp;<code>str</code></dt>
<dd>Name of the option</dd>
</dl>
<h2 id="notes">Notes</h2>
<p>List of plots with described options for each one <a href="https://arena.drwhy.ai/docs/guide/observation-level">https://arena.drwhy.ai/docs/guide/observation-level</a></p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>None</code> or <code>value</code> of <code>option</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/ModelOriented/DALEX/blob/2441c55e88b740295d874c46c88f5edce8139e7f/dalex\arena\object.py#L510-L534" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def get_option(self, plot_type, option):
    &#34;&#34;&#34;Returns value of specified option

    Parameters
    -----------
    plot_type : str
       Type of plot, the option is corresponding to.
    option : str
        Name of the option

    Notes
    --------
    List of plots with described options for each one https://arena.drwhy.ai/docs/guide/observation-level

    Returns
    --------
    None or value of option
    &#34;&#34;&#34;
    options = self.options.get(plot_type)
    if options is None:
        raise Exception(&#39;Invalid plot_type&#39;)
    if not option in options.keys():
        return
    with self.mutex:
        return self.options.get(plot_type).get(option)</code></pre>
</details>
</dd>
<dt id="dalex.Arena.get_param_attributes"><code class="name flex">
<span>def <span class="ident">get_param_attributes</span></span>(<span>self, param_type, param_label)</span>
</code></dt>
<dd>
<div class="desc"><p>Returns attributes for one param</p>
<p>Function searches for param with specified type and label and
returns it's attributes.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>param_type</code></strong> :&ensp;<code>str</code></dt>
<dd>One of ['model', 'variable', 'observation', 'dataset'].</dd>
<dt><strong><code>param_label</code></strong> :&ensp;<code>str</code></dt>
<dd>Label of param</dd>
</dl>
<h2 id="notes">Notes</h2>
<p>Attribused are used for dynamicly modifying observations <a href="https://arena.drwhy.ai/docs/guide/modifying-observations">https://arena.drwhy.ai/docs/guide/modifying-observations</a></p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>dict</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/ModelOriented/DALEX/blob/2441c55e88b740295d874c46c88f5edce8139e7f/dalex\arena\object.py#L646-L674" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def get_param_attributes(self, param_type, param_label):
    &#34;&#34;&#34;Returns attributes for one param

    Function searches for param with specified type and label and
    returns it&#39;s attributes.

    Parameters
    -----------
    param_type : str
        One of [&#39;model&#39;, &#39;variable&#39;, &#39;observation&#39;, &#39;dataset&#39;].
    param_label : str
        Label of param

    Notes
    --------
    Attribused are used for dynamicly modifying observations https://arena.drwhy.ai/docs/guide/modifying-observations

    Returns
    --------
    dict
    &#34;&#34;&#34;

    if not self.enable_attributes:
        return {}
    param_value = self.find_param_value(param_type=param_type, param_label=param_label)
    if param_value:
        return param_value.get_attributes()
    else:
        return {}</code></pre>
</details>
</dd>
<dt id="dalex.Arena.get_params"><code class="name flex">
<span>def <span class="ident">get_params</span></span>(<span>self, param_type)</span>
</code></dt>
<dd>
<div class="desc"><p>Returns list of available params</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>param_type</code></strong> :&ensp;<code>str</code></dt>
<dd>One of ['model', 'variable', 'observation', 'dataset']. Params of this type
will be returned</dd>
</dl>
<h2 id="notes">Notes</h2>
<p>Information about params <a href="https://arena.drwhy.ai/docs/guide/params">https://arena.drwhy.ai/docs/guide/params</a></p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>List</code> of <code>Param objects</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/ModelOriented/DALEX/blob/2441c55e88b740295d874c46c88f5edce8139e7f/dalex\arena\object.py#L355-L403" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def get_params(self, param_type):
    &#34;&#34;&#34;Returns list of available params

    Parameters
    -----------
    param_type : str
        One of [&#39;model&#39;, &#39;variable&#39;, &#39;observation&#39;, &#39;dataset&#39;]. Params of this type
        will be returned

    Notes
    --------
    Information about params https://arena.drwhy.ai/docs/guide/params

    Returns
    --------
    List of Param objects
    &#34;&#34;&#34;
    if param_type == &#39;observation&#39;:
        with self.mutex:
            return self.observations
    elif param_type == &#39;variable&#39;:
        with self.mutex:
            if not self.variables_cache:
                # Extract column names from every dataset in self.dataset list and flatten it
                result_datasets = [col for dataset in self.datasets for col in dataset.variables]
                # Extract column names from every model in self.models list and flatten it
                result_explainers = [col for model in self.models for col in model.variables]
                result_str = np.unique(result_datasets + result_explainers).tolist()
                self.variables_cache = [VariableParam(x) for x in result_str]
                if self.enable_attributes:
                    for var in self.variables_cache:
                        try:
                            for dataset in self.datasets:
                                if var.variable in dataset.variables:
                                    var.update_attributes(dataset.dataset[var.variable])
                            for model in self.models:
                                if var.variable in model.variables:
                                    var.update_attributes(model.explainer.data[var.variable])
                        except:
                            var.clear_attributes()
            return self.variables_cache
    elif param_type == &#39;model&#39;:
        with self.mutex:
            return self.models
    elif param_type == &#39;dataset&#39;:
        with self.mutex:
            return self.datasets
    else:
        raise Exception(&#39;Invalid param type&#39;)</code></pre>
</details>
</dd>
<dt id="dalex.Arena.get_params_attributes"><code class="name flex">
<span>def <span class="ident">get_params_attributes</span></span>(<span>self, param_type=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Returns attributes for all params</p>
<p>When <code>param_type</code> is not None, then function returns list of dicts. Each dict represents
one of available attribute for specified param type. Field <code>name</code> is attribute name
and field <code>values</code> is mapped list of available params to list of value of attribute.
When <code>param_type</code> is None, then function returns dict with keys for each param type and
values are lists described above.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>param_type</code></strong> :&ensp;<code>str</code> or <code>None</code></dt>
<dd>One of ['model', 'variable', 'observation', 'dataset'] or None. Specifies
attributes of which params should be returned.</dd>
</dl>
<h2 id="notes">Notes</h2>
<p>Attribused are used for dynamicly modifying observations <a href="https://arena.drwhy.ai/docs/guide/modifying-observations">https://arena.drwhy.ai/docs/guide/modifying-observations</a></p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>dict</code> or <code>list</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/ModelOriented/DALEX/blob/2441c55e88b740295d874c46c88f5edce8139e7f/dalex\arena\object.py#L606-L644" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def get_params_attributes(self, param_type=None):
    &#34;&#34;&#34;Returns attributes for all params

    When `param_type` is not None, then function returns list of dicts. Each dict represents
    one of available attribute for specified param type. Field `name` is attribute name
    and field `values` is mapped list of available params to list of value of attribute.
    When `param_type` is None, then function returns dict with keys for each param type and
    values are lists described above.

    Parameters
    -----------
    param_type : str or None
        One of [&#39;model&#39;, &#39;variable&#39;, &#39;observation&#39;, &#39;dataset&#39;] or None. Specifies
        attributes of which params should be returned.

    Notes
    --------
    Attribused are used for dynamicly modifying observations https://arena.drwhy.ai/docs/guide/modifying-observations

    Returns
    --------
    dict or list
    &#34;&#34;&#34;

    if param_type is None:
        obj = {}
        for p in [&#39;model&#39;, &#39;observation&#39;, &#39;variable&#39;, &#39;dataset&#39;]:
            obj[p] = self.get_params_attributes(p)
        return obj
    if not self.enable_attributes:
        return []
    attrs = Param.get_param_class(param_type).list_attributes(self)
    array = []
    for attr in attrs:
        array.append({
            &#39;name&#39;: attr,
            &#39;values&#39;: [param.get_attributes().get(attr) for param in self.get_params(param_type)]
        })
    return array</code></pre>
</details>
</dd>
<dt id="dalex.Arena.get_plot"><code class="name flex">
<span>def <span class="ident">get_plot</span></span>(<span>self, plot_type, params_values, cache=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Returns plot for specified type and params</p>
<p>Function serches for plot in cache, when not present creates
requested plot and put it to cache.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>plot_type</code></strong> :&ensp;<code>str</code></dt>
<dd>Type of plot to be generated</dd>
<dt><strong><code>params_values</code></strong> :&ensp;<code>dict</code></dt>
<dd>Dict for param types as keys and Param objects as values</dd>
<dt><strong><code>cache</code></strong> :&ensp;<code>bool</code></dt>
<dd>If serach for plot in cache and put calculated plot into cache.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>PlotContainer</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/ModelOriented/DALEX/blob/2441c55e88b740295d874c46c88f5edce8139e7f/dalex\arena\object.py#L569-L604" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def get_plot(self, plot_type, params_values, cache=True):
    &#34;&#34;&#34;Returns plot for specified type and params

    Function serches for plot in cache, when not present creates
    requested plot and put it to cache.

    Parameters
    -----------
    plot_type : str
        Type of plot to be generated
    params_values : dict
        Dict for param types as keys and Param objects as values
    cache : bool
        If serach for plot in cache and put calculated plot into cache.

    Returns
    --------
    PlotContainer
    &#34;&#34;&#34;
    plot_class = next((c for c in self.plots if c.info.get(&#39;plotType&#39;) == plot_type), None)
    if plot_class is None:
        raise Exception(&#39;Not supported plot type&#39;)
    plot_type = plot_class.info.get(&#39;plotType&#39;)
    required_params_values = {}
    required_params_labels = {}
    for p in plot_class.info.get(&#39;requiredParams&#39;):
        if params_values.get(p) is None:
            raise Exception(&#39;Required param is missing&#39;)
        required_params_values[p] = params_values.get(p)
        required_params_labels[p] = params_values.get(p).get_label()
    result = self.find_in_cache(plot_type, required_params_labels) if cache else None
    if result is None:
        result = plot_class(self).fit(required_params_values)
        if cache:
            self.put_to_cache(result)
    return result</code></pre>
</details>
</dd>
<dt id="dalex.Arena.get_supported_plots"><code class="name flex">
<span>def <span class="ident">get_supported_plots</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Returns plots classes that can produce at least one valid chart for this Arena.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>List</code> of <code>classes extending PlotContainer</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/ModelOriented/DALEX/blob/2441c55e88b740295d874c46c88f5edce8139e7f/dalex\arena\object.py#L98-L105" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def get_supported_plots(self):
    &#34;&#34;&#34;Returns plots classes that can produce at least one valid chart for this Arena.

    Returns
    -----------
    List of classes extending PlotContainer
    &#34;&#34;&#34;
    return [plot for plot in self.plots if plot.test_arena(self)]</code></pre>
</details>
</dd>
<dt id="dalex.Arena.list_available_params"><code class="name flex">
<span>def <span class="ident">list_available_params</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Returns dict containing labels of available params of all types</p>
<p>This methods collect result of <code>list_params</code> for each param type into
a dict. Keys are param types and values are list of labels.</p>
<h2 id="notes">Notes</h2>
<p>Information about params <a href="https://arena.drwhy.ai/docs/guide/params">https://arena.drwhy.ai/docs/guide/params</a></p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>dict</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/ModelOriented/DALEX/blob/2441c55e88b740295d874c46c88f5edce8139e7f/dalex\arena\object.py#L443-L460" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def list_available_params(self):
    &#34;&#34;&#34;Returns dict containing labels of available params of all types

    This methods collect result of `list_params` for each param type into
    a dict. Keys are param types and values are list of labels.

    Notes
    --------
    Information about params https://arena.drwhy.ai/docs/guide/params

    Returns
    --------
    dict
    &#34;&#34;&#34;
    result = {}
    for param_type in [&#39;model&#39;, &#39;observation&#39;, &#39;variable&#39;, &#39;dataset&#39;]:
        result[param_type] = self.list_params(param_type)
    return result</code></pre>
</details>
</dd>
<dt id="dalex.Arena.list_params"><code class="name flex">
<span>def <span class="ident">list_params</span></span>(<span>self, param_type)</span>
</code></dt>
<dd>
<div class="desc"><p>Returns list of available params's labels</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>param_type</code></strong> :&ensp;<code>str</code></dt>
<dd>One of ['model', 'variable', 'observation', 'dataset']. Labels of params
of this type will be returned</dd>
</dl>
<h2 id="notes">Notes</h2>
<p>Information about params <a href="https://arena.drwhy.ai/docs/guide/params">https://arena.drwhy.ai/docs/guide/params</a></p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>List</code> of <code>str</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/ModelOriented/DALEX/blob/2441c55e88b740295d874c46c88f5edce8139e7f/dalex\arena\object.py#L405-L422" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def list_params(self, param_type):
    &#34;&#34;&#34;Returns list of available params&#39;s labels

    Parameters
    -----------
    param_type : str
        One of [&#39;model&#39;, &#39;variable&#39;, &#39;observation&#39;, &#39;dataset&#39;]. Labels of params
        of this type will be returned

    Notes
    --------
    Information about params https://arena.drwhy.ai/docs/guide/params

    Returns
    --------
    List of str
    &#34;&#34;&#34;
    return [x.get_label() for x in self.get_params(param_type)]</code></pre>
</details>
</dd>
<dt id="dalex.Arena.print_options"><code class="name flex">
<span>def <span class="ident">print_options</span></span>(<span>self, plot_type=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Prints available options for plots</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>plot_type</code></strong> :&ensp;<code>str</code> or <code>None</code></dt>
<dd>When not None, then only options for plots with this plot_type will
be printed.</dd>
</dl>
<h2 id="notes">Notes</h2>
<p>List of plots with described options for each one <a href="https://arena.drwhy.ai/docs/guide/observation-level">https://arena.drwhy.ai/docs/guide/observation-level</a></p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/ModelOriented/DALEX/blob/2441c55e88b740295d874c46c88f5edce8139e7f/dalex\arena\object.py#L484-L508" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def print_options(self, plot_type=None):
    &#34;&#34;&#34;Prints available options for plots

    Parameters
    -----------
    plot_type : str or None
        When not None, then only options for plots with this plot_type will
        be printed.

    Notes
    --------
    List of plots with described options for each one https://arena.drwhy.ai/docs/guide/observation-level
    &#34;&#34;&#34;

    plot = next((x for x in self.plots if x.info.get(&#39;plotType&#39;) == plot_type), None)
    if plot_type is None or plot is None:
        for plot in self.plots:
            self.print_options(plot.info.get(&#39;plotType&#39;))
        return
    print(&#39;\n\033[1m&#39; + plot.info.get(&#39;plotType&#39;) + &#39;\033[0m&#39;)
    print(&#39;---------------------------------&#39;)
    for o in plot.options.keys():
        option = plot.options.get(o)
        value = self.options.get(plot_type).get(o)
        print(o + &#39;: &#39; + str(value) + &#39;   #&#39; + option.get(&#39;desc&#39;))</code></pre>
</details>
</dd>
<dt id="dalex.Arena.push_dataset"><code class="name flex">
<span>def <span class="ident">push_dataset</span></span>(<span>self, dataset, target, label, precalculate=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Adds dataset to Arena</p>
<p>Pushed dataset will visualised using exploratory data analysis plots.
Function creates DatasetParam object with specified label and target name.
When precalculation is enabled triggers filling cache.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>dataset</code></strong> :&ensp;<code>pandas.DataFrame</code></dt>
<dd>Data frame to be visualised using EDA plots. This
dataset should contain target variable.</dd>
<dt><strong><code>target</code></strong> :&ensp;<code>str</code></dt>
<dd>Name of target column</dd>
<dt><strong><code>label</code></strong> :&ensp;<code>str</code></dt>
<dd>Label for this dataset</dd>
<dt><strong><code>precalculate</code></strong> :&ensp;<code>bool</code> or <code>None</code></dt>
<dd>Overrides constructor <code>precalculate</code> parameter when it is not None.
If true, then only plots using this model will be precalculated.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/ModelOriented/DALEX/blob/2441c55e88b740295d874c46c88f5edce8139e7f/dalex\arena\object.py#L315-L353" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def push_dataset(self, dataset, target, label, precalculate=None):
    &#34;&#34;&#34;Adds dataset to Arena

    Pushed dataset will visualised using exploratory data analysis plots.
    Function creates DatasetParam object with specified label and target name.
    When precalculation is enabled triggers filling cache.

    Parameters
    -----------
    dataset : pandas.DataFrame
        Data frame to be visualised using EDA plots. This
        dataset should contain target variable.
    target : str
        Name of target column
    label : str
        Label for this dataset
    precalculate : bool or None
        Overrides constructor `precalculate` parameter when it is not None.
        If true, then only plots using this model will be precalculated.
    &#34;&#34;&#34;
    if not isinstance(dataset, DataFrame):
        raise Exception(&#39;Dataset argument is not a pandas DataFrame&#39;)
    if len(dataset.columns.names) != 1:
        raise Exception(&#39;Dataset argument need to have only one level column names&#39;)
    precalculate = self.precalculate if precalculate is None else bool(precalculate)
    target = str(target)
    if target not in dataset.columns:
        raise Exception(&#39;Target is not a column from dataset&#39;)
    if (not isinstance(label, str)) or (len(label) == 0):
        raise Exception(&#39;Label need to be at least one letter&#39;)
    if label in self.list_params(&#39;dataset&#39;):
        raise Exception(&#39;Labels need to be unique&#39;)
    param = DatasetParam(dataset=dataset, label=label, target=target)
    with self.mutex:
        self.update_timestamp()
        self.datasets.append(param)
        self.variables_cache = []
    if precalculate:
        self.fill_cache({&#39;dataset&#39;: param})</code></pre>
</details>
</dd>
<dt id="dalex.Arena.push_model"><code class="name flex">
<span>def <span class="ident">push_model</span></span>(<span>self, explainer, precalculate=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Adds model to Arena</p>
<p>This method encapsulate explainer in ModelParam object and
save appends models fields. When precalculation is enabled
triggers filling cache.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>explainer</code></strong> :&ensp;<code><a title="dalex.Explainer" href="#dalex.Explainer">Explainer</a></code></dt>
<dd>Explainer created using dalex package</dd>
<dt><strong><code>precalculate</code></strong> :&ensp;<code>bool</code> or <code>None</code></dt>
<dd>Overrides constructor <code>precalculate</code> parameter when it is not None.
If true, then only plots using this model will be precalculated.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/ModelOriented/DALEX/blob/2441c55e88b740295d874c46c88f5edce8139e7f/dalex\arena\object.py#L249-L275" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def push_model(self, explainer, precalculate=None):
    &#34;&#34;&#34;Adds model to Arena

    This method encapsulate explainer in ModelParam object and
    save appends models fields. When precalculation is enabled
    triggers filling cache.

    Parameters
    -----------
    explainer : dalex.Explainer
        Explainer created using dalex package
    precalculate : bool or None
        Overrides constructor `precalculate` parameter when it is not None.
        If true, then only plots using this model will be precalculated.
    &#34;&#34;&#34;
    if not isinstance(explainer, Explainer):
        raise Exception(&#39;Invalid Explainer argument&#39;)
    if explainer.label in self.list_params(&#39;model&#39;):
        raise Exception(&#39;Explainer with the same label was already added&#39;)
    precalculate = self.precalculate if precalculate is None else bool(precalculate)
    param = ModelParam(explainer)
    with self.mutex:
        self.update_timestamp()
        self.models.append(param)
        self.variables_cache = []
    if precalculate:
        self.fill_cache({&#39;model&#39;: param})</code></pre>
</details>
</dd>
<dt id="dalex.Arena.push_observations"><code class="name flex">
<span>def <span class="ident">push_observations</span></span>(<span>self, observations, precalculate=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Adds observations to Arena</p>
<p>Pushed observations will be used to local explainations. Function
creates ObservationParam object for each row of pushed dataset. Label
for each observation is taken from row name. When precalculation
is enabled triggers filling cache.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>observations</code></strong> :&ensp;<code>pandas.DataFrame</code></dt>
<dd>Data frame of observations to be explained using instance level plots.
Label for each observation is taken from row name.</dd>
<dt><strong><code>precalculate</code></strong> :&ensp;<code>bool</code> or <code>None</code></dt>
<dd>Overrides constructor <code>precalculate</code> parameter when it is not None.
If true, then only plots using thease observations will be precalculated.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/ModelOriented/DALEX/blob/2441c55e88b740295d874c46c88f5edce8139e7f/dalex\arena\object.py#L277-L313" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def push_observations(self, observations, precalculate=None):
    &#34;&#34;&#34;Adds observations to Arena

    Pushed observations will be used to local explainations. Function
    creates ObservationParam object for each row of pushed dataset. Label
    for each observation is taken from row name. When precalculation
    is enabled triggers filling cache.

    Parameters
    -----------
    observations : pandas.DataFrame
        Data frame of observations to be explained using instance level plots.
        Label for each observation is taken from row name.
    precalculate : bool or None
        Overrides constructor `precalculate` parameter when it is not None.
        If true, then only plots using thease observations will be precalculated.
    &#34;&#34;&#34;
    if not isinstance(observations, DataFrame):
        raise Exception(&#39;Observations argument is not a pandas DataFrame&#39;)
    if len(observations.index.names) != 1:
        raise Exception(&#39;Observations argument need to have only one index&#39;)
    if not observations.index.is_unique:
        raise Exception(&#39;Observations argument need to have unique indexes&#39;)
    precalculate = self.precalculate if precalculate is None else bool(precalculate)
    old_observations = self.list_params(&#39;observation&#39;)
    observations = observations.set_index(observations.index.astype(str))
    params_objects = []
    for x in observations.index:
        if x in old_observations:
            raise Exception(&#39;Indexes of observations need to be unique across all observations&#39;)
        params_objects.append(ObservationParam(dataset=observations, index=x))
    with self.mutex:
        self.update_timestamp()
        self.observations.extend(params_objects)
    if precalculate:
        for obs in params_objects:
            self.fill_cache({&#39;observation&#39;: obs})</code></pre>
</details>
</dd>
<dt id="dalex.Arena.put_to_cache"><code class="name flex">
<span>def <span class="ident">put_to_cache</span></span>(<span>self, plot_container)</span>
</code></dt>
<dd>
<div class="desc"><p>Puts new plot to cache</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>plot_container</code></strong> :&ensp;<code>PlotContainer</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/ModelOriented/DALEX/blob/2441c55e88b740295d874c46c88f5edce8139e7f/dalex\arena\object.py#L206-L216" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def put_to_cache(self, plot_container):
    &#34;&#34;&#34;Puts new plot to cache

    Parameters
    -----------
    plot_container : PlotContainer
    &#34;&#34;&#34;
    if not isinstance(plot_container, PlotContainer):
        raise Exception(&#39;Invalid plot container&#39;)
    with self.mutex:
        self.cache.append(plot_container)</code></pre>
</details>
</dd>
<dt id="dalex.Arena.run_server"><code class="name flex">
<span>def <span class="ident">run_server</span></span>(<span>self, host='127.0.0.1', port=8181, append_data=False, arena_url='https://arena.drwhy.ai/', disable_logs=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Starts server for live mode of Arena</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>host</code></strong> :&ensp;<code>str</code></dt>
<dd>ip or hostname for the server</dd>
<dt><strong><code>port</code></strong> :&ensp;<code>int</code></dt>
<dd>port number for the server</dd>
<dt><strong><code>append_data</code></strong> :&ensp;<code>bool</code></dt>
<dd>if generated link should append data to already existing Arena window.</dd>
<dt><strong><code>arena_url</code></strong> :&ensp;<code>str</code></dt>
<dd>URl of Arena dhasboard</dd>
<dt><strong><code>disable_logs</code></strong> :&ensp;<code>str</code></dt>
<dd>if logs should be muted</dd>
</dl>
<h2 id="notes">Notes</h2>
<p>Read more about data sources <a href="https://arena.drwhy.ai/docs/guide/basic-concepts">https://arena.drwhy.ai/docs/guide/basic-concepts</a></p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>Link to <a title="dalex.Arena" href="#dalex.Arena">Arena</a></code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/ModelOriented/DALEX/blob/2441c55e88b740295d874c46c88f5edce8139e7f/dalex\arena\object.py#L107-L146" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def run_server(self,
               host=&#39;127.0.0.1&#39;,
               port=8181,
               append_data=False,
               arena_url=&#39;https://arena.drwhy.ai/&#39;,
               disable_logs=True):
    &#34;&#34;&#34;Starts server for live mode of Arena

    Parameters
    -----------
    host : str
        ip or hostname for the server
    port : int
        port number for the server
    append_data : bool
        if generated link should append data to already existing Arena window.
    arena_url : str
        URl of Arena dhasboard
    disable_logs : str
        if logs should be muted

    Notes
    --------
    Read more about data sources https://arena.drwhy.ai/docs/guide/basic-concepts

    Returns
    -----------
    Link to Arena
    &#34;&#34;&#34;
    if self.server_thread:
        raise Exception(&#39;Server is already running. To stop ip use arena.stop_server().&#39;)
    global_check_import(&#39;flask&#39;)
    global_check_import(&#39;flask_cors&#39;)
    global_check_import(&#39;requests&#39;)
    self.server_thread = threading.Thread(target=start_server, args=(self, host, port, disable_logs))
    self.server_thread.start()
    if append_data:
        print(arena_url + &#39;?append=http://&#39; + host + &#39;:&#39; + str(port) + &#39;/&#39;)
    else:
        print(arena_url + &#39;?data=http://&#39; + host + &#39;:&#39; + str(port) + &#39;/&#39;)</code></pre>
</details>
</dd>
<dt id="dalex.Arena.save"><code class="name flex">
<span>def <span class="ident">save</span></span>(<span>self, filename='datasource.json')</span>
</code></dt>
<dd>
<div class="desc"><p>Generate all plots and saves them to JSON file</p>
<p>Function generates only not cached plots.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>filename</code></strong> :&ensp;<code>str</code></dt>
<dd>Path or filename to output file</dd>
</dl>
<h2 id="notes">Notes</h2>
<p>Read more about data sources <a href="https://arena.drwhy.ai/docs/guide/basic-concepts">https://arena.drwhy.ai/docs/guide/basic-concepts</a></p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>None</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/ModelOriented/DALEX/blob/2441c55e88b740295d874c46c88f5edce8139e7f/dalex\arena\object.py#L676-L695" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def save(self, filename=&#34;datasource.json&#34;):
    &#34;&#34;&#34;Generate all plots and saves them to JSON file

    Function generates only not cached plots.

    Parameters
    -----------
    filename : str
        Path or filename to output file

    Notes
    --------
    Read more about data sources https://arena.drwhy.ai/docs/guide/basic-concepts

    Returns
    --------
    None
    &#34;&#34;&#34;
    with open(filename, &#39;w&#39;) as file:
        file.write(get_json(self))</code></pre>
</details>
</dd>
<dt id="dalex.Arena.set_option"><code class="name flex">
<span>def <span class="ident">set_option</span></span>(<span>self, plot_type, option, value)</span>
</code></dt>
<dd>
<div class="desc"><p>Sets value for the plot option</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>plot_type</code></strong> :&ensp;<code>str</code></dt>
<dd>When None, then value will be set for each plot with
option of name from <code>option</code> argument. Otherwise only
for plots with specified type.</dd>
<dt><strong><code>option</code></strong> :&ensp;<code>str</code></dt>
<dd>Name of the option</dd>
<dt><strong><code>value</code></strong> :&ensp;<code>*</code></dt>
<dd>Value to be set</dd>
</dl>
<h2 id="notes">Notes</h2>
<p>List of plots with described options for each one <a href="https://arena.drwhy.ai/docs/guide/observation-level">https://arena.drwhy.ai/docs/guide/observation-level</a></p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/ModelOriented/DALEX/blob/2441c55e88b740295d874c46c88f5edce8139e7f/dalex\arena\object.py#L536-L567" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def set_option(self, plot_type, option, value):
    &#34;&#34;&#34;Sets value for the plot option

    Parameters
    -----------
    plot_type : str
        When None, then value will be set for each plot with
        option of name from `option` argument. Otherwise only
        for plots with specified type.
    option : str
        Name of the option
    value : *
        Value to be set

    Notes
    --------
    List of plots with described options for each one https://arena.drwhy.ai/docs/guide/observation-level
    &#34;&#34;&#34;
    if plot_type is None:
        for plot in self.plots:
            self.set_option(plot.info.get(&#39;plotType&#39;), option, value)
        return
    options = self.options.get(plot_type)
    if options is None:
        raise Exception(&#39;Invalid plot_type&#39;)
    if not option in options.keys():
        return
    with self.mutex:
        self.options.get(plot_type)[option] = value
        self.clear_cache(plot_type)
    if self.precalculate:
        self.fill_cache()</code></pre>
</details>
</dd>
<dt id="dalex.Arena.stop_server"><code class="name flex">
<span>def <span class="ident">stop_server</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Stops running server</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/ModelOriented/DALEX/blob/2441c55e88b740295d874c46c88f5edce8139e7f/dalex\arena\object.py#L148-L154" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def stop_server(self):
    &#34;&#34;&#34;Stops running server&#34;&#34;&#34;
    if not self.server_thread:
        raise Exception(&#39;Server is not running&#39;)
    self._stop_server()
    self.server_thread.join()
    self.server_thread = None</code></pre>
</details>
</dd>
<dt id="dalex.Arena.update_timestamp"><code class="name flex">
<span>def <span class="ident">update_timestamp</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Updates timestamp</p>
<h2 id="notes">Notes</h2>
<p>This function must be called from mutex context</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/ModelOriented/DALEX/blob/2441c55e88b740295d874c46c88f5edce8139e7f/dalex\arena\object.py#L156-L164" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def update_timestamp(self):
    &#34;&#34;&#34;Updates timestamp

    Notes
    -------
    This function must be called from mutex context
    &#34;&#34;&#34;
    now = datetime.now()
    self.timestamp = datetime.timestamp(now)</code></pre>
</details>
</dd>
<dt id="dalex.Arena.upload"><code class="name flex">
<span>def <span class="ident">upload</span></span>(<span>self, token=None, arena_url='https://arena.drwhy.ai/', open_browser=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Generate all plots and uploads them to GitHub Gist</p>
<p>Function generates only not cached plots. If token is not provided
then function uses OAuth to open GitHub authorization page.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>token</code></strong> :&ensp;<code>str</code> or <code>None</code></dt>
<dd>GitHub personal access token. If token is None, then OAuth is used.</dd>
<dt><strong><code>arena_url</code></strong> :&ensp;<code>str</code></dt>
<dd>Address of Arena dashboard instance</dd>
<dt><strong><code>open_browser</code></strong> :&ensp;<code>bool</code></dt>
<dd>Whether to open Arena after upload.</dd>
</dl>
<h2 id="notes">Notes</h2>
<p>Read more about data sources <a href="https://arena.drwhy.ai/docs/guide/basic-concepts">https://arena.drwhy.ai/docs/guide/basic-concepts</a></p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>Link to the <a title="dalex.Arena" href="#dalex.Arena">Arena</a></code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/ModelOriented/DALEX/blob/2441c55e88b740295d874c46c88f5edce8139e7f/dalex\arena\object.py#L697-L729" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def upload(self, token=None, arena_url=&#39;https://arena.drwhy.ai/&#39;, open_browser=True):
    &#34;&#34;&#34;Generate all plots and uploads them to GitHub Gist

    Function generates only not cached plots. If token is not provided
    then function uses OAuth to open GitHub authorization page.

    Parameters
    -----------
    token : str or None
        GitHub personal access token. If token is None, then OAuth is used.
    arena_url : str
        Address of Arena dashboard instance
    open_browser : bool
        Whether to open Arena after upload.

    Notes
    --------
    Read more about data sources https://arena.drwhy.ai/docs/guide/basic-concepts

    Returns
    --------
    Link to the Arena
    &#34;&#34;&#34;
    global_check_import(&#39;requests&#39;)
    if token is None:
        global_check_import(&#39;flask&#39;)
        global_check_import(&#39;flask_cors&#39;)
        token = generate_token()
    data_url = upload_arena(self, token)
    url = arena_url + &#39;?data=&#39; + data_url
    if open_browser:
        webbrowser.open(url)
    return url</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="dalex.Explainer"><code class="flex name class">
<span>class <span class="ident">Explainer</span></span>
<span>(</span><span>model, data=None, y=None, predict_function=None, residual_function=None, weights=None, label=None, model_class=None, verbose=True, precalculate=True, model_type=None, model_info=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Create Model Explainer</p>
<p>Black-box models may have very different structures. This class creates a unified
representation of a model, which can be further processed by various explanations.
Methods of this class produce explanation objects, that contain the main result
attribute, and can be visualised using the plot method.</p>
<p>The <code>model</code> is the only required parameter, but most of the explanations require
that other parameters are provided (See <code>data</code>, <code>y</code>, <code>predict_function</code>, <code>model_type</code>).</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>model</code></strong> :&ensp;<code>object</code></dt>
<dd>Model to be explained.</dd>
<dt><strong><code>data</code></strong> :&ensp;<code>pd.DataFrame</code> or <code>np.ndarray (2d)</code></dt>
<dd>Data which will be used to calculate the explanations. It shouldn't contain
the target column (See <code>y</code>).
NOTE: If target variable is present in the data, some of the functionalities may
not work properly.</dd>
<dt><strong><code>y</code></strong> :&ensp;<code>pd.Series</code> or <code>pd.DataFrame</code> or <code>np.ndarray (1d)</code></dt>
<dd>Target variable with outputs / scores. It shall have the same length as <code>data</code>.</dd>
<dt><strong><code>predict_function</code></strong> :&ensp;<code>function</code>, optional</dt>
<dd>Function that takes two parameters (model, data) and returns a np.ndarray (1d)
with model predictions (default is predict method extracted from the model).
NOTE: This function needs to work with <code>data</code> as pd.DataFrame.</dd>
<dt><strong><code>residual_function</code></strong> :&ensp;<code>function</code>, optional</dt>
<dd>Function that takes three parameters (model, data, y) and returns a np.ndarray (1d)
with model residuals (default is a function constructed from <code>predict_function</code>).</dd>
<dt><strong><code>weights</code></strong> :&ensp;<code>pd.Series</code> or <code>np.ndarray (1d)</code>, optional</dt>
<dd>Sampling weights for observations in <code>data</code>. It shall have the same length as
<code>data</code> (default is <code>None</code>).</dd>
<dt><strong><code>label</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>Model name to appear in result and plots
(default is last element of the class attribute extracted from the model).</dd>
<dt><strong><code>model_class</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>Class of the model that is used e.g. to choose the <code>predict_function</code>
(default is the class attribute extracted from the model).
NOTE: Use if your model is wrapped with Pipeline.</dd>
<dt><strong><code>verbose</code></strong> :&ensp;<code>bool</code></dt>
<dd>Print diagnostic messages during the Explainer initialization (default is <code>True</code>).</dd>
<dt><strong><code>precalculate</code></strong> :&ensp;<code>bool</code></dt>
<dd>Calculate y_hat (predicted values) and residuals during the Explainer
initialization (default is <code>True</code>).</dd>
<dt><strong><code>model_type</code></strong> :&ensp;<code>{'regression', 'classification', None}</code></dt>
<dd>Model task type that is used e.g. in <code>model_performance()</code> and <code>model_parts()</code>
(default is try to extract the information from the model, else <code>None</code>).</dd>
<dt><strong><code>model_info</code></strong> :&ensp;<code>dict</code>, optional</dt>
<dd>Dict <code>{'model_package', 'model_package_version', ...}</code> containing additional
information to be stored.</dd>
</dl>
<h2 id="attributes">Attributes</h2>
<dl>
<dt><strong><code>model</code></strong> :&ensp;<code>object</code></dt>
<dd>A model to be explained.</dd>
<dt><strong><code>data</code></strong> :&ensp;<code>pd.DataFrame</code></dt>
<dd>Data which will be used to calculate the explanations.</dd>
<dt><strong><code>y</code></strong> :&ensp;<code>np.ndarray (1d)</code></dt>
<dd>Target variable with outputs / scores.</dd>
<dt><strong><code>predict_function</code></strong> :&ensp;<code>function</code></dt>
<dd>Function that takes two arguments (model, data) and returns np.ndarray (1d)
with model predictions.</dd>
<dt><strong><code>y_hat</code></strong> :&ensp;<code>np.ndarray (1d)</code></dt>
<dd>Model predictions for <code>data</code>.</dd>
<dt><strong><code>residual_function</code></strong> :&ensp;<code>function</code></dt>
<dd>Function that takes three arguments (model, data, y) and returns np.ndarray (1d)
with model residuals.</dd>
<dt><strong><code>residuals</code></strong> :&ensp;<code>np.ndarray (1d)</code></dt>
<dd>Model residuals for <code>data</code>.</dd>
<dt><strong><code>weights</code></strong> :&ensp;<code>np.ndarray (1d)</code></dt>
<dd>Sampling weights for observations in <code>data</code>.</dd>
<dt><strong><code>label</code></strong> :&ensp;<code>str</code></dt>
<dd>Name to appear in result and plots.</dd>
<dt><strong><code>model_class</code></strong> :&ensp;<code>str</code></dt>
<dd>Class of the model.</dd>
<dt><strong><code>model_type</code></strong> :&ensp;<code>{'regression', 'classification',</code>None<code>}</code></dt>
<dd>Model task type.</dd>
<dt><strong><code>model_info</code></strong> :&ensp;<code>dict</code></dt>
<dd>Dict <code>{'model_package', 'model_package_version', ...}</code> containing additional
information.</dd>
</dl>
<h2 id="notes">Notes</h2>
<ul>
<li><a href="https://pbiecek.github.io/ema/dataSetsIntro.html#ExplainersTitanicPythonCode">https://pbiecek.github.io/ema/dataSetsIntro.html#ExplainersTitanicPythonCode</a></li>
</ul></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/ModelOriented/DALEX/blob/2441c55e88b740295d874c46c88f5edce8139e7f/dalex\_explainer\object.py#L15-L1056" class="git-link">Browse git</a>
</summary>
<pre><code class="python">class Explainer:
    &#34;&#34;&#34; Create Model Explainer

    Black-box models may have very different structures. This class creates a unified
    representation of a model, which can be further processed by various explanations.
    Methods of this class produce explanation objects, that contain the main result
    attribute, and can be visualised using the plot method.

    The `model` is the only required parameter, but most of the explanations require
    that other parameters are provided (See `data`, `y`, `predict_function`, `model_type`).

    Parameters
    ----------
    model : object
        Model to be explained.
    data : pd.DataFrame or np.ndarray (2d)
        Data which will be used to calculate the explanations. It shouldn&#39;t contain
        the target column (See `y`).
        NOTE: If target variable is present in the data, some of the functionalities may
        not work properly.
    y : pd.Series or pd.DataFrame or np.ndarray (1d)
        Target variable with outputs / scores. It shall have the same length as `data`.
    predict_function : function, optional
        Function that takes two parameters (model, data) and returns a np.ndarray (1d)
        with model predictions (default is predict method extracted from the model).
        NOTE: This function needs to work with `data` as pd.DataFrame.
    residual_function : function, optional
        Function that takes three parameters (model, data, y) and returns a np.ndarray (1d)
        with model residuals (default is a function constructed from `predict_function`).
    weights : pd.Series or np.ndarray (1d), optional
        Sampling weights for observations in `data`. It shall have the same length as
        `data` (default is `None`).
    label : str, optional
        Model name to appear in result and plots
        (default is last element of the class attribute extracted from the model).
    model_class : str, optional
        Class of the model that is used e.g. to choose the `predict_function`
        (default is the class attribute extracted from the model).
        NOTE: Use if your model is wrapped with Pipeline.
    verbose : bool
        Print diagnostic messages during the Explainer initialization (default is `True`).
    precalculate : bool
        Calculate y_hat (predicted values) and residuals during the Explainer
        initialization (default is `True`).
    model_type : {&#39;regression&#39;, &#39;classification&#39;, None}
        Model task type that is used e.g. in `model_performance()` and `model_parts()`
        (default is try to extract the information from the model, else `None`).
    model_info: dict, optional
        Dict `{&#39;model_package&#39;, &#39;model_package_version&#39;, ...}` containing additional
        information to be stored.

    Attributes
    --------
    model : object
        A model to be explained.
    data : pd.DataFrame
        Data which will be used to calculate the explanations.
    y : np.ndarray (1d)
        Target variable with outputs / scores.
    predict_function : function
        Function that takes two arguments (model, data) and returns np.ndarray (1d)
        with model predictions.
    y_hat : np.ndarray (1d)
        Model predictions for `data`.
    residual_function : function
        Function that takes three arguments (model, data, y) and returns np.ndarray (1d)
        with model residuals.
    residuals : np.ndarray (1d)
        Model residuals for `data`.
    weights : np.ndarray (1d)
        Sampling weights for observations in `data`.
    label : str
        Name to appear in result and plots.
    model_class : str
        Class of the model.
    model_type : {&#39;regression&#39;, &#39;classification&#39;, `None`}
        Model task type.
    model_info: dict
        Dict `{&#39;model_package&#39;, &#39;model_package_version&#39;, ...}` containing additional
        information.

    Notes
    --------
    - https://pbiecek.github.io/ema/dataSetsIntro.html#ExplainersTitanicPythonCode

    &#34;&#34;&#34;

    def __init__(self,
                 model,
                 data=None,
                 y=None,
                 predict_function=None,
                 residual_function=None,
                 weights=None,
                 label=None,
                 model_class=None,
                 verbose=True,
                 precalculate=True,
                 model_type=None,
                 model_info=None):

        # TODO: colorize
        
        helper.verbose_cat(&#34;Preparation of a new explainer is initiated\n&#34;, verbose=verbose)

        # REPORT: checks for data
        data, model = checks.check_data(data, model, verbose)

        # REPORT: checks for y
        y = checks.check_y(y, data, verbose)

        # REPORT: checks for weights
        weights = checks.check_weights(weights, data, verbose)

        # REPORT: checks for model_class
        model_class, _model_info = checks.check_model_class(model_class, model, verbose)

        # REPORT: checks for label
        label, _model_info = checks.check_label(label, model_class, _model_info, verbose)

        # REPORT: checks for predict_function and model_type
        # these two are together only because of `yhat_exception_dict`
        predict_function, model_type, y_hat, _model_info = \
            checks.check_predict_function_and_model_type(predict_function, model_type,
                                                         model, data, model_class, _model_info,
                                                         precalculate, verbose)

        # if data is specified then we may test predict_function
        # at this moment we have predict function

        # REPORT: checks for residual_function
        residual_function, residuals, _model_info = checks.check_residual_function(
            residual_function, predict_function, model, data, y, _model_info, precalculate, verbose
        )

        # REPORT: checks for model_info
        _model_info = checks.check_model_info(model_info, _model_info, verbose)

        # READY to create an explainer
        self.model = model
        self.data = data
        self.y = y
        self.predict_function = predict_function
        self.y_hat = y_hat
        self.residual_function = residual_function
        self.residuals = residuals
        self.model_class = model_class
        self.label = label
        self.model_info = _model_info
        self.weights = weights
        self.model_type = model_type

        helper.verbose_cat(&#34;\nA new explainer has been created!&#34;, verbose=verbose)

    def predict(self, data):
        &#34;&#34;&#34;Make a prediction

        This function uses the `predict_function` attribute.

        Parameters
        ----------
        data : pd.DataFrame, np.ndarray (2d)
            Data which will be used to make a prediction.

        Returns
        ----------
        np.ndarray (1d)
            Model predictions for given `data`.
        &#34;&#34;&#34;

        checks.check_method_data(data)

        return self.predict_function(self.model, data)

    def residual(self, data, y):
        &#34;&#34;&#34;Calculate residuals

        This function uses the `residual_function` attribute.

        Parameters
        -----------
        data : pd.DataFrame
            Data which will be used to calculate residuals.
        y : pd.Series or np.ndarray (1d)
            Target variable which will be used to calculate residuals.

        Returns
        -----------
        np.ndarray (1d)
            Model residuals for given `data` and `y`.
        &#34;&#34;&#34;

        checks.check_method_data(data)

        return self.residual_function(self.model, data, y)

    def predict_parts(self,
                      new_observation,
                      type=(&#39;break_down_interactions&#39;, &#39;break_down&#39;, &#39;shap&#39;, &#39;shap_wrapper&#39;),
                      order=None,
                      interaction_preference=1,
                      path=&#34;average&#34;,
                      N=None,
                      B=25,
                      keep_distributions=False,
                      label=None,
                      processes=1,
                      random_state=None,
                      **kwargs):
        &#34;&#34;&#34;Calculate predict-level variable attributions as Break Down, Shapley Values or Shap Values

        Parameters
        -----------
        new_observation : pd.Series or np.ndarray (1d) or pd.DataFrame (1,p)
            An observation for which a prediction needs to be explained.
        type : {&#39;break_down_interactions&#39;, &#39;break_down&#39;, &#39;shap&#39;, &#39;shap_wrapper&#39;}
            Type of variable attributions (default is `&#39;break_down_interactions&#39;`).
        order : list of int or str, optional
            Parameter specific for `break_down_interactions` and `break_down`. Use a fixed
            order of variables for attribution calculation. Use integer values  or string
            variable names (default is `None`, which means order by importance).
        interaction_preference : int, optional
            Parameter specific for `break_down_interactions` type. Specify which interactions
            will be present in an explanation. The larger the integer, the more frequently
            interactions will be presented (default is `1`).
        path : list of int, optional
            Parameter specific for `shap`. If specified, then attributions for this path
            will be plotted (default is `&#39;average&#39;`, which plots attribution means for
            `B` random paths).
        N : int, optional
            Number of observations that will be sampled from the `data` attribute before
            the calculation of variable attributions. Default is `None` which means all `data`.
        B : int, optional
            Parameter specific for `shap`. Number of random paths to calculate
            variable attributions (default is `25`).
        keep_distributions :  bool, optional
            Save the distribution of partial predictions (default is `False`).
        label : str, optional
            Name to appear in result and plots. Overrides default.
        processes : int, optional
            Parameter specific for `shap`. Number of parallel processes to use in calculations.
            Iterated over `B` (default is `1`, which means no parallel computation).
        random_state : int, optional
            Set seed for random number generator (default is random seed).
        kwargs : dict
            Used only for `&#39;shap_wrapper&#39;`. Pass `shap_explainer_type` to specify, which
            Explainer shall be used: `{&#39;TreeExplainer&#39;, &#39;DeepExplainer&#39;, &#39;GradientExplainer&#39;,
            &#39;LinearExplainer&#39;, &#39;KernelExplainer&#39;}` (default is `None`, which automatically
            chooses an Explainer to use).
            Also keyword arguments passed to one of the: `shap.TreeExplainer.shap_values,
            shap.DeepExplainer.shap_values, shap.GradientExplainer.shap_values,
            shap.LinearExplainer.shap_values, shap.KernelExplainer.shap_values`.
            See https://github.com/slundberg/shap

        Returns
        -----------
        BreakDown, Shap or ShapWrapper class object
            Explanation object containing the main result attribute and the plot method.
            Object class, its attributes, and the plot method depend on the `type` parameter.

        Notes
        --------
        - https://pbiecek.github.io/ema/breakDown.html
        - https://pbiecek.github.io/ema/iBreakDown.html
        - https://pbiecek.github.io/ema/shapley.html
        - https://github.com/slundberg/shap
        &#34;&#34;&#34;

        checks.check_data_again(self.data)

        types = (&#39;break_down_interactions&#39;, &#39;break_down&#39;, &#39;shap&#39;, &#39;shap_wrapper&#39;)
        _type = checks.check_method_type(type, types)

        if isinstance(N, int):
            # temporarly overwrite data in the Explainer (fastest way)
            # at the end of predict_parts fix the Explainer (add original data)
            if isinstance(random_state, int):
                np.random.seed(random_state)
            N = min(N, self.data.shape[0])
            I = np.random.choice(np.arange(N), N, replace=False)
            from copy import deepcopy
            _data = deepcopy(self.data)
            self.data = self.data.iloc[I, :]

        if _type == &#39;break_down_interactions&#39; or _type == &#39;break_down&#39;:
            _predict_parts = BreakDown(
                type=_type,
                keep_distributions=keep_distributions,
                order=order,
                interaction_preference=interaction_preference
            )
        elif _type == &#39;shap&#39;:
            _predict_parts = Shap(
                keep_distributions=keep_distributions,
                path=path,
                B=B,
                processes=processes,
                random_state=random_state
            )
        elif _type == &#39;shap_wrapper&#39;:
            _global_checks.global_check_import(&#39;shap&#39;, &#39;SHAP explanations&#39;)
            _predict_parts = ShapWrapper(&#39;predict_parts&#39;)
        else:
            raise TypeError(&#34;Wrong type parameter.&#34;)

        _predict_parts.fit(self, new_observation, **kwargs)
        
        if label:
            _predict_parts.result[&#39;label&#39;] = label

        if isinstance(N, int):
            self.data = _data

        return _predict_parts

    def predict_profile(self,
                        new_observation,
                        type=(&#39;ceteris_paribus&#39;,),
                        y=None,
                        variables=None,
                        grid_points=101,
                        variable_splits=None,
                        variable_splits_type=&#39;uniform&#39;,
                        variable_splits_with_obs=True,
                        processes=1,
                        label=None,
                        verbose=True):
        &#34;&#34;&#34;Calculate predict-level variable profiles as Ceteris Paribus

        Parameters
        -----------
        new_observation : pd.DataFrame or np.ndarray or pd.Series
            Observations for which predictions need to be explained.
        type : {&#39;ceteris_paribus&#39;, TODO: &#39;oscilations&#39;}
            Type of variable profiles (default is `&#39;ceteris_paribus&#39;`).
        y : pd.Series or np.ndarray (1d), optional
            Target variable with the same length as `new_observation`.
        variables : str or array_like of str, optional
            Variables for which the profiles will be calculated
            (default is `None`, which means all of the variables).
        grid_points : int, optional
            Maximum number of points for profile calculations (default is `101`).
            NOTE: The final number of points may be lower than `grid_points`,
            eg. if there is not enough unique values for a given variable.
        variable_splits : dict of lists, optional
            Split points for variables e.g. `{&#39;x&#39;: [0, 0.2, 0.5, 0.8, 1], &#39;y&#39;: [&#39;a&#39;, &#39;b&#39;]}`
            (default is `None`, which means that they will be calculated using one of
            `variable_splits_type` and the `data` attribute).
        variable_splits_type : {&#39;uniform&#39;, &#39;quantiles&#39;}, optional
            Way of calculating `variable_splits`. Set `&#39;quantiles&#39;` for percentiles.
            (default is `&#39;uniform&#39;`, which means uniform grid of points).
        variable_splits_with_obs: bool, optional
            Add variable values of `new_observation` data to the `variable_splits`
            (default is `True`).
        label : str, optional
            Name to appear in result and plots. Overrides default.
        processes : int, optional
            Number of parallel processes to use in calculations. Iterated over `variables`
            (default is `1`, which means no parallel computation).
        verbose : bool, optional
            Print tqdm progress bar (default is `True`).

        Returns
        -----------
        CeterisParibus class object
            Explanation object containing the main result attribute and the plot method.

        Notes
        --------
        - https://pbiecek.github.io/ema/ceterisParibus.html
        &#34;&#34;&#34;

        checks.check_data_again(self.data)

        types = (&#39;ceteris_paribus&#39;,)
        _type = checks.check_method_type(type, types)

        if _type == &#39;ceteris_paribus&#39;:
            _predict_profile = CeterisParibus(
                variables=variables,
                grid_points=grid_points,
                variable_splits=variable_splits,
                variable_splits_type=variable_splits_type,
                variable_splits_with_obs=variable_splits_with_obs,
                processes=processes
            )
        else:
            raise TypeError(&#34;Wrong type parameter.&#34;)

        _predict_profile.fit(self, new_observation, y, verbose)

        if label:
            _predict_profile.result[&#39;_label_&#39;] = label
            
        return _predict_profile

    def predict_surrogate(self,
                          new_observation,
                          type=&#39;lime&#39;,
                          **kwargs):
        &#34;&#34;&#34;Wrapper for surrogate model explanations

        This function uses the lime package to create the model explanation.
        See https://lime-ml.readthedocs.io/en/latest/lime.html#module-lime.lime_tabular

        Parameters
        -----------
        new_observation : pd.Series or np.ndarray (1d) or pd.DataFrame (1,p)
            An observation for which a prediction needs to be explained.
        type : {&#39;lime&#39;}
            Type of explanation method
            (default is `&#39;lime&#39;`, which uses the lime package to create an explanation).
        kwargs : dict
            Keyword arguments passed to the lime.lime_tabular.LimeTabularExplainer object
            and the LimeTabularExplainer.explain_instance method. Exceptions are:
            `training_data`, `mode`, `data_row` and `predict_fn`. Other parameters:
            https://lime-ml.readthedocs.io/en/latest/lime.html#module-lime.lime_tabular

        Returns
        -----------
        lime.explanation.Explanation
            Explanation object.

        Notes
        -----------
        - https://github.com/marcotcr/lime
        &#34;&#34;&#34;

        checks.check_data_again(self.data)

        if type == &#39;lime&#39;:
            _global_checks.global_check_import(&#39;lime&#39;, &#39;LIME explanations&#39;)
            _new_observation = checks.check_new_observation_lime(new_observation)
            _explanation = utils.create_lime_explanation(self, _new_observation, **kwargs)
        else:
            raise TypeError(&#34;Wrong &#39;type&#39; parameter.&#34;)

        return _explanation

    def model_performance(self,
                          model_type=None,
                          cutoff=0.5,
                          label=None):
        &#34;&#34;&#34;Calculate model-level model performance measures

        Parameters
        -----------
        model_type : {&#39;regression&#39;, &#39;classification&#39;, None}
            Model task type that is used to choose the proper performance measures
            (default is `None`, which means try to extract from the `model_type` attribute).
        cutoff : float, optional
            Cutoff for predictions in classification models. Needed for measures like
            recall, precision, acc, f1 (default is `0.5`).
        label : str, optional
            Name to appear in result and plots. Overrides default.

        Returns
        -----------
        ModelPerformance class object
            Explanation object containing the main result attribute and the plot method.

        Notes
        --------
        - https://pbiecek.github.io/ema/modelPerformance.html
        &#34;&#34;&#34;

        checks.check_data_again(self.data)
        checks.check_y_again(self.y)

        if model_type is None and self.model_type is None:
            raise TypeError(&#34;if self.model_type is None, then model_type must be not None&#34;)
        elif model_type is None:
            model_type = self.model_type

        _model_performance = ModelPerformance(
            model_type=model_type,
            cutoff=cutoff
        )
        _model_performance.fit(self)
        
        if label:
            _model_performance.result[&#39;label&#39;] = label

        return _model_performance

    def model_parts(self,
                    loss_function=None,
                    type=(&#39;variable_importance&#39;, &#39;ratio&#39;, &#39;difference&#39;, &#39;shap_wrapper&#39;),
                    N=1000,
                    B=10,
                    variables=None,
                    variable_groups=None,
                    keep_raw_permutations=True,
                    label=None,
                    processes=1,
                    random_state=None,
                    **kwargs):

        &#34;&#34;&#34;Calculate model-level variable importance

        Parameters
        -----------
        loss_function : {&#39;rmse&#39;, &#39;1-auc&#39;, &#39;mse&#39;, &#39;mae&#39;, &#39;mad&#39;} or function, optional
            If string, then such loss function will be used to assess variable importance
            (default is `&#39;rmse&#39;` or `&#39;1-auc&#39;`, depends on `model_type` attribute).
        type : {&#39;variable_importance&#39;, &#39;ratio&#39;, &#39;difference&#39;, &#39;shap_wrapper&#39;}
            Type of transformation that will be applied to dropout loss.
            (default is `&#39;variable_importance&#39;`, which is Permutational Variable Importance).
        N : int, optional
            Number of observations that will be sampled from the `data` attribute before
            the calculation of variable importance. `None` means all `data` (default is `1000`).
        B : int, optional
            Number of permutation rounds to perform on each variable (default is `10`).
        variables : array_like of str, optional
            Variables for which the importance will be calculated
            (default is `None`, which means all of the variables).
            NOTE: Ignored if `variable_groups` is not `None`.
        variable_groups : dict of lists, optional
            Group the variables to calculate their joint variable importance
            e.g. `{&#39;X&#39;: [&#39;x1&#39;, &#39;x2&#39;], &#39;Y&#39;: [&#39;y1&#39;, &#39;y2&#39;]}` (default is `None`).
        keep_raw_permutations: bool, optional
            Save results for all permutation rounds (default is `True`).
        label : str, optional
            Name to appear in result and plots. Overrides default.
        processes : int, optional
            Number of parallel processes to use in calculations. Iterated over `B`
            (default is `1`, which means no parallel computation).
        random_state : int, optional
            Set seed for random number generator (default is random seed).
        kwargs : dict
            Used only for &#39;shap_wrapper&#39;. Pass `shap_explainer_type` to specify, which
            Explainer shall be used: `{&#39;TreeExplainer&#39;, &#39;DeepExplainer&#39;, &#39;GradientExplainer&#39;,
            &#39;LinearExplainer&#39;, &#39;KernelExplainer&#39;}`.
            Also keyword arguments passed to one of the: `shap.TreeExplainer.shap_values,
            shap.DeepExplainer.shap_values, shap.GradientExplainer.shap_values,
            shap.LinearExplainer.shap_values, shap.KernelExplainer.shap_values`.
            See https://github.com/slundberg/shap

        Returns
        -----------
        VariableImportance or ShapWrapper class object
            Explanation object containing the main result attribute and the plot method.
            Object class, its attributes, and the plot method depend on the `type` parameter.

        Notes
        --------
        - https://pbiecek.github.io/ema/featureImportance.html
        - https://github.com/slundberg/shap
        &#34;&#34;&#34;

        checks.check_data_again(self.data)

        types = (&#39;variable_importance&#39;, &#39;ratio&#39;, &#39;difference&#39;, &#39;shap_wrapper&#39;)
        aliases = {&#39;permutational&#39;: &#39;variable_importance&#39;, &#39;feature_importance&#39;: &#39;variable_importance&#39;}
        _type = checks.check_method_type(type, types, aliases)

        loss_function = checks.check_method_loss_function(self, loss_function)

        if _type != &#39;shap_wrapper&#39;:
            checks.check_y_again(self.y)

            _model_parts = VariableImportance(
                loss_function=loss_function,
                type=_type,
                N=N,
                B=B,
                variables=variables,
                variable_groups=variable_groups,
                processes=processes,
                random_state=random_state,
                keep_raw_permutations=keep_raw_permutations,
            )
            _model_parts.fit(self)
            
            if label:
                _model_parts.result[&#39;label&#39;] = label
                 
        elif _type == &#39;shap_wrapper&#39;:
            _global_checks.global_check_import(&#39;shap&#39;, &#39;SHAP explanations&#39;)
            _model_parts = ShapWrapper(&#39;model_parts&#39;)
            if isinstance(N, int):
                if isinstance(random_state, int):
                    np.random.seed(random_state)
                N = min(N, self.data.shape[0])
                I = np.random.choice(np.arange(N), N, replace=False)
                _new_observation = self.data.iloc[I, :]
            else:
                _new_observation = self.data

            _model_parts.fit(self, _new_observation, **kwargs)
        else:
            raise TypeError(&#34;Wrong type parameter&#34;);

        return _model_parts

    def model_profile(self,
                      type=(&#39;partial&#39;, &#39;accumulated&#39;, &#39;conditional&#39;),
                      N=300,
                      variables=None,
                      variable_type=&#39;numerical&#39;,
                      groups=None,
                      span=0.25,
                      grid_points=101,
                      variable_splits=None,
                      variable_splits_type=&#39;uniform&#39;,
                      center=True,
                      label=None,
                      processes=1,
                      random_state=None,
                      verbose=True):

        &#34;&#34;&#34;Calculate model-level variable profiles as Partial or Accumulated Dependence

        Parameters
        -----------
        type : {&#39;partial&#39;, &#39;accumulated&#39;, &#39;conditional&#39;}
            Type of model profiles
            (default is `&#39;partial&#39;` for Partial Dependence Profiles).
        N : int, optional
            Number of observations that will be sampled from the `data` attribute before
            the calculation of variable profiles. `None` means all `data` (default is `300`).
        variables : str or array_like of str, optional
            Variables for which the profiles will be calculated
            (default is `None`, which means all of the variables).
        variable_type : {&#39;numerical&#39;, &#39;categorical&#39;}
            Calculate the profiles for numerical or categorical variables
            (default is `&#39;numerical&#39;`).
        groups : str or array_like of str, optional
            Names of categorical variables that will be used for profile grouping
            (default is `None`, which means no grouping).
        span : float, optional
            Smoothing coefficient used as sd for gaussian kernel (default is `0.25`).
        grid_points : int, optional
            Maximum number of points for profile calculations (default is `101`).
            NOTE: The final number of points may be lower than `grid_points`,
            e.g. if there is not enough unique values for a given variable.
        variable_splits : dict of lists, optional
            Split points for variables e.g. `{&#39;x&#39;: [0, 0.2, 0.5, 0.8, 1], &#39;y&#39;: [&#39;a&#39;, &#39;b&#39;]}`
            (default is `None`, which means that they will be distributed uniformly).
        variable_splits_type : {&#39;uniform&#39;, &#39;quantiles&#39;}, optional
            Way of calculating `variable_splits`. Set &#39;quantiles&#39; for percentiles.
            (default is `&#39;uniform&#39;`, which means uniform grid of points).
        center : bool, optional
            Theoretically Accumulated Profiles start at `0`, but are centered to compare
            them with Partial Dependence Profiles (default is `True`, which means center
            around the average `y_hat` calculated on the data sample).
        label : str, optional
            Name to appear in result and plots. Overrides default.
        processes : int, optional
            Number of parallel processes to use in calculations. Iterated over `variables`
            (default is `1`, which means no parallel computation).
        random_state : int, optional
            Set seed for random number generator (default is random seed).
        verbose : bool, optional
            Print tqdm progress bar (default is `True`).

        Returns
        -----------
        AggregatedProfiles class object
            Explanation object containing the main result attribute and the plot method.

        Notes
        --------
        - https://pbiecek.github.io/ema/partialDependenceProfiles.html
        - https://pbiecek.github.io/ema/accumulatedLocalProfiles.html
        &#34;&#34;&#34;

        checks.check_data_again(self.data)

        types = (&#39;partial&#39;, &#39;accumulated&#39;, &#39;conditional&#39;)
        aliases = {&#39;pdp&#39;: &#39;partial&#39;, &#39;ale&#39;: &#39;accumulated&#39;}
        _type = checks.check_method_type(type, types, aliases)

        _ceteris_paribus = CeterisParibus(
            grid_points=grid_points,
            variables=variables,
            variable_splits=variable_splits,
            variable_splits_type=variable_splits_type,
            processes=processes
        )

        if isinstance(N, int):
            if isinstance(random_state, int):
                np.random.seed(random_state)
            N = min(N, self.data.shape[0])
            I = np.random.choice(np.arange(N), N, replace=False)
            _y = self.y[I] if self.y is not None else self.y
            _new_observation = self.data.iloc[I, :]
        else:
            _y = self.y
            _new_observation = self.data

        _ceteris_paribus.fit(self, _new_observation, _y, verbose=verbose)

        _model_profile = AggregatedProfiles(
            type=_type,
            variables=variables,
            variable_type=variable_type,
            groups=groups,
            span=span,
            center=center,
            random_state=random_state
        )

        _model_profile.fit(_ceteris_paribus, verbose)

        if label:
            _model_profile.result[&#39;_label_&#39;] = label
                
        return _model_profile

    def model_diagnostics(self,
                          variables=None,
                          label=None):
        &#34;&#34;&#34;Calculate model-level residuals diagnostics

        Parameters
        -----------
        variables : str or array_like of str, optional
            Variables for which the data will be calculated
            (default is `None`, which means all of the variables).
        label : str, optional
            Name to appear in result and plots. Overrides default.

        Returns
        -----------
        ResidualDiagnostics class object
            Explanation object containing the main result attribute and the plot method.

        Notes
        --------
        - https://pbiecek.github.io/ema/residualDiagnostic.html
        &#34;&#34;&#34;

        checks.check_data_again(self.data)
        checks.check_y_again(self.y)

        _residual_diagnostics = ResidualDiagnostics(
            variables=variables
        )
        _residual_diagnostics.fit(self)

        if label:
            _residual_diagnostics.result[&#39;label&#39;] = label
            
        return _residual_diagnostics

    def model_surrogate(self,
                        type=(&#39;tree&#39;, &#39;linear&#39;),
                        max_vars=5,
                        max_depth=3,
                        **kwargs):
        &#34;&#34;&#34;Create a surrogate interpretable model from the black-box model

        This method uses the scikit-learn package to create a surrogate
        interpretable model (e.g. decision tree) from the black-box model.
        It aims to use the most important features and add a plot method to
        the model, so that it can be easily interpreted. See Notes section
        for references.

        Parameters
        -----------
        type : {&#39;tree&#39;, &#39;linear&#39;}
            Type of a surrogate model. This can be a decision tree or a linear model
            (default is `&#39;tree&#39;`).
        max_vars : int, optional
            Maximum number of variables that will be used in surrogate model training.
            These are the most important variables to the black-box model (default is `5`).
        max_depth : int, optional
            The maximum depth of the tree. If `None`, then nodes are expanded until all
            leaves are pure or until all leaves contain less than min_samples_split
            samples (default is `3` for interpretable plot).
        kwargs : dict
            Keyword arguments passed to one of the: `sklearn.tree.DecisionTreeClassifier,
            sklearn.tree.DecisionTreeRegressor, sklearn.linear_model.LogisticRegression,
            sklearn.linear_model.LinearRegression`


        Returns
        -----------
        One of: sklearn.tree.DecisionTreeClassifier, sklearn.tree.DecisionTreeRegressor, sklearn.linear_model.LogisticRegression, sklearn.linear_model.LinearRegression
        A surrogate model with additional:
            - `plot` method
            - `performance` attribute
            - `feature_names` attribute
            - `class_names` attribute

        Notes
        -----------
        - https://christophm.github.io/interpretable-ml-book/global.html
        - https://github.com/scikit-learn/scikit-learn
        &#34;&#34;&#34;

        _global_checks.global_check_import(&#39;scikit-learn&#39;, &#39;surrogate models&#39;)
        checks.check_data_again(self.data)

        types = (&#39;tree&#39;, &#39;linear&#39;)
        _type = checks.check_method_type(type, types)

        surrogate_model = utils.create_surrogate_model(explainer=self,
                                                       type=_type,
                                                       max_vars=max_vars,
                                                       max_depth=max_depth,
                                                       **kwargs)

        return surrogate_model

    def model_fairness(self,
                       protected,
                       privileged,
                       cutoff=0.5,
                       epsilon=0.8,
                       label=None,
                       **kwargs):
        &#34;&#34;&#34;Creates a model-level fairness explanation that enables bias detection

        This method returns a GroupFairnessClassification or a GroupFairnessRegression
        object depending of the type of predictor. They work as a wrapper of the
        protected attribute and the Explainer from which `y` and `y_hat`
        attributes were extracted. Along with an information about
        privileged subgroup (value in the `protected` parameter), those 3 vectors
        create triplet `(y, y_hat, protected)` which is a base for all further
        fairness calculations and visualizations.

        The GroupFairnessRegression should be treated as experimental tool.
        It was implemented according to Fairness Measures for Regression via
        Probabilistic Classification - Steinberg et al. (2020).

        Parameters
        -----------
        protected : np.ndarray (1d)
            Vector, preferably 1-dimensional np.ndarray containing strings,
            which denotes the membership to a subgroup. It doesn&#39;t have to be binary.
            It doesn&#39;t need to be in data. It is sometimes suggested not to use
            sensitive attributes in modelling, but still check model bias for them.
            NOTE: List and pd.Series are also supported; however, if provided,
            they will be transformed into a np.ndarray (1d) with dtype &#39;U&#39;.
        privileged : str
            Subgroup that is suspected to have the most privilege.
            It needs to be a string present in `protected`.
        cutoff : float or dict, optional
            Only for classification models.
            Threshold for probabilistic output of a classifier.
            It might be: a `float` - same for all subgroups from `protected`,
            or a `dict` - individually adjusted for each subgroup;
            must have values from `protected` as keys.
        epsilon : float
            Parameter defines acceptable fairness scores. The closer to `1` the
            more strict the verdict is. If the ratio of certain unprivileged
            and privileged subgroup is within the `(epsilon, 1/epsilon)` range,
            then there is no discrimination in this metric and for this subgroups
            (default is `0.8`).
        label : str, optional
            Name to appear in result and plots. Overrides default.
        kwargs : dict
            Keyword arguments. It supports `verbose`, which is a boolean
            value telling if additional output should be printed
            (`True`) or not (`False`, default).

        Returns
        -----------
        GroupFairnessClassification class object (a subclass of _FairnessObject)
            Explanation object containing the main result attribute and the plot method.
            
        It has the following main attributes:
            - result : `pd.DataFrame`
                Scaled `metric_scores`. The scaling is performed by
                dividing all metric scores by scores of the privileged subgroup.
            - metric_scores : `pd.DataFrame`
                Raw metric scores for each subgroup.
            - parity_loss : `pd.Series`
                It is a summarised `result`. From each metric (column) a logarithm
                is calculated, then the absolute value is taken and summarised.
                Therefore, for metric M:
                    `parity_loss` is a `sum(abs(log(M_i / M_privileged)))`
                        where `M_i` is the metric score for subgroup `i`.
            - label : `str`
                `label` attribute from the Explainer object.
                    Labels must be unique when plotting.
            - cutoff : `dict`
                A float value for each subgroup (key in dict).

        Notes
        -----------
        - Verma, S. &amp; Rubin, J. (2018) https://fairware.cs.umass.edu/papers/Verma.pdf
        - Zafar, M.B., et al. (2017) https://arxiv.org/pdf/1610.08452.pdf
        - Hardt, M., et al. (2016) https://arxiv.org/pdf/1610.02413.pdf
        - Steinberg, D., et al. (2020) https://arxiv.org/pdf/2001.06089.pdf
        &#34;&#34;&#34;

        if self.model_type == &#39;classification&#39;:
            fobject = GroupFairnessClassification(y=self.y,
                                                  y_hat=self.y_hat,
                                                  protected=protected,
                                                  privileged=privileged,
                                                  cutoff=cutoff,
                                                  epsilon=epsilon,
                                                  label=self.label,
                                                  **kwargs)

        elif self.model_type == &#39;regression&#39;:
            fobject = GroupFairnessRegression(y=self.y,
                                              y_hat=self.y_hat,
                                              protected=protected,
                                              privileged=privileged,
                                              epsilon=epsilon,
                                              label=self.label,
                                              **kwargs)

        else :
            raise ValueError(&#34;&#39;model_type&#39; must be either &#39;classification&#39; or &#39;regression&#39;&#34;)

        if label:
             fobject.label = label

        return fobject

    def dumps(self, *args, **kwargs):
        &#34;&#34;&#34;Return the pickled representation (bytes object) of the Explainer

        This method uses the pickle package. See
        https://docs.python.org/3/library/pickle.html#pickle.dumps

        NOTE: local functions and lambdas cannot be pickled.
        Attribute `residual_function` by default contains lambda; thus,
        if not provided by the user, it will be dropped before the dump.

        Parameters
        -----------
        args : dict
            Positional arguments passed to the pickle.dumps function.
        kwargs : dict
            Keyword arguments passed to the pickle.dumps function.

        Returns
        -----------
        bytes object
        &#34;&#34;&#34;

        from copy import deepcopy
        to_dump = deepcopy(self)
        to_dump = checks.check_if_local_and_lambda(to_dump)

        import pickle
        return pickle.dumps(to_dump, *args, **kwargs)

    def dump(self, file, *args, **kwargs):
        &#34;&#34;&#34;Write the pickled representation of the Explainer to the file (pickle)

        This method uses the pickle package. See
        https://docs.python.org/3/library/pickle.html#pickle.dump

        NOTE: local functions and lambdas cannot be pickled.
        Attribute `residual_function` by default contains lambda; thus,
        if not provided by the user, it will be dropped before the dump.

        Parameters
        -----------
        file : ...
            A file object opened for binary writing, or an io.BytesIO instance.
        args : dict
            Positional arguments passed to the pickle.dump function.
        kwargs : dict
            Keyword arguments passed to the pickle.dump function.
        &#34;&#34;&#34;

        from copy import deepcopy
        to_dump = deepcopy(self)
        to_dump = checks.check_if_local_and_lambda(to_dump)

        import pickle
        return pickle.dump(to_dump, file, *args, **kwargs)

    @staticmethod
    def loads(data, use_defaults=True, *args, **kwargs):
        &#34;&#34;&#34;Load the Explainer from the pickled representation (bytes object)

        This method uses the pickle package. See
        https://docs.python.org/3/library/pickle.html#pickle.loads

        NOTE: local functions and lambdas cannot be pickled.
        If `use_defaults` is set to `True`, then dropped functions are set to defaults.

        Parameters
        -----------
        data : bytes object
            Binary representation of the Explainer.
        use_defaults : bool
            Replace empty `predict_function` and `residual_function` with default
            values like in Explainer initialization (default is `True`).
        args : dict
            Positional arguments passed to the pickle.loads function.
        kwargs : dict
            Keyword arguments passed to the pickle.loads function.

        Returns
        -----------
        Explainer object
        &#34;&#34;&#34;

        import pickle
        exp = pickle.loads(data, *args, **kwargs)

        if use_defaults:
            exp = checks.check_if_empty_fields(exp)

        return exp

    @staticmethod
    def load(file, use_defaults=True, *args, **kwargs):
        &#34;&#34;&#34;Read the pickled representation of the Explainer from the file (pickle)

        This method uses the pickle package. See
        https://docs.python.org/3/library/pickle.html#pickle.load

        NOTE: local functions and lambdas cannot be pickled.
        If `use_defaults` is set to `True`, then dropped functions are set to defaults.

        Parameters
        -----------
        file : ...
            A binary file object opened for reading, or an io.BytesIO object.
        use_defaults : bool
            Replace empty `predict_function` and `residual_function` with default
            values like in Explainer initialization (default is `True`).
        args : dict
            Positional arguments passed to the pickle.load function.
        kwargs : dict
            Keyword arguments passed to the pickle.load function.

        Returns
        -----------
        Explainer object
        &#34;&#34;&#34;

        import pickle
        exp = pickle.load(file, *args, **kwargs)

        if use_defaults:
            exp = checks.check_if_empty_fields(exp)

        return exp</code></pre>
</details>
<h3>Static methods</h3>
<dl>
<dt id="dalex.Explainer.load"><code class="name flex">
<span>def <span class="ident">load</span></span>(<span>file, use_defaults=True, *args, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Read the pickled representation of the Explainer from the file (pickle)</p>
<p>This method uses the pickle package. See
<a href="https://docs.python.org/3/library/pickle.html#pickle.load">https://docs.python.org/3/library/pickle.html#pickle.load</a></p>
<p>NOTE: local functions and lambdas cannot be pickled.
If <code>use_defaults</code> is set to <code>True</code>, then dropped functions are set to defaults.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt>file : &hellip;</dt>
<dt>A binary file object opened for reading, or an io.BytesIO object.</dt>
<dt><strong><code>use_defaults</code></strong> :&ensp;<code>bool</code></dt>
<dd>Replace empty <code>predict_function</code> and <code>residual_function</code> with default
values like in Explainer initialization (default is <code>True</code>).</dd>
<dt><strong><code>args</code></strong> :&ensp;<code>dict</code></dt>
<dd>Positional arguments passed to the pickle.load function.</dd>
<dt><strong><code>kwargs</code></strong> :&ensp;<code>dict</code></dt>
<dd>Keyword arguments passed to the pickle.load function.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="dalex.Explainer" href="#dalex.Explainer">Explainer</a> object</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/ModelOriented/DALEX/blob/2441c55e88b740295d874c46c88f5edce8139e7f/dalex\_explainer\object.py#L1023-L1056" class="git-link">Browse git</a>
</summary>
<pre><code class="python">@staticmethod
def load(file, use_defaults=True, *args, **kwargs):
    &#34;&#34;&#34;Read the pickled representation of the Explainer from the file (pickle)

    This method uses the pickle package. See
    https://docs.python.org/3/library/pickle.html#pickle.load

    NOTE: local functions and lambdas cannot be pickled.
    If `use_defaults` is set to `True`, then dropped functions are set to defaults.

    Parameters
    -----------
    file : ...
        A binary file object opened for reading, or an io.BytesIO object.
    use_defaults : bool
        Replace empty `predict_function` and `residual_function` with default
        values like in Explainer initialization (default is `True`).
    args : dict
        Positional arguments passed to the pickle.load function.
    kwargs : dict
        Keyword arguments passed to the pickle.load function.

    Returns
    -----------
    Explainer object
    &#34;&#34;&#34;

    import pickle
    exp = pickle.load(file, *args, **kwargs)

    if use_defaults:
        exp = checks.check_if_empty_fields(exp)

    return exp</code></pre>
</details>
</dd>
<dt id="dalex.Explainer.loads"><code class="name flex">
<span>def <span class="ident">loads</span></span>(<span>data, use_defaults=True, *args, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Load the Explainer from the pickled representation (bytes object)</p>
<p>This method uses the pickle package. See
<a href="https://docs.python.org/3/library/pickle.html#pickle.loads">https://docs.python.org/3/library/pickle.html#pickle.loads</a></p>
<p>NOTE: local functions and lambdas cannot be pickled.
If <code>use_defaults</code> is set to <code>True</code>, then dropped functions are set to defaults.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>data</code></strong> :&ensp;<code>bytes object</code></dt>
<dd>Binary representation of the Explainer.</dd>
<dt><strong><code>use_defaults</code></strong> :&ensp;<code>bool</code></dt>
<dd>Replace empty <code>predict_function</code> and <code>residual_function</code> with default
values like in Explainer initialization (default is <code>True</code>).</dd>
<dt><strong><code>args</code></strong> :&ensp;<code>dict</code></dt>
<dd>Positional arguments passed to the pickle.loads function.</dd>
<dt><strong><code>kwargs</code></strong> :&ensp;<code>dict</code></dt>
<dd>Keyword arguments passed to the pickle.loads function.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="dalex.Explainer" href="#dalex.Explainer">Explainer</a> object</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/ModelOriented/DALEX/blob/2441c55e88b740295d874c46c88f5edce8139e7f/dalex\_explainer\object.py#L988-L1021" class="git-link">Browse git</a>
</summary>
<pre><code class="python">@staticmethod
def loads(data, use_defaults=True, *args, **kwargs):
    &#34;&#34;&#34;Load the Explainer from the pickled representation (bytes object)

    This method uses the pickle package. See
    https://docs.python.org/3/library/pickle.html#pickle.loads

    NOTE: local functions and lambdas cannot be pickled.
    If `use_defaults` is set to `True`, then dropped functions are set to defaults.

    Parameters
    -----------
    data : bytes object
        Binary representation of the Explainer.
    use_defaults : bool
        Replace empty `predict_function` and `residual_function` with default
        values like in Explainer initialization (default is `True`).
    args : dict
        Positional arguments passed to the pickle.loads function.
    kwargs : dict
        Keyword arguments passed to the pickle.loads function.

    Returns
    -----------
    Explainer object
    &#34;&#34;&#34;

    import pickle
    exp = pickle.loads(data, *args, **kwargs)

    if use_defaults:
        exp = checks.check_if_empty_fields(exp)

    return exp</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="dalex.Explainer.dump"><code class="name flex">
<span>def <span class="ident">dump</span></span>(<span>self, file, *args, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Write the pickled representation of the Explainer to the file (pickle)</p>
<p>This method uses the pickle package. See
<a href="https://docs.python.org/3/library/pickle.html#pickle.dump">https://docs.python.org/3/library/pickle.html#pickle.dump</a></p>
<p>NOTE: local functions and lambdas cannot be pickled.
Attribute <code>residual_function</code> by default contains lambda; thus,
if not provided by the user, it will be dropped before the dump.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt>file : &hellip;</dt>
<dt>A file object opened for binary writing, or an io.BytesIO instance.</dt>
<dt><strong><code>args</code></strong> :&ensp;<code>dict</code></dt>
<dd>Positional arguments passed to the pickle.dump function.</dd>
<dt><strong><code>kwargs</code></strong> :&ensp;<code>dict</code></dt>
<dd>Keyword arguments passed to the pickle.dump function.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/ModelOriented/DALEX/blob/2441c55e88b740295d874c46c88f5edce8139e7f/dalex\_explainer\object.py#L961-L986" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def dump(self, file, *args, **kwargs):
    &#34;&#34;&#34;Write the pickled representation of the Explainer to the file (pickle)

    This method uses the pickle package. See
    https://docs.python.org/3/library/pickle.html#pickle.dump

    NOTE: local functions and lambdas cannot be pickled.
    Attribute `residual_function` by default contains lambda; thus,
    if not provided by the user, it will be dropped before the dump.

    Parameters
    -----------
    file : ...
        A file object opened for binary writing, or an io.BytesIO instance.
    args : dict
        Positional arguments passed to the pickle.dump function.
    kwargs : dict
        Keyword arguments passed to the pickle.dump function.
    &#34;&#34;&#34;

    from copy import deepcopy
    to_dump = deepcopy(self)
    to_dump = checks.check_if_local_and_lambda(to_dump)

    import pickle
    return pickle.dump(to_dump, file, *args, **kwargs)</code></pre>
</details>
</dd>
<dt id="dalex.Explainer.dumps"><code class="name flex">
<span>def <span class="ident">dumps</span></span>(<span>self, *args, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Return the pickled representation (bytes object) of the Explainer</p>
<p>This method uses the pickle package. See
<a href="https://docs.python.org/3/library/pickle.html#pickle.dumps">https://docs.python.org/3/library/pickle.html#pickle.dumps</a></p>
<p>NOTE: local functions and lambdas cannot be pickled.
Attribute <code>residual_function</code> by default contains lambda; thus,
if not provided by the user, it will be dropped before the dump.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>args</code></strong> :&ensp;<code>dict</code></dt>
<dd>Positional arguments passed to the pickle.dumps function.</dd>
<dt><strong><code>kwargs</code></strong> :&ensp;<code>dict</code></dt>
<dd>Keyword arguments passed to the pickle.dumps function.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>bytes object</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/ModelOriented/DALEX/blob/2441c55e88b740295d874c46c88f5edce8139e7f/dalex\_explainer\object.py#L932-L959" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def dumps(self, *args, **kwargs):
    &#34;&#34;&#34;Return the pickled representation (bytes object) of the Explainer

    This method uses the pickle package. See
    https://docs.python.org/3/library/pickle.html#pickle.dumps

    NOTE: local functions and lambdas cannot be pickled.
    Attribute `residual_function` by default contains lambda; thus,
    if not provided by the user, it will be dropped before the dump.

    Parameters
    -----------
    args : dict
        Positional arguments passed to the pickle.dumps function.
    kwargs : dict
        Keyword arguments passed to the pickle.dumps function.

    Returns
    -----------
    bytes object
    &#34;&#34;&#34;

    from copy import deepcopy
    to_dump = deepcopy(self)
    to_dump = checks.check_if_local_and_lambda(to_dump)

    import pickle
    return pickle.dumps(to_dump, *args, **kwargs)</code></pre>
</details>
</dd>
<dt id="dalex.Explainer.model_diagnostics"><code class="name flex">
<span>def <span class="ident">model_diagnostics</span></span>(<span>self, variables=None, label=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Calculate model-level residuals diagnostics</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>variables</code></strong> :&ensp;<code>str</code> or <code>array_like</code> of <code>str</code>, optional</dt>
<dd>Variables for which the data will be calculated
(default is <code>None</code>, which means all of the variables).</dd>
<dt><strong><code>label</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>Name to appear in result and plots. Overrides default.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>ResidualDiagnostics class object</code></dt>
<dd>Explanation object containing the main result attribute and the plot method.</dd>
</dl>
<h2 id="notes">Notes</h2>
<ul>
<li><a href="https://pbiecek.github.io/ema/residualDiagnostic.html">https://pbiecek.github.io/ema/residualDiagnostic.html</a></li>
</ul></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/ModelOriented/DALEX/blob/2441c55e88b740295d874c46c88f5edce8139e7f/dalex\_explainer\object.py#L726-L760" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def model_diagnostics(self,
                      variables=None,
                      label=None):
    &#34;&#34;&#34;Calculate model-level residuals diagnostics

    Parameters
    -----------
    variables : str or array_like of str, optional
        Variables for which the data will be calculated
        (default is `None`, which means all of the variables).
    label : str, optional
        Name to appear in result and plots. Overrides default.

    Returns
    -----------
    ResidualDiagnostics class object
        Explanation object containing the main result attribute and the plot method.

    Notes
    --------
    - https://pbiecek.github.io/ema/residualDiagnostic.html
    &#34;&#34;&#34;

    checks.check_data_again(self.data)
    checks.check_y_again(self.y)

    _residual_diagnostics = ResidualDiagnostics(
        variables=variables
    )
    _residual_diagnostics.fit(self)

    if label:
        _residual_diagnostics.result[&#39;label&#39;] = label
        
    return _residual_diagnostics</code></pre>
</details>
</dd>
<dt id="dalex.Explainer.model_fairness"><code class="name flex">
<span>def <span class="ident">model_fairness</span></span>(<span>self, protected, privileged, cutoff=0.5, epsilon=0.8, label=None, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Creates a model-level fairness explanation that enables bias detection</p>
<p>This method returns a GroupFairnessClassification or a GroupFairnessRegression
object depending of the type of predictor. They work as a wrapper of the
protected attribute and the Explainer from which <code>y</code> and <code>y_hat</code>
attributes were extracted. Along with an information about
privileged subgroup (value in the <code>protected</code> parameter), those 3 vectors
create triplet <code>(y, y_hat, protected)</code> which is a base for all further
fairness calculations and visualizations.</p>
<p>The GroupFairnessRegression should be treated as experimental tool.
It was implemented according to Fairness Measures for Regression via
Probabilistic Classification - Steinberg et al. (2020).</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>protected</code></strong> :&ensp;<code>np.ndarray (1d)</code></dt>
<dd>Vector, preferably 1-dimensional np.ndarray containing strings,
which denotes the membership to a subgroup. It doesn't have to be binary.
It doesn't need to be in data. It is sometimes suggested not to use
sensitive attributes in modelling, but still check model bias for them.
NOTE: List and pd.Series are also supported; however, if provided,
they will be transformed into a np.ndarray (1d) with dtype 'U'.</dd>
<dt><strong><code>privileged</code></strong> :&ensp;<code>str</code></dt>
<dd>Subgroup that is suspected to have the most privilege.
It needs to be a string present in <code>protected</code>.</dd>
<dt><strong><code>cutoff</code></strong> :&ensp;<code>float</code> or <code>dict</code>, optional</dt>
<dd>Only for classification models.
Threshold for probabilistic output of a classifier.
It might be: a <code>float</code> - same for all subgroups from <code>protected</code>,
or a <code>dict</code> - individually adjusted for each subgroup;
must have values from <code>protected</code> as keys.</dd>
<dt><strong><code>epsilon</code></strong> :&ensp;<code>float</code></dt>
<dd>Parameter defines acceptable fairness scores. The closer to <code>1</code> the
more strict the verdict is. If the ratio of certain unprivileged
and privileged subgroup is within the <code>(epsilon, 1/epsilon)</code> range,
then there is no discrimination in this metric and for this subgroups
(default is <code>0.8</code>).</dd>
<dt><strong><code>label</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>Name to appear in result and plots. Overrides default.</dd>
<dt><strong><code>kwargs</code></strong> :&ensp;<code>dict</code></dt>
<dd>Keyword arguments. It supports <code>verbose</code>, which is a boolean
value telling if additional output should be printed
(<code>True</code>) or not (<code>False</code>, default).</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>GroupFairnessClassification class object (a subclass</code> of <code>_FairnessObject)</code></dt>
<dd>Explanation object containing the main result attribute and the plot method.</dd>
<dt><code>It has the following main attributes:</code></dt>
<dd>
<ul>
<li>result : <code>pd.DataFrame</code>
Scaled <code>metric_scores</code>. The scaling is performed by
dividing all metric scores by scores of the privileged subgroup.</li>
<li>metric_scores : <code>pd.DataFrame</code>
Raw metric scores for each subgroup.</li>
<li>parity_loss : <code>pd.Series</code>
It is a summarised <code>result</code>. From each metric (column) a logarithm
is calculated, then the absolute value is taken and summarised.
Therefore, for metric M:
<code>parity_loss</code> is a <code>sum(abs(log(M_i / M_privileged)))</code>
where <code>M_i</code> is the metric score for subgroup <code>i</code>.</li>
<li>label : <code>str</code>
<code>label</code> attribute from the Explainer object.
Labels must be unique when plotting.</li>
<li>cutoff : <code>dict</code>
A float value for each subgroup (key in dict).</li>
</ul>
</dd>
</dl>
<h2 id="notes">Notes</h2>
<ul>
<li>Verma, S. &amp; Rubin, J. (2018) <a href="https://fairware.cs.umass.edu/papers/Verma.pdf">https://fairware.cs.umass.edu/papers/Verma.pdf</a></li>
<li>Zafar, M.B., et al. (2017) <a href="https://arxiv.org/pdf/1610.08452.pdf">https://arxiv.org/pdf/1610.08452.pdf</a></li>
<li>Hardt, M., et al. (2016) <a href="https://arxiv.org/pdf/1610.02413.pdf">https://arxiv.org/pdf/1610.02413.pdf</a></li>
<li>Steinberg, D., et al. (2020) <a href="https://arxiv.org/pdf/2001.06089.pdf">https://arxiv.org/pdf/2001.06089.pdf</a></li>
</ul></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/ModelOriented/DALEX/blob/2441c55e88b740295d874c46c88f5edce8139e7f/dalex\_explainer\object.py#L822-L930" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def model_fairness(self,
                   protected,
                   privileged,
                   cutoff=0.5,
                   epsilon=0.8,
                   label=None,
                   **kwargs):
    &#34;&#34;&#34;Creates a model-level fairness explanation that enables bias detection

    This method returns a GroupFairnessClassification or a GroupFairnessRegression
    object depending of the type of predictor. They work as a wrapper of the
    protected attribute and the Explainer from which `y` and `y_hat`
    attributes were extracted. Along with an information about
    privileged subgroup (value in the `protected` parameter), those 3 vectors
    create triplet `(y, y_hat, protected)` which is a base for all further
    fairness calculations and visualizations.

    The GroupFairnessRegression should be treated as experimental tool.
    It was implemented according to Fairness Measures for Regression via
    Probabilistic Classification - Steinberg et al. (2020).

    Parameters
    -----------
    protected : np.ndarray (1d)
        Vector, preferably 1-dimensional np.ndarray containing strings,
        which denotes the membership to a subgroup. It doesn&#39;t have to be binary.
        It doesn&#39;t need to be in data. It is sometimes suggested not to use
        sensitive attributes in modelling, but still check model bias for them.
        NOTE: List and pd.Series are also supported; however, if provided,
        they will be transformed into a np.ndarray (1d) with dtype &#39;U&#39;.
    privileged : str
        Subgroup that is suspected to have the most privilege.
        It needs to be a string present in `protected`.
    cutoff : float or dict, optional
        Only for classification models.
        Threshold for probabilistic output of a classifier.
        It might be: a `float` - same for all subgroups from `protected`,
        or a `dict` - individually adjusted for each subgroup;
        must have values from `protected` as keys.
    epsilon : float
        Parameter defines acceptable fairness scores. The closer to `1` the
        more strict the verdict is. If the ratio of certain unprivileged
        and privileged subgroup is within the `(epsilon, 1/epsilon)` range,
        then there is no discrimination in this metric and for this subgroups
        (default is `0.8`).
    label : str, optional
        Name to appear in result and plots. Overrides default.
    kwargs : dict
        Keyword arguments. It supports `verbose`, which is a boolean
        value telling if additional output should be printed
        (`True`) or not (`False`, default).

    Returns
    -----------
    GroupFairnessClassification class object (a subclass of _FairnessObject)
        Explanation object containing the main result attribute and the plot method.
        
    It has the following main attributes:
        - result : `pd.DataFrame`
            Scaled `metric_scores`. The scaling is performed by
            dividing all metric scores by scores of the privileged subgroup.
        - metric_scores : `pd.DataFrame`
            Raw metric scores for each subgroup.
        - parity_loss : `pd.Series`
            It is a summarised `result`. From each metric (column) a logarithm
            is calculated, then the absolute value is taken and summarised.
            Therefore, for metric M:
                `parity_loss` is a `sum(abs(log(M_i / M_privileged)))`
                    where `M_i` is the metric score for subgroup `i`.
        - label : `str`
            `label` attribute from the Explainer object.
                Labels must be unique when plotting.
        - cutoff : `dict`
            A float value for each subgroup (key in dict).

    Notes
    -----------
    - Verma, S. &amp; Rubin, J. (2018) https://fairware.cs.umass.edu/papers/Verma.pdf
    - Zafar, M.B., et al. (2017) https://arxiv.org/pdf/1610.08452.pdf
    - Hardt, M., et al. (2016) https://arxiv.org/pdf/1610.02413.pdf
    - Steinberg, D., et al. (2020) https://arxiv.org/pdf/2001.06089.pdf
    &#34;&#34;&#34;

    if self.model_type == &#39;classification&#39;:
        fobject = GroupFairnessClassification(y=self.y,
                                              y_hat=self.y_hat,
                                              protected=protected,
                                              privileged=privileged,
                                              cutoff=cutoff,
                                              epsilon=epsilon,
                                              label=self.label,
                                              **kwargs)

    elif self.model_type == &#39;regression&#39;:
        fobject = GroupFairnessRegression(y=self.y,
                                          y_hat=self.y_hat,
                                          protected=protected,
                                          privileged=privileged,
                                          epsilon=epsilon,
                                          label=self.label,
                                          **kwargs)

    else :
        raise ValueError(&#34;&#39;model_type&#39; must be either &#39;classification&#39; or &#39;regression&#39;&#34;)

    if label:
         fobject.label = label

    return fobject</code></pre>
</details>
</dd>
<dt id="dalex.Explainer.model_parts"><code class="name flex">
<span>def <span class="ident">model_parts</span></span>(<span>self, loss_function=None, type=('variable_importance', 'ratio', 'difference', 'shap_wrapper'), N=1000, B=10, variables=None, variable_groups=None, keep_raw_permutations=True, label=None, processes=1, random_state=None, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Calculate model-level variable importance</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>loss_function</code></strong> :&ensp;<code>{'rmse', '1-auc', 'mse', 'mae', 'mad'}</code> or <code>function</code>, optional</dt>
<dd>If string, then such loss function will be used to assess variable importance
(default is <code>'rmse'</code> or <code>'1-auc'</code>, depends on <code>model_type</code> attribute).</dd>
<dt><strong><code>type</code></strong> :&ensp;<code>{'variable_importance', 'ratio', 'difference', 'shap_wrapper'}</code></dt>
<dd>Type of transformation that will be applied to dropout loss.
(default is <code>'variable_importance'</code>, which is Permutational Variable Importance).</dd>
<dt><strong><code>N</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>Number of observations that will be sampled from the <code>data</code> attribute before
the calculation of variable importance. <code>None</code> means all <code>data</code> (default is <code>1000</code>).</dd>
<dt><strong><code>B</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>Number of permutation rounds to perform on each variable (default is <code>10</code>).</dd>
<dt><strong><code>variables</code></strong> :&ensp;<code>array_like</code> of <code>str</code>, optional</dt>
<dd>Variables for which the importance will be calculated
(default is <code>None</code>, which means all of the variables).
NOTE: Ignored if <code>variable_groups</code> is not <code>None</code>.</dd>
<dt><strong><code>variable_groups</code></strong> :&ensp;<code>dict</code> of <code>lists</code>, optional</dt>
<dd>Group the variables to calculate their joint variable importance
e.g. <code>{'X': ['x1', 'x2'], 'Y': ['y1', 'y2']}</code> (default is <code>None</code>).</dd>
<dt><strong><code>keep_raw_permutations</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>Save results for all permutation rounds (default is <code>True</code>).</dd>
<dt><strong><code>label</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>Name to appear in result and plots. Overrides default.</dd>
<dt><strong><code>processes</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>Number of parallel processes to use in calculations. Iterated over <code>B</code>
(default is <code>1</code>, which means no parallel computation).</dd>
<dt><strong><code>random_state</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>Set seed for random number generator (default is random seed).</dd>
<dt><strong><code>kwargs</code></strong> :&ensp;<code>dict</code></dt>
<dd>Used only for 'shap_wrapper'. Pass <code>shap_explainer_type</code> to specify, which
Explainer shall be used: <code>{'TreeExplainer', 'DeepExplainer', 'GradientExplainer',
'LinearExplainer', 'KernelExplainer'}</code>.
Also keyword arguments passed to one of the: <code>shap.TreeExplainer.shap_values,
shap.DeepExplainer.shap_values, shap.GradientExplainer.shap_values,
shap.LinearExplainer.shap_values, shap.KernelExplainer.shap_values</code>.
See <a href="https://github.com/slundberg/shap">https://github.com/slundberg/shap</a></dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>VariableImportance</code> or <code>ShapWrapper class object</code></dt>
<dd>Explanation object containing the main result attribute and the plot method.
Object class, its attributes, and the plot method depend on the <code>type</code> parameter.</dd>
</dl>
<h2 id="notes">Notes</h2>
<ul>
<li><a href="https://pbiecek.github.io/ema/featureImportance.html">https://pbiecek.github.io/ema/featureImportance.html</a></li>
<li><a href="https://github.com/slundberg/shap">https://github.com/slundberg/shap</a></li>
</ul></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/ModelOriented/DALEX/blob/2441c55e88b740295d874c46c88f5edce8139e7f/dalex\_explainer\object.py#L500-L608" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def model_parts(self,
                loss_function=None,
                type=(&#39;variable_importance&#39;, &#39;ratio&#39;, &#39;difference&#39;, &#39;shap_wrapper&#39;),
                N=1000,
                B=10,
                variables=None,
                variable_groups=None,
                keep_raw_permutations=True,
                label=None,
                processes=1,
                random_state=None,
                **kwargs):

    &#34;&#34;&#34;Calculate model-level variable importance

    Parameters
    -----------
    loss_function : {&#39;rmse&#39;, &#39;1-auc&#39;, &#39;mse&#39;, &#39;mae&#39;, &#39;mad&#39;} or function, optional
        If string, then such loss function will be used to assess variable importance
        (default is `&#39;rmse&#39;` or `&#39;1-auc&#39;`, depends on `model_type` attribute).
    type : {&#39;variable_importance&#39;, &#39;ratio&#39;, &#39;difference&#39;, &#39;shap_wrapper&#39;}
        Type of transformation that will be applied to dropout loss.
        (default is `&#39;variable_importance&#39;`, which is Permutational Variable Importance).
    N : int, optional
        Number of observations that will be sampled from the `data` attribute before
        the calculation of variable importance. `None` means all `data` (default is `1000`).
    B : int, optional
        Number of permutation rounds to perform on each variable (default is `10`).
    variables : array_like of str, optional
        Variables for which the importance will be calculated
        (default is `None`, which means all of the variables).
        NOTE: Ignored if `variable_groups` is not `None`.
    variable_groups : dict of lists, optional
        Group the variables to calculate their joint variable importance
        e.g. `{&#39;X&#39;: [&#39;x1&#39;, &#39;x2&#39;], &#39;Y&#39;: [&#39;y1&#39;, &#39;y2&#39;]}` (default is `None`).
    keep_raw_permutations: bool, optional
        Save results for all permutation rounds (default is `True`).
    label : str, optional
        Name to appear in result and plots. Overrides default.
    processes : int, optional
        Number of parallel processes to use in calculations. Iterated over `B`
        (default is `1`, which means no parallel computation).
    random_state : int, optional
        Set seed for random number generator (default is random seed).
    kwargs : dict
        Used only for &#39;shap_wrapper&#39;. Pass `shap_explainer_type` to specify, which
        Explainer shall be used: `{&#39;TreeExplainer&#39;, &#39;DeepExplainer&#39;, &#39;GradientExplainer&#39;,
        &#39;LinearExplainer&#39;, &#39;KernelExplainer&#39;}`.
        Also keyword arguments passed to one of the: `shap.TreeExplainer.shap_values,
        shap.DeepExplainer.shap_values, shap.GradientExplainer.shap_values,
        shap.LinearExplainer.shap_values, shap.KernelExplainer.shap_values`.
        See https://github.com/slundberg/shap

    Returns
    -----------
    VariableImportance or ShapWrapper class object
        Explanation object containing the main result attribute and the plot method.
        Object class, its attributes, and the plot method depend on the `type` parameter.

    Notes
    --------
    - https://pbiecek.github.io/ema/featureImportance.html
    - https://github.com/slundberg/shap
    &#34;&#34;&#34;

    checks.check_data_again(self.data)

    types = (&#39;variable_importance&#39;, &#39;ratio&#39;, &#39;difference&#39;, &#39;shap_wrapper&#39;)
    aliases = {&#39;permutational&#39;: &#39;variable_importance&#39;, &#39;feature_importance&#39;: &#39;variable_importance&#39;}
    _type = checks.check_method_type(type, types, aliases)

    loss_function = checks.check_method_loss_function(self, loss_function)

    if _type != &#39;shap_wrapper&#39;:
        checks.check_y_again(self.y)

        _model_parts = VariableImportance(
            loss_function=loss_function,
            type=_type,
            N=N,
            B=B,
            variables=variables,
            variable_groups=variable_groups,
            processes=processes,
            random_state=random_state,
            keep_raw_permutations=keep_raw_permutations,
        )
        _model_parts.fit(self)
        
        if label:
            _model_parts.result[&#39;label&#39;] = label
             
    elif _type == &#39;shap_wrapper&#39;:
        _global_checks.global_check_import(&#39;shap&#39;, &#39;SHAP explanations&#39;)
        _model_parts = ShapWrapper(&#39;model_parts&#39;)
        if isinstance(N, int):
            if isinstance(random_state, int):
                np.random.seed(random_state)
            N = min(N, self.data.shape[0])
            I = np.random.choice(np.arange(N), N, replace=False)
            _new_observation = self.data.iloc[I, :]
        else:
            _new_observation = self.data

        _model_parts.fit(self, _new_observation, **kwargs)
    else:
        raise TypeError(&#34;Wrong type parameter&#34;);

    return _model_parts</code></pre>
</details>
</dd>
<dt id="dalex.Explainer.model_performance"><code class="name flex">
<span>def <span class="ident">model_performance</span></span>(<span>self, model_type=None, cutoff=0.5, label=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Calculate model-level model performance measures</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>model_type</code></strong> :&ensp;<code>{'regression', 'classification', None}</code></dt>
<dd>Model task type that is used to choose the proper performance measures
(default is <code>None</code>, which means try to extract from the <code>model_type</code> attribute).</dd>
<dt><strong><code>cutoff</code></strong> :&ensp;<code>float</code>, optional</dt>
<dd>Cutoff for predictions in classification models. Needed for measures like
recall, precision, acc, f1 (default is <code>0.5</code>).</dd>
<dt><strong><code>label</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>Name to appear in result and plots. Overrides default.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>ModelPerformance class object</code></dt>
<dd>Explanation object containing the main result attribute and the plot method.</dd>
</dl>
<h2 id="notes">Notes</h2>
<ul>
<li><a href="https://pbiecek.github.io/ema/modelPerformance.html">https://pbiecek.github.io/ema/modelPerformance.html</a></li>
</ul></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/ModelOriented/DALEX/blob/2441c55e88b740295d874c46c88f5edce8139e7f/dalex\_explainer\object.py#L454-L498" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def model_performance(self,
                      model_type=None,
                      cutoff=0.5,
                      label=None):
    &#34;&#34;&#34;Calculate model-level model performance measures

    Parameters
    -----------
    model_type : {&#39;regression&#39;, &#39;classification&#39;, None}
        Model task type that is used to choose the proper performance measures
        (default is `None`, which means try to extract from the `model_type` attribute).
    cutoff : float, optional
        Cutoff for predictions in classification models. Needed for measures like
        recall, precision, acc, f1 (default is `0.5`).
    label : str, optional
        Name to appear in result and plots. Overrides default.

    Returns
    -----------
    ModelPerformance class object
        Explanation object containing the main result attribute and the plot method.

    Notes
    --------
    - https://pbiecek.github.io/ema/modelPerformance.html
    &#34;&#34;&#34;

    checks.check_data_again(self.data)
    checks.check_y_again(self.y)

    if model_type is None and self.model_type is None:
        raise TypeError(&#34;if self.model_type is None, then model_type must be not None&#34;)
    elif model_type is None:
        model_type = self.model_type

    _model_performance = ModelPerformance(
        model_type=model_type,
        cutoff=cutoff
    )
    _model_performance.fit(self)
    
    if label:
        _model_performance.result[&#39;label&#39;] = label

    return _model_performance</code></pre>
</details>
</dd>
<dt id="dalex.Explainer.model_profile"><code class="name flex">
<span>def <span class="ident">model_profile</span></span>(<span>self, type=('partial', 'accumulated', 'conditional'), N=300, variables=None, variable_type='numerical', groups=None, span=0.25, grid_points=101, variable_splits=None, variable_splits_type='uniform', center=True, label=None, processes=1, random_state=None, verbose=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Calculate model-level variable profiles as Partial or Accumulated Dependence</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>type</code></strong> :&ensp;<code>{'partial', 'accumulated', 'conditional'}</code></dt>
<dd>Type of model profiles
(default is <code>'partial'</code> for Partial Dependence Profiles).</dd>
<dt><strong><code>N</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>Number of observations that will be sampled from the <code>data</code> attribute before
the calculation of variable profiles. <code>None</code> means all <code>data</code> (default is <code>300</code>).</dd>
<dt><strong><code>variables</code></strong> :&ensp;<code>str</code> or <code>array_like</code> of <code>str</code>, optional</dt>
<dd>Variables for which the profiles will be calculated
(default is <code>None</code>, which means all of the variables).</dd>
<dt><strong><code>variable_type</code></strong> :&ensp;<code>{'numerical', 'categorical'}</code></dt>
<dd>Calculate the profiles for numerical or categorical variables
(default is <code>'numerical'</code>).</dd>
<dt><strong><code>groups</code></strong> :&ensp;<code>str</code> or <code>array_like</code> of <code>str</code>, optional</dt>
<dd>Names of categorical variables that will be used for profile grouping
(default is <code>None</code>, which means no grouping).</dd>
<dt><strong><code>span</code></strong> :&ensp;<code>float</code>, optional</dt>
<dd>Smoothing coefficient used as sd for gaussian kernel (default is <code>0.25</code>).</dd>
<dt><strong><code>grid_points</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>Maximum number of points for profile calculations (default is <code>101</code>).
NOTE: The final number of points may be lower than <code>grid_points</code>,
e.g. if there is not enough unique values for a given variable.</dd>
<dt><strong><code>variable_splits</code></strong> :&ensp;<code>dict</code> of <code>lists</code>, optional</dt>
<dd>Split points for variables e.g. <code>{'x': [0, 0.2, 0.5, 0.8, 1], 'y': ['a', 'b']}</code>
(default is <code>None</code>, which means that they will be distributed uniformly).</dd>
<dt><strong><code>variable_splits_type</code></strong> :&ensp;<code>{'uniform', 'quantiles'}</code>, optional</dt>
<dd>Way of calculating <code>variable_splits</code>. Set 'quantiles' for percentiles.
(default is <code>'uniform'</code>, which means uniform grid of points).</dd>
<dt><strong><code>center</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>Theoretically Accumulated Profiles start at <code>0</code>, but are centered to compare
them with Partial Dependence Profiles (default is <code>True</code>, which means center
around the average <code>y_hat</code> calculated on the data sample).</dd>
<dt><strong><code>label</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>Name to appear in result and plots. Overrides default.</dd>
<dt><strong><code>processes</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>Number of parallel processes to use in calculations. Iterated over <code>variables</code>
(default is <code>1</code>, which means no parallel computation).</dd>
<dt><strong><code>random_state</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>Set seed for random number generator (default is random seed).</dd>
<dt><strong><code>verbose</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>Print tqdm progress bar (default is <code>True</code>).</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>AggregatedProfiles class object</code></dt>
<dd>Explanation object containing the main result attribute and the plot method.</dd>
</dl>
<h2 id="notes">Notes</h2>
<ul>
<li><a href="https://pbiecek.github.io/ema/partialDependenceProfiles.html">https://pbiecek.github.io/ema/partialDependenceProfiles.html</a></li>
<li><a href="https://pbiecek.github.io/ema/accumulatedLocalProfiles.html">https://pbiecek.github.io/ema/accumulatedLocalProfiles.html</a></li>
</ul></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/ModelOriented/DALEX/blob/2441c55e88b740295d874c46c88f5edce8139e7f/dalex\_explainer\object.py#L610-L724" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def model_profile(self,
                  type=(&#39;partial&#39;, &#39;accumulated&#39;, &#39;conditional&#39;),
                  N=300,
                  variables=None,
                  variable_type=&#39;numerical&#39;,
                  groups=None,
                  span=0.25,
                  grid_points=101,
                  variable_splits=None,
                  variable_splits_type=&#39;uniform&#39;,
                  center=True,
                  label=None,
                  processes=1,
                  random_state=None,
                  verbose=True):

    &#34;&#34;&#34;Calculate model-level variable profiles as Partial or Accumulated Dependence

    Parameters
    -----------
    type : {&#39;partial&#39;, &#39;accumulated&#39;, &#39;conditional&#39;}
        Type of model profiles
        (default is `&#39;partial&#39;` for Partial Dependence Profiles).
    N : int, optional
        Number of observations that will be sampled from the `data` attribute before
        the calculation of variable profiles. `None` means all `data` (default is `300`).
    variables : str or array_like of str, optional
        Variables for which the profiles will be calculated
        (default is `None`, which means all of the variables).
    variable_type : {&#39;numerical&#39;, &#39;categorical&#39;}
        Calculate the profiles for numerical or categorical variables
        (default is `&#39;numerical&#39;`).
    groups : str or array_like of str, optional
        Names of categorical variables that will be used for profile grouping
        (default is `None`, which means no grouping).
    span : float, optional
        Smoothing coefficient used as sd for gaussian kernel (default is `0.25`).
    grid_points : int, optional
        Maximum number of points for profile calculations (default is `101`).
        NOTE: The final number of points may be lower than `grid_points`,
        e.g. if there is not enough unique values for a given variable.
    variable_splits : dict of lists, optional
        Split points for variables e.g. `{&#39;x&#39;: [0, 0.2, 0.5, 0.8, 1], &#39;y&#39;: [&#39;a&#39;, &#39;b&#39;]}`
        (default is `None`, which means that they will be distributed uniformly).
    variable_splits_type : {&#39;uniform&#39;, &#39;quantiles&#39;}, optional
        Way of calculating `variable_splits`. Set &#39;quantiles&#39; for percentiles.
        (default is `&#39;uniform&#39;`, which means uniform grid of points).
    center : bool, optional
        Theoretically Accumulated Profiles start at `0`, but are centered to compare
        them with Partial Dependence Profiles (default is `True`, which means center
        around the average `y_hat` calculated on the data sample).
    label : str, optional
        Name to appear in result and plots. Overrides default.
    processes : int, optional
        Number of parallel processes to use in calculations. Iterated over `variables`
        (default is `1`, which means no parallel computation).
    random_state : int, optional
        Set seed for random number generator (default is random seed).
    verbose : bool, optional
        Print tqdm progress bar (default is `True`).

    Returns
    -----------
    AggregatedProfiles class object
        Explanation object containing the main result attribute and the plot method.

    Notes
    --------
    - https://pbiecek.github.io/ema/partialDependenceProfiles.html
    - https://pbiecek.github.io/ema/accumulatedLocalProfiles.html
    &#34;&#34;&#34;

    checks.check_data_again(self.data)

    types = (&#39;partial&#39;, &#39;accumulated&#39;, &#39;conditional&#39;)
    aliases = {&#39;pdp&#39;: &#39;partial&#39;, &#39;ale&#39;: &#39;accumulated&#39;}
    _type = checks.check_method_type(type, types, aliases)

    _ceteris_paribus = CeterisParibus(
        grid_points=grid_points,
        variables=variables,
        variable_splits=variable_splits,
        variable_splits_type=variable_splits_type,
        processes=processes
    )

    if isinstance(N, int):
        if isinstance(random_state, int):
            np.random.seed(random_state)
        N = min(N, self.data.shape[0])
        I = np.random.choice(np.arange(N), N, replace=False)
        _y = self.y[I] if self.y is not None else self.y
        _new_observation = self.data.iloc[I, :]
    else:
        _y = self.y
        _new_observation = self.data

    _ceteris_paribus.fit(self, _new_observation, _y, verbose=verbose)

    _model_profile = AggregatedProfiles(
        type=_type,
        variables=variables,
        variable_type=variable_type,
        groups=groups,
        span=span,
        center=center,
        random_state=random_state
    )

    _model_profile.fit(_ceteris_paribus, verbose)

    if label:
        _model_profile.result[&#39;_label_&#39;] = label
            
    return _model_profile</code></pre>
</details>
</dd>
<dt id="dalex.Explainer.model_surrogate"><code class="name flex">
<span>def <span class="ident">model_surrogate</span></span>(<span>self, type=('tree', 'linear'), max_vars=5, max_depth=3, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Create a surrogate interpretable model from the black-box model</p>
<p>This method uses the scikit-learn package to create a surrogate
interpretable model (e.g. decision tree) from the black-box model.
It aims to use the most important features and add a plot method to
the model, so that it can be easily interpreted. See Notes section
for references.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>type</code></strong> :&ensp;<code>{'tree', 'linear'}</code></dt>
<dd>Type of a surrogate model. This can be a decision tree or a linear model
(default is <code>'tree'</code>).</dd>
<dt><strong><code>max_vars</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>Maximum number of variables that will be used in surrogate model training.
These are the most important variables to the black-box model (default is <code>5</code>).</dd>
<dt><strong><code>max_depth</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>The maximum depth of the tree. If <code>None</code>, then nodes are expanded until all
leaves are pure or until all leaves contain less than min_samples_split
samples (default is <code>3</code> for interpretable plot).</dd>
<dt><strong><code>kwargs</code></strong> :&ensp;<code>dict</code></dt>
<dd>Keyword arguments passed to one of the: <code>sklearn.tree.DecisionTreeClassifier,
sklearn.tree.DecisionTreeRegressor, sklearn.linear_model.LogisticRegression,
sklearn.linear_model.LinearRegression</code></dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>One of: sklearn.tree.DecisionTreeClassifier, sklearn.tree.DecisionTreeRegressor, sklearn.linear_model.LogisticRegression, sklearn.linear_model.LinearRegression</code></dt>
<dd>&nbsp;</dd>
<dt><code>A surrogate model with additional:</code></dt>
<dd>
<ul>
<li><code>plot</code> method</li>
<li><code>performance</code> attribute</li>
<li><code>feature_names</code> attribute</li>
<li><code>class_names</code> attribute</li>
</ul>
</dd>
</dl>
<h2 id="notes">Notes</h2>
<ul>
<li><a href="https://christophm.github.io/interpretable-ml-book/global.html">https://christophm.github.io/interpretable-ml-book/global.html</a></li>
<li><a href="https://github.com/scikit-learn/scikit-learn">https://github.com/scikit-learn/scikit-learn</a></li>
</ul></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/ModelOriented/DALEX/blob/2441c55e88b740295d874c46c88f5edce8139e7f/dalex\_explainer\object.py#L762-L820" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def model_surrogate(self,
                    type=(&#39;tree&#39;, &#39;linear&#39;),
                    max_vars=5,
                    max_depth=3,
                    **kwargs):
    &#34;&#34;&#34;Create a surrogate interpretable model from the black-box model

    This method uses the scikit-learn package to create a surrogate
    interpretable model (e.g. decision tree) from the black-box model.
    It aims to use the most important features and add a plot method to
    the model, so that it can be easily interpreted. See Notes section
    for references.

    Parameters
    -----------
    type : {&#39;tree&#39;, &#39;linear&#39;}
        Type of a surrogate model. This can be a decision tree or a linear model
        (default is `&#39;tree&#39;`).
    max_vars : int, optional
        Maximum number of variables that will be used in surrogate model training.
        These are the most important variables to the black-box model (default is `5`).
    max_depth : int, optional
        The maximum depth of the tree. If `None`, then nodes are expanded until all
        leaves are pure or until all leaves contain less than min_samples_split
        samples (default is `3` for interpretable plot).
    kwargs : dict
        Keyword arguments passed to one of the: `sklearn.tree.DecisionTreeClassifier,
        sklearn.tree.DecisionTreeRegressor, sklearn.linear_model.LogisticRegression,
        sklearn.linear_model.LinearRegression`


    Returns
    -----------
    One of: sklearn.tree.DecisionTreeClassifier, sklearn.tree.DecisionTreeRegressor, sklearn.linear_model.LogisticRegression, sklearn.linear_model.LinearRegression
    A surrogate model with additional:
        - `plot` method
        - `performance` attribute
        - `feature_names` attribute
        - `class_names` attribute

    Notes
    -----------
    - https://christophm.github.io/interpretable-ml-book/global.html
    - https://github.com/scikit-learn/scikit-learn
    &#34;&#34;&#34;

    _global_checks.global_check_import(&#39;scikit-learn&#39;, &#39;surrogate models&#39;)
    checks.check_data_again(self.data)

    types = (&#39;tree&#39;, &#39;linear&#39;)
    _type = checks.check_method_type(type, types)

    surrogate_model = utils.create_surrogate_model(explainer=self,
                                                   type=_type,
                                                   max_vars=max_vars,
                                                   max_depth=max_depth,
                                                   **kwargs)

    return surrogate_model</code></pre>
</details>
</dd>
<dt id="dalex.Explainer.predict"><code class="name flex">
<span>def <span class="ident">predict</span></span>(<span>self, data)</span>
</code></dt>
<dd>
<div class="desc"><p>Make a prediction</p>
<p>This function uses the <code>predict_function</code> attribute.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>data</code></strong> :&ensp;<code>pd.DataFrame, np.ndarray (2d)</code></dt>
<dd>Data which will be used to make a prediction.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>np.ndarray (1d)</code></dt>
<dd>Model predictions for given <code>data</code>.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/ModelOriented/DALEX/blob/2441c55e88b740295d874c46c88f5edce8139e7f/dalex\_explainer\object.py#L169-L187" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def predict(self, data):
    &#34;&#34;&#34;Make a prediction

    This function uses the `predict_function` attribute.

    Parameters
    ----------
    data : pd.DataFrame, np.ndarray (2d)
        Data which will be used to make a prediction.

    Returns
    ----------
    np.ndarray (1d)
        Model predictions for given `data`.
    &#34;&#34;&#34;

    checks.check_method_data(data)

    return self.predict_function(self.model, data)</code></pre>
</details>
</dd>
<dt id="dalex.Explainer.predict_parts"><code class="name flex">
<span>def <span class="ident">predict_parts</span></span>(<span>self, new_observation, type=('break_down_interactions', 'break_down', 'shap', 'shap_wrapper'), order=None, interaction_preference=1, path='average', N=None, B=25, keep_distributions=False, label=None, processes=1, random_state=None, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Calculate predict-level variable attributions as Break Down, Shapley Values or Shap Values</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>new_observation</code></strong> :&ensp;<code>pd.Series</code> or <code>np.ndarray (1d)</code> or <code>pd.DataFrame (1,p)</code></dt>
<dd>An observation for which a prediction needs to be explained.</dd>
<dt><strong><code>type</code></strong> :&ensp;<code>{'break_down_interactions', 'break_down', 'shap', 'shap_wrapper'}</code></dt>
<dd>Type of variable attributions (default is <code>'break_down_interactions'</code>).</dd>
<dt><strong><code>order</code></strong> :&ensp;<code>list</code> of <code>int</code> or <code>str</code>, optional</dt>
<dd>Parameter specific for <code>break_down_interactions</code> and <code>break_down</code>. Use a fixed
order of variables for attribution calculation. Use integer values
or string
variable names (default is <code>None</code>, which means order by importance).</dd>
<dt><strong><code>interaction_preference</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>Parameter specific for <code>break_down_interactions</code> type. Specify which interactions
will be present in an explanation. The larger the integer, the more frequently
interactions will be presented (default is <code>1</code>).</dd>
<dt><strong><code>path</code></strong> :&ensp;<code>list</code> of <code>int</code>, optional</dt>
<dd>Parameter specific for <code>shap</code>. If specified, then attributions for this path
will be plotted (default is <code>'average'</code>, which plots attribution means for
<code>B</code> random paths).</dd>
<dt><strong><code>N</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>Number of observations that will be sampled from the <code>data</code> attribute before
the calculation of variable attributions. Default is <code>None</code> which means all <code>data</code>.</dd>
<dt><strong><code>B</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>Parameter specific for <code>shap</code>. Number of random paths to calculate
variable attributions (default is <code>25</code>).</dd>
<dt><strong><code>keep_distributions</code></strong> :&ensp;<code> bool</code>, optional</dt>
<dd>Save the distribution of partial predictions (default is <code>False</code>).</dd>
<dt><strong><code>label</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>Name to appear in result and plots. Overrides default.</dd>
<dt><strong><code>processes</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>Parameter specific for <code>shap</code>. Number of parallel processes to use in calculations.
Iterated over <code>B</code> (default is <code>1</code>, which means no parallel computation).</dd>
<dt><strong><code>random_state</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>Set seed for random number generator (default is random seed).</dd>
<dt><strong><code>kwargs</code></strong> :&ensp;<code>dict</code></dt>
<dd>Used only for <code>'shap_wrapper'</code>. Pass <code>shap_explainer_type</code> to specify, which
Explainer shall be used: <code>{'TreeExplainer', 'DeepExplainer', 'GradientExplainer',
'LinearExplainer', 'KernelExplainer'}&lt;code&gt; (default is &lt;/code&gt;None</code>, which automatically
chooses an Explainer to use).
Also keyword arguments passed to one of the: <code>shap.TreeExplainer.shap_values,
shap.DeepExplainer.shap_values, shap.GradientExplainer.shap_values,
shap.LinearExplainer.shap_values, shap.KernelExplainer.shap_values</code>.
See <a href="https://github.com/slundberg/shap">https://github.com/slundberg/shap</a></dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>BreakDown, Shap</code> or <code>ShapWrapper class object</code></dt>
<dd>Explanation object containing the main result attribute and the plot method.
Object class, its attributes, and the plot method depend on the <code>type</code> parameter.</dd>
</dl>
<h2 id="notes">Notes</h2>
<ul>
<li><a href="https://pbiecek.github.io/ema/breakDown.html">https://pbiecek.github.io/ema/breakDown.html</a></li>
<li><a href="https://pbiecek.github.io/ema/iBreakDown.html">https://pbiecek.github.io/ema/iBreakDown.html</a></li>
<li><a href="https://pbiecek.github.io/ema/shapley.html">https://pbiecek.github.io/ema/shapley.html</a></li>
<li><a href="https://github.com/slundberg/shap">https://github.com/slundberg/shap</a></li>
</ul></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/ModelOriented/DALEX/blob/2441c55e88b740295d874c46c88f5edce8139e7f/dalex\_explainer\object.py#L211-L328" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def predict_parts(self,
                  new_observation,
                  type=(&#39;break_down_interactions&#39;, &#39;break_down&#39;, &#39;shap&#39;, &#39;shap_wrapper&#39;),
                  order=None,
                  interaction_preference=1,
                  path=&#34;average&#34;,
                  N=None,
                  B=25,
                  keep_distributions=False,
                  label=None,
                  processes=1,
                  random_state=None,
                  **kwargs):
    &#34;&#34;&#34;Calculate predict-level variable attributions as Break Down, Shapley Values or Shap Values

    Parameters
    -----------
    new_observation : pd.Series or np.ndarray (1d) or pd.DataFrame (1,p)
        An observation for which a prediction needs to be explained.
    type : {&#39;break_down_interactions&#39;, &#39;break_down&#39;, &#39;shap&#39;, &#39;shap_wrapper&#39;}
        Type of variable attributions (default is `&#39;break_down_interactions&#39;`).
    order : list of int or str, optional
        Parameter specific for `break_down_interactions` and `break_down`. Use a fixed
        order of variables for attribution calculation. Use integer values  or string
        variable names (default is `None`, which means order by importance).
    interaction_preference : int, optional
        Parameter specific for `break_down_interactions` type. Specify which interactions
        will be present in an explanation. The larger the integer, the more frequently
        interactions will be presented (default is `1`).
    path : list of int, optional
        Parameter specific for `shap`. If specified, then attributions for this path
        will be plotted (default is `&#39;average&#39;`, which plots attribution means for
        `B` random paths).
    N : int, optional
        Number of observations that will be sampled from the `data` attribute before
        the calculation of variable attributions. Default is `None` which means all `data`.
    B : int, optional
        Parameter specific for `shap`. Number of random paths to calculate
        variable attributions (default is `25`).
    keep_distributions :  bool, optional
        Save the distribution of partial predictions (default is `False`).
    label : str, optional
        Name to appear in result and plots. Overrides default.
    processes : int, optional
        Parameter specific for `shap`. Number of parallel processes to use in calculations.
        Iterated over `B` (default is `1`, which means no parallel computation).
    random_state : int, optional
        Set seed for random number generator (default is random seed).
    kwargs : dict
        Used only for `&#39;shap_wrapper&#39;`. Pass `shap_explainer_type` to specify, which
        Explainer shall be used: `{&#39;TreeExplainer&#39;, &#39;DeepExplainer&#39;, &#39;GradientExplainer&#39;,
        &#39;LinearExplainer&#39;, &#39;KernelExplainer&#39;}` (default is `None`, which automatically
        chooses an Explainer to use).
        Also keyword arguments passed to one of the: `shap.TreeExplainer.shap_values,
        shap.DeepExplainer.shap_values, shap.GradientExplainer.shap_values,
        shap.LinearExplainer.shap_values, shap.KernelExplainer.shap_values`.
        See https://github.com/slundberg/shap

    Returns
    -----------
    BreakDown, Shap or ShapWrapper class object
        Explanation object containing the main result attribute and the plot method.
        Object class, its attributes, and the plot method depend on the `type` parameter.

    Notes
    --------
    - https://pbiecek.github.io/ema/breakDown.html
    - https://pbiecek.github.io/ema/iBreakDown.html
    - https://pbiecek.github.io/ema/shapley.html
    - https://github.com/slundberg/shap
    &#34;&#34;&#34;

    checks.check_data_again(self.data)

    types = (&#39;break_down_interactions&#39;, &#39;break_down&#39;, &#39;shap&#39;, &#39;shap_wrapper&#39;)
    _type = checks.check_method_type(type, types)

    if isinstance(N, int):
        # temporarly overwrite data in the Explainer (fastest way)
        # at the end of predict_parts fix the Explainer (add original data)
        if isinstance(random_state, int):
            np.random.seed(random_state)
        N = min(N, self.data.shape[0])
        I = np.random.choice(np.arange(N), N, replace=False)
        from copy import deepcopy
        _data = deepcopy(self.data)
        self.data = self.data.iloc[I, :]

    if _type == &#39;break_down_interactions&#39; or _type == &#39;break_down&#39;:
        _predict_parts = BreakDown(
            type=_type,
            keep_distributions=keep_distributions,
            order=order,
            interaction_preference=interaction_preference
        )
    elif _type == &#39;shap&#39;:
        _predict_parts = Shap(
            keep_distributions=keep_distributions,
            path=path,
            B=B,
            processes=processes,
            random_state=random_state
        )
    elif _type == &#39;shap_wrapper&#39;:
        _global_checks.global_check_import(&#39;shap&#39;, &#39;SHAP explanations&#39;)
        _predict_parts = ShapWrapper(&#39;predict_parts&#39;)
    else:
        raise TypeError(&#34;Wrong type parameter.&#34;)

    _predict_parts.fit(self, new_observation, **kwargs)
    
    if label:
        _predict_parts.result[&#39;label&#39;] = label

    if isinstance(N, int):
        self.data = _data

    return _predict_parts</code></pre>
</details>
</dd>
<dt id="dalex.Explainer.predict_profile"><code class="name flex">
<span>def <span class="ident">predict_profile</span></span>(<span>self, new_observation, type=('ceteris_paribus',), y=None, variables=None, grid_points=101, variable_splits=None, variable_splits_type='uniform', variable_splits_with_obs=True, processes=1, label=None, verbose=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Calculate predict-level variable profiles as Ceteris Paribus</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>new_observation</code></strong> :&ensp;<code>pd.DataFrame</code> or <code>np.ndarray</code> or <code>pd.Series</code></dt>
<dd>Observations for which predictions need to be explained.</dd>
<dt><strong><code>type</code></strong> :&ensp;<code>{'ceteris_paribus', TODO: 'oscilations'}</code></dt>
<dd>Type of variable profiles (default is <code>'ceteris_paribus'</code>).</dd>
<dt><strong><code>y</code></strong> :&ensp;<code>pd.Series</code> or <code>np.ndarray (1d)</code>, optional</dt>
<dd>Target variable with the same length as <code>new_observation</code>.</dd>
<dt><strong><code>variables</code></strong> :&ensp;<code>str</code> or <code>array_like</code> of <code>str</code>, optional</dt>
<dd>Variables for which the profiles will be calculated
(default is <code>None</code>, which means all of the variables).</dd>
<dt><strong><code>grid_points</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>Maximum number of points for profile calculations (default is <code>101</code>).
NOTE: The final number of points may be lower than <code>grid_points</code>,
eg. if there is not enough unique values for a given variable.</dd>
<dt><strong><code>variable_splits</code></strong> :&ensp;<code>dict</code> of <code>lists</code>, optional</dt>
<dd>Split points for variables e.g. <code>{'x': [0, 0.2, 0.5, 0.8, 1], 'y': ['a', 'b']}</code>
(default is <code>None</code>, which means that they will be calculated using one of
<code>variable_splits_type</code> and the <code>data</code> attribute).</dd>
<dt><strong><code>variable_splits_type</code></strong> :&ensp;<code>{'uniform', 'quantiles'}</code>, optional</dt>
<dd>Way of calculating <code>variable_splits</code>. Set <code>'quantiles'</code> for percentiles.
(default is <code>'uniform'</code>, which means uniform grid of points).</dd>
<dt><strong><code>variable_splits_with_obs</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>Add variable values of <code>new_observation</code> data to the <code>variable_splits</code>
(default is <code>True</code>).</dd>
<dt><strong><code>label</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>Name to appear in result and plots. Overrides default.</dd>
<dt><strong><code>processes</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>Number of parallel processes to use in calculations. Iterated over <code>variables</code>
(default is <code>1</code>, which means no parallel computation).</dd>
<dt><strong><code>verbose</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>Print tqdm progress bar (default is <code>True</code>).</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>CeterisParibus class object</code></dt>
<dd>Explanation object containing the main result attribute and the plot method.</dd>
</dl>
<h2 id="notes">Notes</h2>
<ul>
<li><a href="https://pbiecek.github.io/ema/ceterisParibus.html">https://pbiecek.github.io/ema/ceterisParibus.html</a></li>
</ul></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/ModelOriented/DALEX/blob/2441c55e88b740295d874c46c88f5edce8139e7f/dalex\_explainer\object.py#L330-L409" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def predict_profile(self,
                    new_observation,
                    type=(&#39;ceteris_paribus&#39;,),
                    y=None,
                    variables=None,
                    grid_points=101,
                    variable_splits=None,
                    variable_splits_type=&#39;uniform&#39;,
                    variable_splits_with_obs=True,
                    processes=1,
                    label=None,
                    verbose=True):
    &#34;&#34;&#34;Calculate predict-level variable profiles as Ceteris Paribus

    Parameters
    -----------
    new_observation : pd.DataFrame or np.ndarray or pd.Series
        Observations for which predictions need to be explained.
    type : {&#39;ceteris_paribus&#39;, TODO: &#39;oscilations&#39;}
        Type of variable profiles (default is `&#39;ceteris_paribus&#39;`).
    y : pd.Series or np.ndarray (1d), optional
        Target variable with the same length as `new_observation`.
    variables : str or array_like of str, optional
        Variables for which the profiles will be calculated
        (default is `None`, which means all of the variables).
    grid_points : int, optional
        Maximum number of points for profile calculations (default is `101`).
        NOTE: The final number of points may be lower than `grid_points`,
        eg. if there is not enough unique values for a given variable.
    variable_splits : dict of lists, optional
        Split points for variables e.g. `{&#39;x&#39;: [0, 0.2, 0.5, 0.8, 1], &#39;y&#39;: [&#39;a&#39;, &#39;b&#39;]}`
        (default is `None`, which means that they will be calculated using one of
        `variable_splits_type` and the `data` attribute).
    variable_splits_type : {&#39;uniform&#39;, &#39;quantiles&#39;}, optional
        Way of calculating `variable_splits`. Set `&#39;quantiles&#39;` for percentiles.
        (default is `&#39;uniform&#39;`, which means uniform grid of points).
    variable_splits_with_obs: bool, optional
        Add variable values of `new_observation` data to the `variable_splits`
        (default is `True`).
    label : str, optional
        Name to appear in result and plots. Overrides default.
    processes : int, optional
        Number of parallel processes to use in calculations. Iterated over `variables`
        (default is `1`, which means no parallel computation).
    verbose : bool, optional
        Print tqdm progress bar (default is `True`).

    Returns
    -----------
    CeterisParibus class object
        Explanation object containing the main result attribute and the plot method.

    Notes
    --------
    - https://pbiecek.github.io/ema/ceterisParibus.html
    &#34;&#34;&#34;

    checks.check_data_again(self.data)

    types = (&#39;ceteris_paribus&#39;,)
    _type = checks.check_method_type(type, types)

    if _type == &#39;ceteris_paribus&#39;:
        _predict_profile = CeterisParibus(
            variables=variables,
            grid_points=grid_points,
            variable_splits=variable_splits,
            variable_splits_type=variable_splits_type,
            variable_splits_with_obs=variable_splits_with_obs,
            processes=processes
        )
    else:
        raise TypeError(&#34;Wrong type parameter.&#34;)

    _predict_profile.fit(self, new_observation, y, verbose)

    if label:
        _predict_profile.result[&#39;_label_&#39;] = label
        
    return _predict_profile</code></pre>
</details>
</dd>
<dt id="dalex.Explainer.predict_surrogate"><code class="name flex">
<span>def <span class="ident">predict_surrogate</span></span>(<span>self, new_observation, type='lime', **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Wrapper for surrogate model explanations</p>
<p>This function uses the lime package to create the model explanation.
See <a href="https://lime-ml.readthedocs.io/en/latest/lime.html#module-lime.lime_tabular">https://lime-ml.readthedocs.io/en/latest/lime.html#module-lime.lime_tabular</a></p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>new_observation</code></strong> :&ensp;<code>pd.Series</code> or <code>np.ndarray (1d)</code> or <code>pd.DataFrame (1,p)</code></dt>
<dd>An observation for which a prediction needs to be explained.</dd>
<dt><strong><code>type</code></strong> :&ensp;<code>{'lime'}</code></dt>
<dd>Type of explanation method
(default is <code>'lime'</code>, which uses the lime package to create an explanation).</dd>
<dt><strong><code>kwargs</code></strong> :&ensp;<code>dict</code></dt>
<dd>Keyword arguments passed to the lime.lime_tabular.LimeTabularExplainer object
and the LimeTabularExplainer.explain_instance method. Exceptions are:
<code>training_data</code>, <code>mode</code>, <code>data_row</code> and <code>predict_fn</code>. Other parameters:
<a href="https://lime-ml.readthedocs.io/en/latest/lime.html#module-lime.lime_tabular">https://lime-ml.readthedocs.io/en/latest/lime.html#module-lime.lime_tabular</a></dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>lime.explanation.Explanation</code></dt>
<dd>Explanation object.</dd>
</dl>
<h2 id="notes">Notes</h2>
<ul>
<li><a href="https://github.com/marcotcr/lime">https://github.com/marcotcr/lime</a></li>
</ul></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/ModelOriented/DALEX/blob/2441c55e88b740295d874c46c88f5edce8139e7f/dalex\_explainer\object.py#L411-L452" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def predict_surrogate(self,
                      new_observation,
                      type=&#39;lime&#39;,
                      **kwargs):
    &#34;&#34;&#34;Wrapper for surrogate model explanations

    This function uses the lime package to create the model explanation.
    See https://lime-ml.readthedocs.io/en/latest/lime.html#module-lime.lime_tabular

    Parameters
    -----------
    new_observation : pd.Series or np.ndarray (1d) or pd.DataFrame (1,p)
        An observation for which a prediction needs to be explained.
    type : {&#39;lime&#39;}
        Type of explanation method
        (default is `&#39;lime&#39;`, which uses the lime package to create an explanation).
    kwargs : dict
        Keyword arguments passed to the lime.lime_tabular.LimeTabularExplainer object
        and the LimeTabularExplainer.explain_instance method. Exceptions are:
        `training_data`, `mode`, `data_row` and `predict_fn`. Other parameters:
        https://lime-ml.readthedocs.io/en/latest/lime.html#module-lime.lime_tabular

    Returns
    -----------
    lime.explanation.Explanation
        Explanation object.

    Notes
    -----------
    - https://github.com/marcotcr/lime
    &#34;&#34;&#34;

    checks.check_data_again(self.data)

    if type == &#39;lime&#39;:
        _global_checks.global_check_import(&#39;lime&#39;, &#39;LIME explanations&#39;)
        _new_observation = checks.check_new_observation_lime(new_observation)
        _explanation = utils.create_lime_explanation(self, _new_observation, **kwargs)
    else:
        raise TypeError(&#34;Wrong &#39;type&#39; parameter.&#34;)

    return _explanation</code></pre>
</details>
</dd>
<dt id="dalex.Explainer.residual"><code class="name flex">
<span>def <span class="ident">residual</span></span>(<span>self, data, y)</span>
</code></dt>
<dd>
<div class="desc"><p>Calculate residuals</p>
<p>This function uses the <code>residual_function</code> attribute.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>data</code></strong> :&ensp;<code>pd.DataFrame</code></dt>
<dd>Data which will be used to calculate residuals.</dd>
<dt><strong><code>y</code></strong> :&ensp;<code>pd.Series</code> or <code>np.ndarray (1d)</code></dt>
<dd>Target variable which will be used to calculate residuals.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>np.ndarray (1d)</code></dt>
<dd>Model residuals for given <code>data</code> and <code>y</code>.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/ModelOriented/DALEX/blob/2441c55e88b740295d874c46c88f5edce8139e7f/dalex\_explainer\object.py#L189-L209" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def residual(self, data, y):
    &#34;&#34;&#34;Calculate residuals

    This function uses the `residual_function` attribute.

    Parameters
    -----------
    data : pd.DataFrame
        Data which will be used to calculate residuals.
    y : pd.Series or np.ndarray (1d)
        Target variable which will be used to calculate residuals.

    Returns
    -----------
    np.ndarray (1d)
        Model residuals for given `data` and `y`.
    &#34;&#34;&#34;

    checks.check_method_data(data)

    return self.residual_function(self.model, data, y)</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<header>
<a class="homelink" rel="home" title="dalex Home" href="https://dalex.drwhy.ai/">
<img src="https://raw.githubusercontent.com/ModelOriented/DALEX-docs/master/docs/misc/dalex_even.png" alt=""> dalex
</a>
</header>
<h1>Index</h1>
<div class="toc">
<ul>
<li><a href="#overview">Overview</a></li>
<li><a href="#installation">Installation</a></li>
<li><a href="#examples">Examples</a></li>
<li><a href="#plots">Plots</a></li>
<li><a href="#citation">Citation</a></li>
<li><a href="#developer">Developer</a><ul>
<li><a href="#class-diagram">Class diagram</a></li>
<li><a href="#folder-structure">Folder structure</a></li>
</ul>
</li>
</ul>
</div>
<ul id="index">
<li><h3><a href="#header-submodules">Sub-modules</a></h3>
<ul>
<li><code><a title="dalex.arena" href="arena/index.html">dalex.arena</a></code></li>
<li><code><a title="dalex.datasets" href="datasets/index.html">dalex.datasets</a></code></li>
<li><code><a title="dalex.fairness" href="fairness/index.html">dalex.fairness</a></code></li>
<li><code><a title="dalex.model_explanations" href="model_explanations/index.html">dalex.model_explanations</a></code></li>
<li><code><a title="dalex.predict_explanations" href="predict_explanations/index.html">dalex.predict_explanations</a></code></li>
<li><code><a title="dalex.wrappers" href="wrappers/index.html">dalex.wrappers</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="dalex.Arena" href="#dalex.Arena">Arena</a></code></h4>
<ul class="two-column">
<li><code><a title="dalex.Arena.clear_cache" href="#dalex.Arena.clear_cache">clear_cache</a></code></li>
<li><code><a title="dalex.Arena.fill_cache" href="#dalex.Arena.fill_cache">fill_cache</a></code></li>
<li><code><a title="dalex.Arena.find_in_cache" href="#dalex.Arena.find_in_cache">find_in_cache</a></code></li>
<li><code><a title="dalex.Arena.find_param_value" href="#dalex.Arena.find_param_value">find_param_value</a></code></li>
<li><code><a title="dalex.Arena.get_available_params" href="#dalex.Arena.get_available_params">get_available_params</a></code></li>
<li><code><a title="dalex.Arena.get_option" href="#dalex.Arena.get_option">get_option</a></code></li>
<li><code><a title="dalex.Arena.get_param_attributes" href="#dalex.Arena.get_param_attributes">get_param_attributes</a></code></li>
<li><code><a title="dalex.Arena.get_params" href="#dalex.Arena.get_params">get_params</a></code></li>
<li><code><a title="dalex.Arena.get_params_attributes" href="#dalex.Arena.get_params_attributes">get_params_attributes</a></code></li>
<li><code><a title="dalex.Arena.get_plot" href="#dalex.Arena.get_plot">get_plot</a></code></li>
<li><code><a title="dalex.Arena.get_supported_plots" href="#dalex.Arena.get_supported_plots">get_supported_plots</a></code></li>
<li><code><a title="dalex.Arena.list_available_params" href="#dalex.Arena.list_available_params">list_available_params</a></code></li>
<li><code><a title="dalex.Arena.list_params" href="#dalex.Arena.list_params">list_params</a></code></li>
<li><code><a title="dalex.Arena.print_options" href="#dalex.Arena.print_options">print_options</a></code></li>
<li><code><a title="dalex.Arena.push_dataset" href="#dalex.Arena.push_dataset">push_dataset</a></code></li>
<li><code><a title="dalex.Arena.push_model" href="#dalex.Arena.push_model">push_model</a></code></li>
<li><code><a title="dalex.Arena.push_observations" href="#dalex.Arena.push_observations">push_observations</a></code></li>
<li><code><a title="dalex.Arena.put_to_cache" href="#dalex.Arena.put_to_cache">put_to_cache</a></code></li>
<li><code><a title="dalex.Arena.run_server" href="#dalex.Arena.run_server">run_server</a></code></li>
<li><code><a title="dalex.Arena.save" href="#dalex.Arena.save">save</a></code></li>
<li><code><a title="dalex.Arena.set_option" href="#dalex.Arena.set_option">set_option</a></code></li>
<li><code><a title="dalex.Arena.stop_server" href="#dalex.Arena.stop_server">stop_server</a></code></li>
<li><code><a title="dalex.Arena.update_timestamp" href="#dalex.Arena.update_timestamp">update_timestamp</a></code></li>
<li><code><a title="dalex.Arena.upload" href="#dalex.Arena.upload">upload</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="dalex.Explainer" href="#dalex.Explainer">Explainer</a></code></h4>
<ul class="two-column">
<li><code><a title="dalex.Explainer.dump" href="#dalex.Explainer.dump">dump</a></code></li>
<li><code><a title="dalex.Explainer.dumps" href="#dalex.Explainer.dumps">dumps</a></code></li>
<li><code><a title="dalex.Explainer.load" href="#dalex.Explainer.load">load</a></code></li>
<li><code><a title="dalex.Explainer.loads" href="#dalex.Explainer.loads">loads</a></code></li>
<li><code><a title="dalex.Explainer.model_diagnostics" href="#dalex.Explainer.model_diagnostics">model_diagnostics</a></code></li>
<li><code><a title="dalex.Explainer.model_fairness" href="#dalex.Explainer.model_fairness">model_fairness</a></code></li>
<li><code><a title="dalex.Explainer.model_parts" href="#dalex.Explainer.model_parts">model_parts</a></code></li>
<li><code><a title="dalex.Explainer.model_performance" href="#dalex.Explainer.model_performance">model_performance</a></code></li>
<li><code><a title="dalex.Explainer.model_profile" href="#dalex.Explainer.model_profile">model_profile</a></code></li>
<li><code><a title="dalex.Explainer.model_surrogate" href="#dalex.Explainer.model_surrogate">model_surrogate</a></code></li>
<li><code><a title="dalex.Explainer.predict" href="#dalex.Explainer.predict">predict</a></code></li>
<li><code><a title="dalex.Explainer.predict_parts" href="#dalex.Explainer.predict_parts">predict_parts</a></code></li>
<li><code><a title="dalex.Explainer.predict_profile" href="#dalex.Explainer.predict_profile">predict_profile</a></code></li>
<li><code><a title="dalex.Explainer.predict_surrogate" href="#dalex.Explainer.predict_surrogate">predict_surrogate</a></code></li>
<li><code><a title="dalex.Explainer.residual" href="#dalex.Explainer.residual">residual</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
</body>
</html>