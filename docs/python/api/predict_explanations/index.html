<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.1" />
<title>dalex.predict_explanations API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
<style>.homelink{display:block;font-size:2em;font-weight:bold;color:#555;padding-bottom:.5em;border-bottom:1px solid silver}.homelink:hover{color:inherit}.homelink img{max-width:50%;max-height:10em;margin:auto}</style>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>dalex.predict_explanations</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">from ._break_down.object import BreakDown
from ._ceteris_paribus.object import CeterisParibus
from ._shap.object import Shap

__all__ = [
    &#34;BreakDown&#34;,
    &#34;CeterisParibus&#34;,
    &#34;Shap&#34;
]</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="dalex.predict_explanations.BreakDown"><code class="flex name class">
<span>class <span class="ident">BreakDown</span></span>
<span>(</span><span>type='break_down', order=None, interaction_preference=1, keep_distributions=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Calculate predict-level variable attributions as Break Down</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>type</code></strong> :&ensp;<code>{'break_down_interactions', 'break_down'}</code></dt>
<dd>Type of variable attributions (default is <code>'break_down_interactions'</code>).</dd>
<dt><strong><code>order</code></strong> :&ensp;<code>list</code> of <code>int</code> or <code>str</code>, optional</dt>
<dd>Use a fixed order of variables for attribution calculation. Use integer values
or string variable names (default is <code>None</code> which means order by importance).</dd>
<dt><strong><code>interaction_preference</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>Specify which interactions will be present in an explanation. The larger the
integer, the more frequently interactions will be presented (default is <code>1</code>).</dd>
<dt><strong><code>keep_distributions</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>Save the distribution of partial predictions (default is <code>False</code>).</dd>
</dl>
<h2 id="attributes">Attributes</h2>
<dl>
<dt><strong><code>result</code></strong> :&ensp;<code>pd.DataFrame</code></dt>
<dd>Main result attribute of an explanation.</dd>
<dt><strong><code>type</code></strong> :&ensp;<code>{'break_down_interactions', 'break_down'}</code></dt>
<dd>Type of variable attributions.</dd>
<dt><strong><code>order</code></strong> :&ensp;<code>list</code> of <code>int</code> or <code>str</code> or <code>None</code></dt>
<dd>Order of variables used in attribution calculation.</dd>
<dt><strong><code>interaction_preference</code></strong> :&ensp;<code>int</code></dt>
<dd>Frequency of interaction use.</dd>
<dt><strong><code>keep_distributions</code></strong> :&ensp;<code>bool</code></dt>
<dd>Save the distribution of partial predictions.</dd>
<dt><strong><code>yhats_distributions</code></strong> :&ensp;<code>pd.DataFrame</code> or <code>None</code></dt>
<dd>The distribution of partial predictions.</dd>
</dl>
<h2 id="notes">Notes</h2>
<ul>
<li><a href="https://pbiecek.github.io/ema/breakDown.html">https://pbiecek.github.io/ema/breakDown.html</a></li>
<li><a href="https://pbiecek.github.io/ema/iBreakDown.html">https://pbiecek.github.io/ema/iBreakDown.html</a></li>
</ul></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class BreakDown:
    &#34;&#34;&#34;Calculate predict-level variable attributions as Break Down

    Parameters
    -----------
    type : {&#39;break_down_interactions&#39;, &#39;break_down&#39;}
        Type of variable attributions (default is `&#39;break_down_interactions&#39;`).
    order : list of int or str, optional
        Use a fixed order of variables for attribution calculation. Use integer values
        or string variable names (default is `None` which means order by importance).
    interaction_preference : int, optional
        Specify which interactions will be present in an explanation. The larger the
        integer, the more frequently interactions will be presented (default is `1`).
    keep_distributions : bool, optional
        Save the distribution of partial predictions (default is `False`).

    Attributes
    -----------
    result : pd.DataFrame
        Main result attribute of an explanation.
    type : {&#39;break_down_interactions&#39;, &#39;break_down&#39;}
        Type of variable attributions.
    order : list of int or str or None
        Order of variables used in attribution calculation.
    interaction_preference : int
        Frequency of interaction use.
    keep_distributions : bool
        Save the distribution of partial predictions.
    yhats_distributions : pd.DataFrame or None
        The distribution of partial predictions.

    Notes
    --------
    - https://pbiecek.github.io/ema/breakDown.html
    - https://pbiecek.github.io/ema/iBreakDown.html
    &#34;&#34;&#34;

    def __init__(self,
                 type=&#39;break_down&#39;,
                 order=None,
                 interaction_preference=1,
                 keep_distributions=False):

        _order = checks.check_order(order)

        self.type = type
        self.keep_distributions = keep_distributions
        self.order = _order
        self.interaction_preference = interaction_preference
        self.result = None
        self.yhats_distributions = None

    def _repr_html_(self):
        return self.result._repr_html_()

    def fit(self,
            explainer,
            new_observation):
        &#34;&#34;&#34;Calculate the result of explanation

        Fit method makes calculations in place and changes the attributes.

        Parameters
        -----------
        explainer : Explainer object
            Model wrapper created using the Explainer class.
        new_observation : pd.Series or np.ndarray
            An observation for which a prediction needs to be explained.

        Returns
        -----------
        None
        &#34;&#34;&#34;

        _new_observation = checks.check_new_observation(new_observation, explainer)
        if _new_observation.shape[0] != 1:
            warnings.warn(&#34;You should pass only one new_observation, taken only first&#34;)
            _new_observation = _new_observation.iloc[0, :]

        if self.type == &#39;break_down_interactions&#39;:
            result, yhats_distributions = utils.local_interactions(
                explainer,
                _new_observation,
                self.interaction_preference,
                &#39;2d&#39;,
                self.order,
                self.keep_distributions
            )
        elif self.type == &#39;break_down&#39;:
            result, yhats_distributions = utils.local_interactions(
                explainer,
                _new_observation,
                self.interaction_preference,
                &#39;1d&#39;,
                self.order,
                self.keep_distributions
            )
        else:
            raise ValueError(&#34;&#39;type&#39; must be one of {&#39;break_down_interactions&#39;, &#39;break_down&#39;}&#34;)

        self.result = result
        self.yhats_distributions = yhats_distributions

    def plot(self,
             objects=None,
             baseline=None,
             max_vars=10,
             digits=3,
             rounding_function=np.around,
             bar_width=16,
             min_max=None,
             vcolors=None,
             title=&#34;Break Down&#34;,
             vertical_spacing=None,
             show=True):
        &#34;&#34;&#34;Plot the Break Down explanation

        Parameters
        -----------
        objects : BreakDown object or array_like of BreakDown objects
            Additional objects to plot in subplots (default is `None`).
        baseline: float, optional
            Starting x point for bars (default is average prediction).
        max_vars : int, optional
            Maximum number of variables that will be presented for for each subplot
            (default is `10`).
        digits : int, optional
            Number of decimal places (`np.around`) to round contributions.
            See `rounding_function` parameter (default is `3`).
        rounding_function : function, optional
            A function that will be used for rounding numbers (default is `np.around`).
        bar_width : float, optional
            Width of bars in px (default is `16`).
        min_max : 2-tuple of float, optional
            Range of OX axis (default is `[min-0.15*(max-min), max+0.15*(max-min)]`).
        vcolors : 3-tuple of str, optional
            Color of bars (default is `[&#34;#371ea3&#34;, &#34;#8bdcbe&#34;, &#34;#f05a71&#34;]`).
        title : str, optional
            Title of the plot (default is `&#34;Break Down&#34;`).
        vertical_spacing : float &lt;0, 1&gt;, optional
            Ratio of vertical space between the plots (default is `0.2/number of rows`).
        show : bool, optional
            `True` shows the plot; `False` returns the plotly Figure object that can
            be edited or saved using the `write_image()` method (default is `True`).

        Returns
        -----------
        None or plotly.graph_objects.Figure
            Return figure that can be edited or saved. See `show` parameter.
        &#34;&#34;&#34;

        # are there any other objects to plot?
        if objects is None:
            n = 1
            _result_list = [self.result.copy()]
        elif isinstance(objects, self.__class__):  # allow for objects to be a single element
            n = 2
            _result_list = [self.result.copy(), objects.result.copy()]
        elif isinstance(objects, (list, tuple)):  # objects as tuple or array
            n = len(objects) + 1
            _result_list = [self.result.copy()]
            for ob in objects:
                _global_checks.global_check_object_class(ob, self.__class__)
                _result_list += [ob.result.copy()]
        else:
            _global_checks.global_raise_objects_class(objects, self.__class__)

        deleted_indexes = []
        for i, _result in enumerate(_result_list):
            if len(_result[&#39;label&#39;].unique()) &gt; 1:
                n += len(_result[&#39;label&#39;].unique()) - 1
                # add new data frames to list
                _result_list += [v for k, v in _result.groupby(&#39;label&#39;, sort=False)]

                deleted_indexes += [i]

        _result_list = [val for i, val in enumerate(_result_list) if i not in deleted_indexes]
        model_names = [result.iloc[0, result.columns.get_loc(&#34;label&#34;)] for result in _result_list]

        if vertical_spacing is None:
            vertical_spacing = 0.2 / n

        fig = make_subplots(rows=n, cols=1,
                            shared_xaxes=True, vertical_spacing=vertical_spacing,
                            x_title=&#39;contribution&#39;, subplot_titles=model_names)
        plot_height = 78 + 71

        if vcolors is None:
            vcolors = _theme.get_break_down_colors()

        if min_max is None:
            temp_min_max = [np.Inf, -np.Inf]
        else:
            temp_min_max = min_max

        for i, _result in enumerate(_result_list):
            if _result.shape[0] - 2 &lt;= max_vars:
                m = _result.shape[0]
            else:
                m = max_vars + 3

            if baseline is None:
                baseline = _result.iloc[0, _result.columns.get_loc(&#34;cumulative&#34;)]

            df = plot.prepare_data_for_break_down_plot(_result, baseline, max_vars, rounding_function, digits)

            measure = [&#34;relative&#34;] * m
            measure[m - 1] = &#34;total&#34;

            fig.add_shape(
                type=&#39;line&#39;,
                x0=baseline,
                x1=baseline,
                y0=-1,
                y1=m,
                yref=&#34;paper&#34;,
                xref=&#34;x&#34;,
                line={&#39;color&#39;: &#34;#371ea3&#34;, &#39;width&#39;: 1.5, &#39;dash&#39;: &#39;dot&#39;},
                row=i + 1, col=1
            )

            fig.add_waterfall(
                orientation=&#34;h&#34;,
                measure=measure,
                y=df[&#39;variable&#39;].tolist(),
                x=df[&#39;contribution&#39;].tolist(),
                textposition=&#34;outside&#34;,
                text=df[&#39;label_text&#39;].tolist(),
                connector={&#34;mode&#34;: &#34;spanning&#34;, &#34;line&#34;: {&#34;width&#34;: 1, &#34;color&#34;: &#34;#371ea3&#34;, &#34;dash&#34;: &#34;solid&#34;}},
                decreasing={&#34;marker&#34;: {&#34;color&#34;: vcolors[-1]}},
                increasing={&#34;marker&#34;: {&#34;color&#34;: vcolors[1]}},
                totals={&#34;marker&#34;: {&#34;color&#34;: vcolors[0]}},
                base=baseline,
                hovertext=df[&#39;tooltip_text&#39;].tolist(),
                hoverinfo=&#39;text+delta&#39;,
                hoverlabel={&#39;bgcolor&#39;: &#39;rgba(0,0,0,0.8)&#39;},
                showlegend=False,
                row=i + 1, col=1
            )

            fig.update_yaxes({&#39;type&#39;: &#39;category&#39;, &#39;autorange&#39;: &#39;reversed&#39;, &#39;gridwidth&#39;: 2, &#39;automargin&#39;: True,
                              &#39;ticks&#39;: &#34;outside&#34;, &#39;tickcolor&#39;: &#39;white&#39;, &#39;ticklen&#39;: 10, &#39;fixedrange&#39;: True},
                             row=i + 1, col=1)

            if min_max is None:
                cum = df.cumulative.values
                min_max_margin = cum.ptp() * 0.15
                temp_min_max[0] = np.min([temp_min_max[0], cum.min() - min_max_margin])
                temp_min_max[1] = np.max([temp_min_max[1], cum.max() + min_max_margin])

            fig.update_xaxes({&#39;type&#39;: &#39;linear&#39;, &#39;gridwidth&#39;: 2, &#39;zeroline&#39;: False, &#39;automargin&#39;: True,
                              &#39;ticks&#39;: &#34;outside&#34;, &#39;tickcolor&#39;: &#39;white&#39;, &#39;ticklen&#39;: 3, &#39;fixedrange&#39;: True},
                             row=i + 1, col=1)

            plot_height += m * bar_width + (m + 1) * bar_width / 4

        plot_height += (n - 1) * 70

        fig.update_xaxes({&#39;range&#39;: temp_min_max})
        fig.update_layout(title_text=title, title_x=0.15, font={&#39;color&#39;: &#34;#371ea3&#34;}, template=&#34;none&#34;,
                          height=plot_height, margin={&#39;t&#39;: 78, &#39;b&#39;: 71, &#39;r&#39;: 30})

        if show:
            fig.show(config=_theme.get_default_config())
        else:
            return fig</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="dalex.predict_explanations.BreakDown.fit"><code class="name flex">
<span>def <span class="ident">fit</span></span>(<span>self, explainer, new_observation)</span>
</code></dt>
<dd>
<div class="desc"><p>Calculate the result of explanation</p>
<p>Fit method makes calculations in place and changes the attributes.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>explainer</code></strong> :&ensp;<code>Explainer object</code></dt>
<dd>Model wrapper created using the Explainer class.</dd>
<dt><strong><code>new_observation</code></strong> :&ensp;<code>pd.Series</code> or <code>np.ndarray</code></dt>
<dd>An observation for which a prediction needs to be explained.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>None</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def fit(self,
        explainer,
        new_observation):
    &#34;&#34;&#34;Calculate the result of explanation

    Fit method makes calculations in place and changes the attributes.

    Parameters
    -----------
    explainer : Explainer object
        Model wrapper created using the Explainer class.
    new_observation : pd.Series or np.ndarray
        An observation for which a prediction needs to be explained.

    Returns
    -----------
    None
    &#34;&#34;&#34;

    _new_observation = checks.check_new_observation(new_observation, explainer)
    if _new_observation.shape[0] != 1:
        warnings.warn(&#34;You should pass only one new_observation, taken only first&#34;)
        _new_observation = _new_observation.iloc[0, :]

    if self.type == &#39;break_down_interactions&#39;:
        result, yhats_distributions = utils.local_interactions(
            explainer,
            _new_observation,
            self.interaction_preference,
            &#39;2d&#39;,
            self.order,
            self.keep_distributions
        )
    elif self.type == &#39;break_down&#39;:
        result, yhats_distributions = utils.local_interactions(
            explainer,
            _new_observation,
            self.interaction_preference,
            &#39;1d&#39;,
            self.order,
            self.keep_distributions
        )
    else:
        raise ValueError(&#34;&#39;type&#39; must be one of {&#39;break_down_interactions&#39;, &#39;break_down&#39;}&#34;)

    self.result = result
    self.yhats_distributions = yhats_distributions</code></pre>
</details>
</dd>
<dt id="dalex.predict_explanations.BreakDown.plot"><code class="name flex">
<span>def <span class="ident">plot</span></span>(<span>self, objects=None, baseline=None, max_vars=10, digits=3, rounding_function=&lt;function around&gt;, bar_width=16, min_max=None, vcolors=None, title='Break Down', vertical_spacing=None, show=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Plot the Break Down explanation</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>objects</code></strong> :&ensp;<code><a title="dalex.predict_explanations.BreakDown" href="#dalex.predict_explanations.BreakDown">BreakDown</a> object</code> or <code>array_like</code> of <code><a title="dalex.predict_explanations.BreakDown" href="#dalex.predict_explanations.BreakDown">BreakDown</a> objects</code></dt>
<dd>Additional objects to plot in subplots (default is <code>None</code>).</dd>
<dt><strong><code>baseline</code></strong> :&ensp;<code>float</code>, optional</dt>
<dd>Starting x point for bars (default is average prediction).</dd>
<dt><strong><code>max_vars</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>Maximum number of variables that will be presented for for each subplot
(default is <code>10</code>).</dd>
<dt><strong><code>digits</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>Number of decimal places (<code>np.around</code>) to round contributions.
See <code>rounding_function</code> parameter (default is <code>3</code>).</dd>
<dt><strong><code>rounding_function</code></strong> :&ensp;<code>function</code>, optional</dt>
<dd>A function that will be used for rounding numbers (default is <code>np.around</code>).</dd>
<dt><strong><code>bar_width</code></strong> :&ensp;<code>float</code>, optional</dt>
<dd>Width of bars in px (default is <code>16</code>).</dd>
<dt><strong><code>min_max</code></strong> :&ensp;<code>2-tuple</code> of <code>float</code>, optional</dt>
<dd>Range of OX axis (default is <code>[min-0.15*(max-min), max+0.15*(max-min)]</code>).</dd>
<dt><strong><code>vcolors</code></strong> :&ensp;<code>3-tuple</code> of <code>str</code>, optional</dt>
<dd>Color of bars (default is <code>["#371ea3", "#8bdcbe", "#f05a71"]</code>).</dd>
<dt><strong><code>title</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>Title of the plot (default is <code>"Break Down"</code>).</dd>
<dt><strong><code>vertical_spacing</code></strong> :&ensp;<code>float &lt;0, 1&gt;</code>, optional</dt>
<dd>Ratio of vertical space between the plots (default is <code>0.2/number of rows</code>).</dd>
<dt><strong><code>show</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd><code>True</code> shows the plot; <code>False</code> returns the plotly Figure object that can
be edited or saved using the <code>write_image()</code> method (default is <code>True</code>).</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>None</code> or <code>plotly.graph_objects.Figure</code></dt>
<dd>Return figure that can be edited or saved. See <code>show</code> parameter.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def plot(self,
         objects=None,
         baseline=None,
         max_vars=10,
         digits=3,
         rounding_function=np.around,
         bar_width=16,
         min_max=None,
         vcolors=None,
         title=&#34;Break Down&#34;,
         vertical_spacing=None,
         show=True):
    &#34;&#34;&#34;Plot the Break Down explanation

    Parameters
    -----------
    objects : BreakDown object or array_like of BreakDown objects
        Additional objects to plot in subplots (default is `None`).
    baseline: float, optional
        Starting x point for bars (default is average prediction).
    max_vars : int, optional
        Maximum number of variables that will be presented for for each subplot
        (default is `10`).
    digits : int, optional
        Number of decimal places (`np.around`) to round contributions.
        See `rounding_function` parameter (default is `3`).
    rounding_function : function, optional
        A function that will be used for rounding numbers (default is `np.around`).
    bar_width : float, optional
        Width of bars in px (default is `16`).
    min_max : 2-tuple of float, optional
        Range of OX axis (default is `[min-0.15*(max-min), max+0.15*(max-min)]`).
    vcolors : 3-tuple of str, optional
        Color of bars (default is `[&#34;#371ea3&#34;, &#34;#8bdcbe&#34;, &#34;#f05a71&#34;]`).
    title : str, optional
        Title of the plot (default is `&#34;Break Down&#34;`).
    vertical_spacing : float &lt;0, 1&gt;, optional
        Ratio of vertical space between the plots (default is `0.2/number of rows`).
    show : bool, optional
        `True` shows the plot; `False` returns the plotly Figure object that can
        be edited or saved using the `write_image()` method (default is `True`).

    Returns
    -----------
    None or plotly.graph_objects.Figure
        Return figure that can be edited or saved. See `show` parameter.
    &#34;&#34;&#34;

    # are there any other objects to plot?
    if objects is None:
        n = 1
        _result_list = [self.result.copy()]
    elif isinstance(objects, self.__class__):  # allow for objects to be a single element
        n = 2
        _result_list = [self.result.copy(), objects.result.copy()]
    elif isinstance(objects, (list, tuple)):  # objects as tuple or array
        n = len(objects) + 1
        _result_list = [self.result.copy()]
        for ob in objects:
            _global_checks.global_check_object_class(ob, self.__class__)
            _result_list += [ob.result.copy()]
    else:
        _global_checks.global_raise_objects_class(objects, self.__class__)

    deleted_indexes = []
    for i, _result in enumerate(_result_list):
        if len(_result[&#39;label&#39;].unique()) &gt; 1:
            n += len(_result[&#39;label&#39;].unique()) - 1
            # add new data frames to list
            _result_list += [v for k, v in _result.groupby(&#39;label&#39;, sort=False)]

            deleted_indexes += [i]

    _result_list = [val for i, val in enumerate(_result_list) if i not in deleted_indexes]
    model_names = [result.iloc[0, result.columns.get_loc(&#34;label&#34;)] for result in _result_list]

    if vertical_spacing is None:
        vertical_spacing = 0.2 / n

    fig = make_subplots(rows=n, cols=1,
                        shared_xaxes=True, vertical_spacing=vertical_spacing,
                        x_title=&#39;contribution&#39;, subplot_titles=model_names)
    plot_height = 78 + 71

    if vcolors is None:
        vcolors = _theme.get_break_down_colors()

    if min_max is None:
        temp_min_max = [np.Inf, -np.Inf]
    else:
        temp_min_max = min_max

    for i, _result in enumerate(_result_list):
        if _result.shape[0] - 2 &lt;= max_vars:
            m = _result.shape[0]
        else:
            m = max_vars + 3

        if baseline is None:
            baseline = _result.iloc[0, _result.columns.get_loc(&#34;cumulative&#34;)]

        df = plot.prepare_data_for_break_down_plot(_result, baseline, max_vars, rounding_function, digits)

        measure = [&#34;relative&#34;] * m
        measure[m - 1] = &#34;total&#34;

        fig.add_shape(
            type=&#39;line&#39;,
            x0=baseline,
            x1=baseline,
            y0=-1,
            y1=m,
            yref=&#34;paper&#34;,
            xref=&#34;x&#34;,
            line={&#39;color&#39;: &#34;#371ea3&#34;, &#39;width&#39;: 1.5, &#39;dash&#39;: &#39;dot&#39;},
            row=i + 1, col=1
        )

        fig.add_waterfall(
            orientation=&#34;h&#34;,
            measure=measure,
            y=df[&#39;variable&#39;].tolist(),
            x=df[&#39;contribution&#39;].tolist(),
            textposition=&#34;outside&#34;,
            text=df[&#39;label_text&#39;].tolist(),
            connector={&#34;mode&#34;: &#34;spanning&#34;, &#34;line&#34;: {&#34;width&#34;: 1, &#34;color&#34;: &#34;#371ea3&#34;, &#34;dash&#34;: &#34;solid&#34;}},
            decreasing={&#34;marker&#34;: {&#34;color&#34;: vcolors[-1]}},
            increasing={&#34;marker&#34;: {&#34;color&#34;: vcolors[1]}},
            totals={&#34;marker&#34;: {&#34;color&#34;: vcolors[0]}},
            base=baseline,
            hovertext=df[&#39;tooltip_text&#39;].tolist(),
            hoverinfo=&#39;text+delta&#39;,
            hoverlabel={&#39;bgcolor&#39;: &#39;rgba(0,0,0,0.8)&#39;},
            showlegend=False,
            row=i + 1, col=1
        )

        fig.update_yaxes({&#39;type&#39;: &#39;category&#39;, &#39;autorange&#39;: &#39;reversed&#39;, &#39;gridwidth&#39;: 2, &#39;automargin&#39;: True,
                          &#39;ticks&#39;: &#34;outside&#34;, &#39;tickcolor&#39;: &#39;white&#39;, &#39;ticklen&#39;: 10, &#39;fixedrange&#39;: True},
                         row=i + 1, col=1)

        if min_max is None:
            cum = df.cumulative.values
            min_max_margin = cum.ptp() * 0.15
            temp_min_max[0] = np.min([temp_min_max[0], cum.min() - min_max_margin])
            temp_min_max[1] = np.max([temp_min_max[1], cum.max() + min_max_margin])

        fig.update_xaxes({&#39;type&#39;: &#39;linear&#39;, &#39;gridwidth&#39;: 2, &#39;zeroline&#39;: False, &#39;automargin&#39;: True,
                          &#39;ticks&#39;: &#34;outside&#34;, &#39;tickcolor&#39;: &#39;white&#39;, &#39;ticklen&#39;: 3, &#39;fixedrange&#39;: True},
                         row=i + 1, col=1)

        plot_height += m * bar_width + (m + 1) * bar_width / 4

    plot_height += (n - 1) * 70

    fig.update_xaxes({&#39;range&#39;: temp_min_max})
    fig.update_layout(title_text=title, title_x=0.15, font={&#39;color&#39;: &#34;#371ea3&#34;}, template=&#34;none&#34;,
                      height=plot_height, margin={&#39;t&#39;: 78, &#39;b&#39;: 71, &#39;r&#39;: 30})

    if show:
        fig.show(config=_theme.get_default_config())
    else:
        return fig</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="dalex.predict_explanations.CeterisParibus"><code class="flex name class">
<span>class <span class="ident">CeterisParibus</span></span>
<span>(</span><span>variables=None, grid_points=101, variable_splits=None, variable_splits_type='uniform', variable_splits_with_obs=False, processes=1)</span>
</code></dt>
<dd>
<div class="desc"><p>Calculate predict-level variable profiles as Ceteris Paribus</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>variables</code></strong> :&ensp;<code>array_like</code> of <code>str</code>, optional</dt>
<dd>Variables for which the profiles will be calculated
(default is <code>None</code>, which means all of the variables).</dd>
<dt><strong><code>grid_points</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>Maximum number of points for profile calculations (default is <code>101</code>).
NOTE: The final number of points may be lower than <code>grid_points</code>,
eg. if there is not enough unique values for a given variable.</dd>
<dt><strong><code>variable_splits</code></strong> :&ensp;<code>dict</code> of <code>lists</code>, optional</dt>
<dd>Split points for variables e.g. <code>{'x': [0, 0.2, 0.5, 0.8, 1], 'y': ['a', 'b']}</code>
(default is <code>None</code>, which means that they will be calculated using one of
<code>variable_splits_type</code> and the <code>data</code> attribute).</dd>
<dt><strong><code>variable_splits_type</code></strong> :&ensp;<code>{'uniform', 'quantiles'}</code>, optional</dt>
<dd>Way of calculating <code>variable_splits</code>. Set <code>'quantiles'</code> for percentiles.
(default is <code>'uniform'</code>, which means uniform grid of points).</dd>
<dt><strong><code>variable_splits_with_obs</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>Add variable values of <code>new_observation</code> data to the <code>variable_splits</code>
(default is <code>True</code>).</dd>
<dt><strong><code>processes</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>Number of parallel processes to use in calculations. Iterated over <code>variables</code>
(default is <code>1</code>, which means no parallel computation).</dd>
</dl>
<h2 id="attributes">Attributes</h2>
<dl>
<dt><strong><code>result</code></strong> :&ensp;<code>pd.DataFrame</code></dt>
<dd>Main result attribute of an explanation.</dd>
<dt><strong><code>new_observation</code></strong> :&ensp;<code>pd.DataFrame</code></dt>
<dd>Observations for which predictions need to be explained.</dd>
<dt><strong><code>variables</code></strong> :&ensp;<code>array_like</code> of <code>str</code> or <code>None</code></dt>
<dd>Variables for which the profiles will be calculated.</dd>
<dt><strong><code>grid_points</code></strong> :&ensp;<code>int</code></dt>
<dd>Maximum number of points for profile calculations.</dd>
<dt><strong><code>variable_splits</code></strong> :&ensp;<code>dict</code> of <code>lists</code> or <code>None</code></dt>
<dd>Split points for variables.</dd>
<dt><strong><code>variable_splits_type</code></strong> :&ensp;<code>{'uniform', 'quantiles'}</code></dt>
<dd>Way of calculating <code>variable_splits</code>.</dd>
<dt><strong><code>variable_splits_with_obs</code></strong> :&ensp;<code>bool</code></dt>
<dd>Add variable values of <code>new_observation</code> data to the <code>variable_splits</code>.</dd>
<dt><strong><code>processes</code></strong> :&ensp;<code>int</code></dt>
<dd>Number of parallel processes to use in calculations. Iterated over <code>B</code>.</dd>
</dl>
<h2 id="notes">Notes</h2>
<ul>
<li><a href="https://pbiecek.github.io/ema/ceterisParibus.html">https://pbiecek.github.io/ema/ceterisParibus.html</a></li>
</ul></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class CeterisParibus:
    &#34;&#34;&#34;Calculate predict-level variable profiles as Ceteris Paribus

    Parameters
    -----------
    variables : array_like of str, optional
        Variables for which the profiles will be calculated
        (default is `None`, which means all of the variables).
    grid_points : int, optional
        Maximum number of points for profile calculations (default is `101`).
        NOTE: The final number of points may be lower than `grid_points`,
        eg. if there is not enough unique values for a given variable.
    variable_splits : dict of lists, optional
        Split points for variables e.g. `{&#39;x&#39;: [0, 0.2, 0.5, 0.8, 1], &#39;y&#39;: [&#39;a&#39;, &#39;b&#39;]}`
        (default is `None`, which means that they will be calculated using one of
        `variable_splits_type` and the `data` attribute).
    variable_splits_type : {&#39;uniform&#39;, &#39;quantiles&#39;}, optional
        Way of calculating `variable_splits`. Set `&#39;quantiles&#39;` for percentiles.
        (default is `&#39;uniform&#39;`, which means uniform grid of points).
    variable_splits_with_obs: bool, optional
        Add variable values of `new_observation` data to the `variable_splits`
        (default is `True`).
    processes : int, optional
        Number of parallel processes to use in calculations. Iterated over `variables`
        (default is `1`, which means no parallel computation).

    Attributes
    -----------
    result : pd.DataFrame
        Main result attribute of an explanation.
    new_observation : pd.DataFrame
        Observations for which predictions need to be explained.
    variables : array_like of str or None
        Variables for which the profiles will be calculated.
    grid_points : int
        Maximum number of points for profile calculations.
    variable_splits : dict of lists or None
        Split points for variables.
    variable_splits_type : {&#39;uniform&#39;, &#39;quantiles&#39;}
        Way of calculating `variable_splits`.
    variable_splits_with_obs: bool
        Add variable values of `new_observation` data to the `variable_splits`.
    processes : int
        Number of parallel processes to use in calculations. Iterated over `B`.

    Notes
    --------
    - https://pbiecek.github.io/ema/ceterisParibus.html
    &#34;&#34;&#34;

    def __init__(self,
                 variables=None,
                 grid_points=101,
                 variable_splits=None,
                 variable_splits_type=&#39;uniform&#39;,
                 variable_splits_with_obs=False,
                 processes=1):

        _processes = checks.check_processes(processes)
        _variable_splits_type = checks.check_variable_splits_type(variable_splits_type)

        self.variables = variables
        self.grid_points = grid_points
        self.variable_splits = variable_splits
        self.variable_splits_type = _variable_splits_type
        self.variable_splits_with_obs = variable_splits_with_obs
        self.result = None
        self.new_observation = None
        self.processes = _processes

    def _repr_html_(self):
        return self.result._repr_html_()

    def fit(self,
            explainer,
            new_observation,
            y=None,
            verbose=True):
        &#34;&#34;&#34;Calculate the result of explanation

        Fit method makes calculations in place and changes the attributes.

        Parameters
        -----------
        explainer : Explainer object
            Model wrapper created using the Explainer class.
        new_observation : pd.DataFrame or np.ndarray
            Observations for which predictions need to be explained.
        y : pd.Series or np.ndarray (1d), optional
            Target variable with the same length as `new_observation`.
        verbose : bool, optional
            Print tqdm progress bar (default is `True`).

        Returns
        -----------
        None
        &#34;&#34;&#34;

        self.variables = checks.check_variables(self.variables, explainer, self.variable_splits)

        checks.check_data(explainer.data, self.variables)

        self.new_observation = checks.check_new_observation(new_observation, explainer)

        self.variable_splits = checks.check_variable_splits(self.variable_splits,
                                                     self.variables,
                                                     self.grid_points,
                                                     explainer.data,
                                                     self.variable_splits_type,
                                                     self.variable_splits_with_obs,
                                                     self.new_observation)

        y = checks.check_y(y)

        self.result, self.new_observation = utils.calculate_ceteris_paribus(
            explainer,
            self.new_observation,
            self.variable_splits,
            y,
            self.processes,
            verbose
        )

    def plot(self,
             objects=None,
             variable_type=&#34;numerical&#34;,
             variables=None,
             size=2,
             alpha=1,
             color=&#34;_label_&#34;,
             facet_ncol=2,
             show_observations=True,
             title=&#34;Ceteris Paribus Profiles&#34;,
             y_title=&#39;prediction&#39;,
             horizontal_spacing=None,
             vertical_spacing=None,
             show=True):
        &#34;&#34;&#34;Plot the Ceteris Paribus explanation

        Parameters
        -----------
        objects : CeterisParibus object or array_like of CeterisParibus objects
            Additional objects to plot in subplots (default is `None`).
        variable_type : {&#39;numerical&#39;, &#39;categorical&#39;}
            Plot the profiles for numerical or categorical variables 
            (default is `&#39;numerical&#39;`).
        variables : str or array_like of str, optional
            Variables for which the profiles will be calculated
            (default is `None`, which means all of the variables).
        size : float, optional
            Width of lines in px (default is `2`).
        alpha : float &lt;0, 1&gt;, optional
            Opacity of lines (default is `1`).
        color : str, optional
            Variable name used for grouping
            (default is `&#39;_label_&#39;`, which groups by models).
        facet_ncol : int, optional
            Number of columns on the plot grid (default is `2`).
        show_observations : bool, optional
            Show observation points (default is `True`).
        title : str, optional
            Title of the plot (default is `&#34;Ceteris Paribus Profiles&#34;`).
        y_title : str, optional
            Title of the y/x axis (default is `&#34;prediction&#34;`).
        horizontal_spacing : float &lt;0, 1&gt;, optional
            Ratio of horizontal space between the plots
            (default depends on `variable_type`).
        vertical_spacing : float &lt;0, 1&gt;, optional
            Ratio of vertical space between the plots (default is `0.3/number of rows`).
        show : bool, optional
            `True` shows the plot; `False` returns the plotly Figure object that can 
            be edited or saved using the `write_image()` method (default is `True`).

        Returns
        -----------
        None or plotly.graph_objects.Figure
            Return figure that can be edited or saved. See `show` parameter.
        &#34;&#34;&#34;

        if variable_type not in (&#34;numerical&#34;, &#34;categorical&#34;):
            raise TypeError(&#34;variable_type should be &#39;numerical&#39; or &#39;categorical&#39;&#34;)
        if isinstance(variables, str):
            variables = (variables,)

        # are there any other objects to plot?
        if objects is None:
            _result_df = self.result.assign(_original_yhat_=lambda x: self.new_observation.loc[x.index, &#39;_yhat_&#39;])
            _include = self.variable_splits_with_obs
        elif isinstance(objects, self.__class__):  # allow for objects to be a single element
            _result_df = pd.concat([
                self.result.assign(_original_yhat_=lambda x: self.new_observation.loc[x.index, &#39;_yhat_&#39;]),
                objects.result.assign(_original_yhat_=lambda x: objects.new_observation.loc[x.index, &#39;_yhat_&#39;])])
            _include = np.all([self.variable_splits_with_obs, objects.variable_splits_with_obs])
        elif isinstance(objects, (list, tuple)):  # objects as tuple or array
            _result_df = self.result.assign(_original_yhat_=lambda x: self.new_observation.loc[x.index, &#39;_yhat_&#39;])
            _include = [self.variable_splits_with_obs]
            for ob in objects:
                _global_checks.global_check_object_class(ob, self.__class__)
                _result_df = pd.concat([
                    _result_df, ob.result.assign(_original_yhat_=lambda x: ob.new_observation.loc[x.index, &#39;_yhat_&#39;])])
                _include += [ob.variable_splits_with_obs]
            _include = np.all(_include)
        else:
            _global_checks.global_raise_objects_class(objects, self.__class__)

        if _include is False and show_observations:
                warnings.warn(&#34;&#39;show_observations&#39; parameter changed to False,&#34;
                              &#34;because the &#39;variable_splits_with_obs&#39; attribute is False&#34;
                              &#34;See `variable_splits_with_obs` parameter in `predict_profile`.&#34;)
                show_observations = False

        # variables to use
        all_variables = list(_result_df[&#39;_vname_&#39;].dropna().unique())

        if variables is not None:
            all_variables = _global_utils.intersect_unsorted(variables, all_variables)
            if len(all_variables) == 0:
                raise TypeError(&#34;variables do not overlap with &#34; + &#39;&#39;.join(variables))

        # names of numeric variables
        numeric_variables = _result_df[all_variables].select_dtypes(include=np.number).columns.tolist()

        if variable_type == &#34;numerical&#34;:
            variable_names = numeric_variables

            if len(variable_names) == 0:
                # change to categorical
                variable_type = &#34;categorical&#34;
                # send message
                warnings.warn(&#34;&#39;variable_type&#39; parameter changed to &#39;categorical&#39; due to lack of numerical variables.&#34;)
                # take all
                variable_names = all_variables
            elif variables is not None and len(variable_names) != len(variables):
                raise TypeError(&#34;There are no numerical variables&#34;)
        else:
            variable_names = np.setdiff1d(all_variables, numeric_variables).tolist()

            # there are variables selected
            if variables is not None:
                # take all
                variable_names = all_variables
            elif len(variable_names) == 0:
                # there were no variables selected and there are no categorical variables
                raise TypeError(&#34;There are no non-numerical variables.&#34;)

        # prepare profiles data
        _result_df = _result_df.loc[_result_df[&#39;_vname_&#39;].isin(variable_names), ].reset_index(drop=True)

        #  calculate y axis range to allow for fixedrange True
        dl = _result_df[&#39;_yhat_&#39;].to_numpy()
        min_max_margin = dl.ptp() * 0.10
        min_max = [dl.min() - min_max_margin, dl.max() + min_max_margin]

        # create _x_
        if len(variable_names) == 1:
            _result_df.loc[:, &#39;_x_&#39;] = deepcopy(_result_df.loc[:, variable_names[0]])
        else:
            for variable in variable_names:
                where_variable = _result_df[&#39;_vname_&#39;] == variable
                _result_df.loc[where_variable, &#39;_x_&#39;] = deepcopy(_result_df.loc[where_variable, variable])

        # change x column to proper character values
        if variable_type == &#39;categorical&#39;:
            _result_df.loc[:, &#39;_x_&#39;] = _result_df.apply(lambda row: str(row[row[&#39;_vname_&#39;]]), axis=1)

        n = len(variable_names)
        facet_nrow = int(np.ceil(n / facet_ncol))
        if vertical_spacing is None:
            vertical_spacing = 0.3 / facet_nrow if variable_type == &#39;numerical&#39; else 0.05
        if horizontal_spacing is None:
            horizontal_spacing = 0.05 if variable_type == &#39;numerical&#39; else 0.1

        plot_height = 78 + 71 + facet_nrow * (280 + 60)

        _result_df = _result_df.assign(_text_=_result_df.apply(lambda obs: plot.tooltip_text(obs), axis=1))

        if variable_type == &#34;numerical&#34;:    
            m = len(_result_df[color].dropna().unique())
            _result_df[color] = _result_df[color].astype(object)  # prevent error when using pd.StringDtype
        
            fig = px.line(_result_df,
                          x=&#34;_x_&#34;, y=&#34;_yhat_&#34;, color=color, facet_col=&#34;_vname_&#34;, line_group=&#39;_ids_&#39;,
                          category_orders={&#34;_vname_&#34;: list(variable_names)},
                          labels={&#39;_yhat_&#39;: &#39;prediction&#39;, &#39;_label_&#39;: &#39;label&#39;, &#39;_ids_&#39;: &#39;id&#39;},  # , color: &#39;group&#39;},
                          # hover_data={&#39;_text_&#39;: True, &#39;_yhat_&#39;: &#39;:.3f&#39;, &#39;_vname_&#39;: False, &#39;_x_&#39;: False, color: False},
                          custom_data=[&#39;_text_&#39;],
                          facet_col_wrap=facet_ncol,
                          facet_row_spacing=vertical_spacing,
                          facet_col_spacing=horizontal_spacing,
                          template=&#34;none&#34;,
                          color_discrete_sequence=_theme.get_default_colors(m, &#39;line&#39;)) \
                    .update_traces(dict(line_width=size, opacity=alpha,
                                        hovertemplate=&#34;%{customdata[0]}&lt;extra&gt;&lt;/extra&gt;&#34;)) \
                    .update_xaxes({&#39;matches&#39;: None, &#39;showticklabels&#39;: True,
                                   &#39;type&#39;: &#39;linear&#39;, &#39;gridwidth&#39;: 2, &#39;zeroline&#39;: False, &#39;automargin&#39;: True,
                                   &#39;ticks&#39;: &#34;outside&#34;, &#39;tickcolor&#39;: &#39;white&#39;, &#39;ticklen&#39;: 3, &#39;fixedrange&#39;: True}) \
                    .update_yaxes({&#39;type&#39;: &#39;linear&#39;, &#39;gridwidth&#39;: 2, &#39;zeroline&#39;: False, &#39;automargin&#39;: True,
                                   &#39;ticks&#39;: &#39;outside&#39;, &#39;tickcolor&#39;: &#39;white&#39;, &#39;ticklen&#39;: 3, &#39;fixedrange&#39;: True,
                                   &#39;range&#39;: min_max})

            if show_observations:
                _points_df = _result_df.loc[_result_df[&#39;_original_&#39;] == _result_df[&#39;_x_&#39;], :].copy()

                fig_points = px.scatter(_points_df,
                                        x=&#39;_original_&#39;, y=&#39;_yhat_&#39;, facet_col=&#39;_vname_&#39;,
                                        category_orders={&#34;_vname_&#34;: list(variable_names)},
                                        labels={&#39;_yhat_&#39;: &#39;prediction&#39;, &#39;_label_&#39;: &#39;label&#39;, &#39;_ids_&#39;: &#39;id&#39;},
                                        custom_data=[&#39;_text_&#39;],
                                        facet_col_wrap=facet_ncol,
                                        facet_row_spacing=vertical_spacing,
                                        facet_col_spacing=horizontal_spacing,
                                        color_discrete_sequence=[&#34;#371ea3&#34;]) \
                               .update_traces(dict(marker_size=5*size, opacity=alpha),
                                              hovertemplate=&#34;%{customdata[0]}&lt;extra&gt;&lt;/extra&gt;&#34;)

                for _, value in enumerate(fig_points.data):
                    fig.add_trace(value)
                    
                fig = _theme.fig_update_line_plot(fig, title, y_title, plot_height, &#39;closest&#39;)

        else:
            if color==&#34;_label_&#34; and len(_result_df[&#39;_ids_&#39;].unique()) &gt; 1 and len(_result_df[&#39;_label_&#39;].unique()) == 1:
                warnings.warn(&#34;&#39;color&#39; parameter changed to &#39;_ids_&#39; because there are multiple observations for one model.&#34;)
                color = &#39;_ids_&#39;
            elif color==&#34;_label_&#34; and len(_result_df[&#39;_ids_&#39;].unique()) != len(_result_df[&#39;_label_&#39;].unique()): 
                # https://github.com/plotly/plotly.py/issues/2657
                raise TypeError(&#34;Please pick one observation per label or change the `color` parameter.&#34;)

            m = len(_result_df[color].dropna().unique())
            _result_df[color] = _result_df[color].astype(object)  # prevent error when using pd.StringDtype
            
            _result_df = _result_df.assign(_diff_=lambda x: x[&#39;_yhat_&#39;] - x[&#39;_original_yhat_&#39;])
            fig = px.bar(_result_df,
                         x=&#34;_diff_&#34;, y=&#34;_x_&#34;, color=color, facet_col=&#34;_vname_&#34;,
                         category_orders={&#34;_vname_&#34;: list(variable_names)},
                         labels={&#39;_yhat_&#39;: &#39;prediction&#39;, &#39;_label_&#39;: &#39;label&#39;, &#39;_ids_&#39;: &#39;id&#39;},  # , color: &#39;group&#39;},
                         # hover_data={&#39;_yhat_&#39;: &#39;:.3f&#39;, &#39;_ids_&#39;: True, &#39;_vname_&#39;: False, color: False},
                         custom_data=[&#39;_text_&#39;],
                         base=&#34;_original_yhat_&#34;,
                         facet_col_wrap=facet_ncol,
                         facet_row_spacing=vertical_spacing,
                         facet_col_spacing=horizontal_spacing,
                         template=&#34;none&#34;,
                         color_discrete_sequence=_theme.get_default_colors(m, &#39;line&#39;),
                         barmode=&#39;group&#39;,
                         orientation=&#39;h&#39;)  \
                    .update_traces(dict(opacity=alpha),
                                   hovertemplate=&#34;%{customdata[0]}&lt;extra&gt;&lt;/extra&gt;&#34;) \
                    .update_yaxes({&#39;matches&#39;: None, &#39;showticklabels&#39;: True,
                                   &#39;type&#39;: &#39;category&#39;, &#39;gridwidth&#39;: 2, &#39;automargin&#39;: True, 
                                   &#39;ticks&#39;: &#34;outside&#34;, &#39;tickcolor&#39;: &#39;white&#39;, &#39;ticklen&#39;: 10, &#39;fixedrange&#39;: True}) \
                    .update_xaxes({&#39;type&#39;: &#39;linear&#39;, &#39;gridwidth&#39;: 2, &#39;zeroline&#39;: False, &#39;automargin&#39;: True,
                                   &#39;ticks&#39;: &#39;outside&#39;, &#39;tickcolor&#39;: &#39;white&#39;, &#39;ticklen&#39;: 3, &#39;fixedrange&#39;: True,
                                   &#39;range&#39;: min_max})

            # add hline https://github.com/plotly/plotly.py/issues/2141
            for _, bar in enumerate(fig.data):
                fig.add_vline(x=bar.base[0], layer=&#39;below&#39;,
                              line={&#39;color&#39;: &#34;#371ea3&#34;, &#39;width&#39;: 1.5, &#39;dash&#39;: &#39;dot&#39;})

            fig = _theme.fig_update_bar_plot(fig, title, y_title, plot_height, &#39;closest&#39;)
            
        fig.update_layout(hoverlabel=dict(bgcolor=&#39;rgba(0,0,0,0.8)&#39;))
        if show:
            fig.show(config=_theme.get_default_config())
        else:
            return fig</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="dalex.predict_explanations.CeterisParibus.fit"><code class="name flex">
<span>def <span class="ident">fit</span></span>(<span>self, explainer, new_observation, y=None, verbose=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Calculate the result of explanation</p>
<p>Fit method makes calculations in place and changes the attributes.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>explainer</code></strong> :&ensp;<code>Explainer object</code></dt>
<dd>Model wrapper created using the Explainer class.</dd>
<dt><strong><code>new_observation</code></strong> :&ensp;<code>pd.DataFrame</code> or <code>np.ndarray</code></dt>
<dd>Observations for which predictions need to be explained.</dd>
<dt><strong><code>y</code></strong> :&ensp;<code>pd.Series</code> or <code>np.ndarray (1d)</code>, optional</dt>
<dd>Target variable with the same length as <code>new_observation</code>.</dd>
<dt><strong><code>verbose</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>Print tqdm progress bar (default is <code>True</code>).</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>None</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def fit(self,
        explainer,
        new_observation,
        y=None,
        verbose=True):
    &#34;&#34;&#34;Calculate the result of explanation

    Fit method makes calculations in place and changes the attributes.

    Parameters
    -----------
    explainer : Explainer object
        Model wrapper created using the Explainer class.
    new_observation : pd.DataFrame or np.ndarray
        Observations for which predictions need to be explained.
    y : pd.Series or np.ndarray (1d), optional
        Target variable with the same length as `new_observation`.
    verbose : bool, optional
        Print tqdm progress bar (default is `True`).

    Returns
    -----------
    None
    &#34;&#34;&#34;

    self.variables = checks.check_variables(self.variables, explainer, self.variable_splits)

    checks.check_data(explainer.data, self.variables)

    self.new_observation = checks.check_new_observation(new_observation, explainer)

    self.variable_splits = checks.check_variable_splits(self.variable_splits,
                                                 self.variables,
                                                 self.grid_points,
                                                 explainer.data,
                                                 self.variable_splits_type,
                                                 self.variable_splits_with_obs,
                                                 self.new_observation)

    y = checks.check_y(y)

    self.result, self.new_observation = utils.calculate_ceteris_paribus(
        explainer,
        self.new_observation,
        self.variable_splits,
        y,
        self.processes,
        verbose
    )</code></pre>
</details>
</dd>
<dt id="dalex.predict_explanations.CeterisParibus.plot"><code class="name flex">
<span>def <span class="ident">plot</span></span>(<span>self, objects=None, variable_type='numerical', variables=None, size=2, alpha=1, color='_label_', facet_ncol=2, show_observations=True, title='Ceteris Paribus Profiles', y_title='prediction', horizontal_spacing=None, vertical_spacing=None, show=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Plot the Ceteris Paribus explanation</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>objects</code></strong> :&ensp;<code><a title="dalex.predict_explanations.CeterisParibus" href="#dalex.predict_explanations.CeterisParibus">CeterisParibus</a> object</code> or <code>array_like</code> of <code><a title="dalex.predict_explanations.CeterisParibus" href="#dalex.predict_explanations.CeterisParibus">CeterisParibus</a> objects</code></dt>
<dd>Additional objects to plot in subplots (default is <code>None</code>).</dd>
<dt><strong><code>variable_type</code></strong> :&ensp;<code>{'numerical', 'categorical'}</code></dt>
<dd>Plot the profiles for numerical or categorical variables
(default is <code>'numerical'</code>).</dd>
<dt><strong><code>variables</code></strong> :&ensp;<code>str</code> or <code>array_like</code> of <code>str</code>, optional</dt>
<dd>Variables for which the profiles will be calculated
(default is <code>None</code>, which means all of the variables).</dd>
<dt><strong><code>size</code></strong> :&ensp;<code>float</code>, optional</dt>
<dd>Width of lines in px (default is <code>2</code>).</dd>
<dt><strong><code>alpha</code></strong> :&ensp;<code>float &lt;0, 1&gt;</code>, optional</dt>
<dd>Opacity of lines (default is <code>1</code>).</dd>
<dt><strong><code>color</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>Variable name used for grouping
(default is <code>'_label_'</code>, which groups by models).</dd>
<dt><strong><code>facet_ncol</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>Number of columns on the plot grid (default is <code>2</code>).</dd>
<dt><strong><code>show_observations</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>Show observation points (default is <code>True</code>).</dd>
<dt><strong><code>title</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>Title of the plot (default is <code>"Ceteris Paribus Profiles"</code>).</dd>
<dt><strong><code>y_title</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>Title of the y/x axis (default is <code>"prediction"</code>).</dd>
<dt><strong><code>horizontal_spacing</code></strong> :&ensp;<code>float &lt;0, 1&gt;</code>, optional</dt>
<dd>Ratio of horizontal space between the plots
(default depends on <code>variable_type</code>).</dd>
<dt><strong><code>vertical_spacing</code></strong> :&ensp;<code>float &lt;0, 1&gt;</code>, optional</dt>
<dd>Ratio of vertical space between the plots (default is <code>0.3/number of rows</code>).</dd>
<dt><strong><code>show</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd><code>True</code> shows the plot; <code>False</code> returns the plotly Figure object that can
be edited or saved using the <code>write_image()</code> method (default is <code>True</code>).</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>None</code> or <code>plotly.graph_objects.Figure</code></dt>
<dd>Return figure that can be edited or saved. See <code>show</code> parameter.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def plot(self,
         objects=None,
         variable_type=&#34;numerical&#34;,
         variables=None,
         size=2,
         alpha=1,
         color=&#34;_label_&#34;,
         facet_ncol=2,
         show_observations=True,
         title=&#34;Ceteris Paribus Profiles&#34;,
         y_title=&#39;prediction&#39;,
         horizontal_spacing=None,
         vertical_spacing=None,
         show=True):
    &#34;&#34;&#34;Plot the Ceteris Paribus explanation

    Parameters
    -----------
    objects : CeterisParibus object or array_like of CeterisParibus objects
        Additional objects to plot in subplots (default is `None`).
    variable_type : {&#39;numerical&#39;, &#39;categorical&#39;}
        Plot the profiles for numerical or categorical variables 
        (default is `&#39;numerical&#39;`).
    variables : str or array_like of str, optional
        Variables for which the profiles will be calculated
        (default is `None`, which means all of the variables).
    size : float, optional
        Width of lines in px (default is `2`).
    alpha : float &lt;0, 1&gt;, optional
        Opacity of lines (default is `1`).
    color : str, optional
        Variable name used for grouping
        (default is `&#39;_label_&#39;`, which groups by models).
    facet_ncol : int, optional
        Number of columns on the plot grid (default is `2`).
    show_observations : bool, optional
        Show observation points (default is `True`).
    title : str, optional
        Title of the plot (default is `&#34;Ceteris Paribus Profiles&#34;`).
    y_title : str, optional
        Title of the y/x axis (default is `&#34;prediction&#34;`).
    horizontal_spacing : float &lt;0, 1&gt;, optional
        Ratio of horizontal space between the plots
        (default depends on `variable_type`).
    vertical_spacing : float &lt;0, 1&gt;, optional
        Ratio of vertical space between the plots (default is `0.3/number of rows`).
    show : bool, optional
        `True` shows the plot; `False` returns the plotly Figure object that can 
        be edited or saved using the `write_image()` method (default is `True`).

    Returns
    -----------
    None or plotly.graph_objects.Figure
        Return figure that can be edited or saved. See `show` parameter.
    &#34;&#34;&#34;

    if variable_type not in (&#34;numerical&#34;, &#34;categorical&#34;):
        raise TypeError(&#34;variable_type should be &#39;numerical&#39; or &#39;categorical&#39;&#34;)
    if isinstance(variables, str):
        variables = (variables,)

    # are there any other objects to plot?
    if objects is None:
        _result_df = self.result.assign(_original_yhat_=lambda x: self.new_observation.loc[x.index, &#39;_yhat_&#39;])
        _include = self.variable_splits_with_obs
    elif isinstance(objects, self.__class__):  # allow for objects to be a single element
        _result_df = pd.concat([
            self.result.assign(_original_yhat_=lambda x: self.new_observation.loc[x.index, &#39;_yhat_&#39;]),
            objects.result.assign(_original_yhat_=lambda x: objects.new_observation.loc[x.index, &#39;_yhat_&#39;])])
        _include = np.all([self.variable_splits_with_obs, objects.variable_splits_with_obs])
    elif isinstance(objects, (list, tuple)):  # objects as tuple or array
        _result_df = self.result.assign(_original_yhat_=lambda x: self.new_observation.loc[x.index, &#39;_yhat_&#39;])
        _include = [self.variable_splits_with_obs]
        for ob in objects:
            _global_checks.global_check_object_class(ob, self.__class__)
            _result_df = pd.concat([
                _result_df, ob.result.assign(_original_yhat_=lambda x: ob.new_observation.loc[x.index, &#39;_yhat_&#39;])])
            _include += [ob.variable_splits_with_obs]
        _include = np.all(_include)
    else:
        _global_checks.global_raise_objects_class(objects, self.__class__)

    if _include is False and show_observations:
            warnings.warn(&#34;&#39;show_observations&#39; parameter changed to False,&#34;
                          &#34;because the &#39;variable_splits_with_obs&#39; attribute is False&#34;
                          &#34;See `variable_splits_with_obs` parameter in `predict_profile`.&#34;)
            show_observations = False

    # variables to use
    all_variables = list(_result_df[&#39;_vname_&#39;].dropna().unique())

    if variables is not None:
        all_variables = _global_utils.intersect_unsorted(variables, all_variables)
        if len(all_variables) == 0:
            raise TypeError(&#34;variables do not overlap with &#34; + &#39;&#39;.join(variables))

    # names of numeric variables
    numeric_variables = _result_df[all_variables].select_dtypes(include=np.number).columns.tolist()

    if variable_type == &#34;numerical&#34;:
        variable_names = numeric_variables

        if len(variable_names) == 0:
            # change to categorical
            variable_type = &#34;categorical&#34;
            # send message
            warnings.warn(&#34;&#39;variable_type&#39; parameter changed to &#39;categorical&#39; due to lack of numerical variables.&#34;)
            # take all
            variable_names = all_variables
        elif variables is not None and len(variable_names) != len(variables):
            raise TypeError(&#34;There are no numerical variables&#34;)
    else:
        variable_names = np.setdiff1d(all_variables, numeric_variables).tolist()

        # there are variables selected
        if variables is not None:
            # take all
            variable_names = all_variables
        elif len(variable_names) == 0:
            # there were no variables selected and there are no categorical variables
            raise TypeError(&#34;There are no non-numerical variables.&#34;)

    # prepare profiles data
    _result_df = _result_df.loc[_result_df[&#39;_vname_&#39;].isin(variable_names), ].reset_index(drop=True)

    #  calculate y axis range to allow for fixedrange True
    dl = _result_df[&#39;_yhat_&#39;].to_numpy()
    min_max_margin = dl.ptp() * 0.10
    min_max = [dl.min() - min_max_margin, dl.max() + min_max_margin]

    # create _x_
    if len(variable_names) == 1:
        _result_df.loc[:, &#39;_x_&#39;] = deepcopy(_result_df.loc[:, variable_names[0]])
    else:
        for variable in variable_names:
            where_variable = _result_df[&#39;_vname_&#39;] == variable
            _result_df.loc[where_variable, &#39;_x_&#39;] = deepcopy(_result_df.loc[where_variable, variable])

    # change x column to proper character values
    if variable_type == &#39;categorical&#39;:
        _result_df.loc[:, &#39;_x_&#39;] = _result_df.apply(lambda row: str(row[row[&#39;_vname_&#39;]]), axis=1)

    n = len(variable_names)
    facet_nrow = int(np.ceil(n / facet_ncol))
    if vertical_spacing is None:
        vertical_spacing = 0.3 / facet_nrow if variable_type == &#39;numerical&#39; else 0.05
    if horizontal_spacing is None:
        horizontal_spacing = 0.05 if variable_type == &#39;numerical&#39; else 0.1

    plot_height = 78 + 71 + facet_nrow * (280 + 60)

    _result_df = _result_df.assign(_text_=_result_df.apply(lambda obs: plot.tooltip_text(obs), axis=1))

    if variable_type == &#34;numerical&#34;:    
        m = len(_result_df[color].dropna().unique())
        _result_df[color] = _result_df[color].astype(object)  # prevent error when using pd.StringDtype
    
        fig = px.line(_result_df,
                      x=&#34;_x_&#34;, y=&#34;_yhat_&#34;, color=color, facet_col=&#34;_vname_&#34;, line_group=&#39;_ids_&#39;,
                      category_orders={&#34;_vname_&#34;: list(variable_names)},
                      labels={&#39;_yhat_&#39;: &#39;prediction&#39;, &#39;_label_&#39;: &#39;label&#39;, &#39;_ids_&#39;: &#39;id&#39;},  # , color: &#39;group&#39;},
                      # hover_data={&#39;_text_&#39;: True, &#39;_yhat_&#39;: &#39;:.3f&#39;, &#39;_vname_&#39;: False, &#39;_x_&#39;: False, color: False},
                      custom_data=[&#39;_text_&#39;],
                      facet_col_wrap=facet_ncol,
                      facet_row_spacing=vertical_spacing,
                      facet_col_spacing=horizontal_spacing,
                      template=&#34;none&#34;,
                      color_discrete_sequence=_theme.get_default_colors(m, &#39;line&#39;)) \
                .update_traces(dict(line_width=size, opacity=alpha,
                                    hovertemplate=&#34;%{customdata[0]}&lt;extra&gt;&lt;/extra&gt;&#34;)) \
                .update_xaxes({&#39;matches&#39;: None, &#39;showticklabels&#39;: True,
                               &#39;type&#39;: &#39;linear&#39;, &#39;gridwidth&#39;: 2, &#39;zeroline&#39;: False, &#39;automargin&#39;: True,
                               &#39;ticks&#39;: &#34;outside&#34;, &#39;tickcolor&#39;: &#39;white&#39;, &#39;ticklen&#39;: 3, &#39;fixedrange&#39;: True}) \
                .update_yaxes({&#39;type&#39;: &#39;linear&#39;, &#39;gridwidth&#39;: 2, &#39;zeroline&#39;: False, &#39;automargin&#39;: True,
                               &#39;ticks&#39;: &#39;outside&#39;, &#39;tickcolor&#39;: &#39;white&#39;, &#39;ticklen&#39;: 3, &#39;fixedrange&#39;: True,
                               &#39;range&#39;: min_max})

        if show_observations:
            _points_df = _result_df.loc[_result_df[&#39;_original_&#39;] == _result_df[&#39;_x_&#39;], :].copy()

            fig_points = px.scatter(_points_df,
                                    x=&#39;_original_&#39;, y=&#39;_yhat_&#39;, facet_col=&#39;_vname_&#39;,
                                    category_orders={&#34;_vname_&#34;: list(variable_names)},
                                    labels={&#39;_yhat_&#39;: &#39;prediction&#39;, &#39;_label_&#39;: &#39;label&#39;, &#39;_ids_&#39;: &#39;id&#39;},
                                    custom_data=[&#39;_text_&#39;],
                                    facet_col_wrap=facet_ncol,
                                    facet_row_spacing=vertical_spacing,
                                    facet_col_spacing=horizontal_spacing,
                                    color_discrete_sequence=[&#34;#371ea3&#34;]) \
                           .update_traces(dict(marker_size=5*size, opacity=alpha),
                                          hovertemplate=&#34;%{customdata[0]}&lt;extra&gt;&lt;/extra&gt;&#34;)

            for _, value in enumerate(fig_points.data):
                fig.add_trace(value)
                
            fig = _theme.fig_update_line_plot(fig, title, y_title, plot_height, &#39;closest&#39;)

    else:
        if color==&#34;_label_&#34; and len(_result_df[&#39;_ids_&#39;].unique()) &gt; 1 and len(_result_df[&#39;_label_&#39;].unique()) == 1:
            warnings.warn(&#34;&#39;color&#39; parameter changed to &#39;_ids_&#39; because there are multiple observations for one model.&#34;)
            color = &#39;_ids_&#39;
        elif color==&#34;_label_&#34; and len(_result_df[&#39;_ids_&#39;].unique()) != len(_result_df[&#39;_label_&#39;].unique()): 
            # https://github.com/plotly/plotly.py/issues/2657
            raise TypeError(&#34;Please pick one observation per label or change the `color` parameter.&#34;)

        m = len(_result_df[color].dropna().unique())
        _result_df[color] = _result_df[color].astype(object)  # prevent error when using pd.StringDtype
        
        _result_df = _result_df.assign(_diff_=lambda x: x[&#39;_yhat_&#39;] - x[&#39;_original_yhat_&#39;])
        fig = px.bar(_result_df,
                     x=&#34;_diff_&#34;, y=&#34;_x_&#34;, color=color, facet_col=&#34;_vname_&#34;,
                     category_orders={&#34;_vname_&#34;: list(variable_names)},
                     labels={&#39;_yhat_&#39;: &#39;prediction&#39;, &#39;_label_&#39;: &#39;label&#39;, &#39;_ids_&#39;: &#39;id&#39;},  # , color: &#39;group&#39;},
                     # hover_data={&#39;_yhat_&#39;: &#39;:.3f&#39;, &#39;_ids_&#39;: True, &#39;_vname_&#39;: False, color: False},
                     custom_data=[&#39;_text_&#39;],
                     base=&#34;_original_yhat_&#34;,
                     facet_col_wrap=facet_ncol,
                     facet_row_spacing=vertical_spacing,
                     facet_col_spacing=horizontal_spacing,
                     template=&#34;none&#34;,
                     color_discrete_sequence=_theme.get_default_colors(m, &#39;line&#39;),
                     barmode=&#39;group&#39;,
                     orientation=&#39;h&#39;)  \
                .update_traces(dict(opacity=alpha),
                               hovertemplate=&#34;%{customdata[0]}&lt;extra&gt;&lt;/extra&gt;&#34;) \
                .update_yaxes({&#39;matches&#39;: None, &#39;showticklabels&#39;: True,
                               &#39;type&#39;: &#39;category&#39;, &#39;gridwidth&#39;: 2, &#39;automargin&#39;: True, 
                               &#39;ticks&#39;: &#34;outside&#34;, &#39;tickcolor&#39;: &#39;white&#39;, &#39;ticklen&#39;: 10, &#39;fixedrange&#39;: True}) \
                .update_xaxes({&#39;type&#39;: &#39;linear&#39;, &#39;gridwidth&#39;: 2, &#39;zeroline&#39;: False, &#39;automargin&#39;: True,
                               &#39;ticks&#39;: &#39;outside&#39;, &#39;tickcolor&#39;: &#39;white&#39;, &#39;ticklen&#39;: 3, &#39;fixedrange&#39;: True,
                               &#39;range&#39;: min_max})

        # add hline https://github.com/plotly/plotly.py/issues/2141
        for _, bar in enumerate(fig.data):
            fig.add_vline(x=bar.base[0], layer=&#39;below&#39;,
                          line={&#39;color&#39;: &#34;#371ea3&#34;, &#39;width&#39;: 1.5, &#39;dash&#39;: &#39;dot&#39;})

        fig = _theme.fig_update_bar_plot(fig, title, y_title, plot_height, &#39;closest&#39;)
        
    fig.update_layout(hoverlabel=dict(bgcolor=&#39;rgba(0,0,0,0.8)&#39;))
    if show:
        fig.show(config=_theme.get_default_config())
    else:
        return fig</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="dalex.predict_explanations.Shap"><code class="flex name class">
<span>class <span class="ident">Shap</span></span>
<span>(</span><span>path='average', B=25, keep_distributions=False, processes=1, random_state=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Calculate predict-level variable attributions as Shapley Values</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>path</code></strong> :&ensp;<code>list</code> of <code>int</code>, optional</dt>
<dd>If specified, then attributions for this path will be plotted
(default is <code>'average'</code>, which plots attribution means for <code>B</code> random paths).</dd>
<dt><strong><code>B</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>Number of random paths to calculate variable attributions (default is <code>25</code>).</dd>
<dt><strong><code>keep_distributions</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>Save the distribution of partial predictions (default is <code>False</code>).</dd>
<dt><strong><code>processes</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>Number of parallel processes to use in calculations. Iterated over <code>B</code>
(default is <code>1</code>, which means no parallel computation).</dd>
<dt><strong><code>random_state</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>Set seed for random number generator (default is random seed).</dd>
</dl>
<h2 id="attributes">Attributes</h2>
<dl>
<dt><strong><code>result</code></strong> :&ensp;<code>pd.DataFrame</code></dt>
<dd>Main result attribute of an explanation.</dd>
<dt><strong><code>prediction</code></strong> :&ensp;<code>float</code></dt>
<dd>Prediction for <code>new_observation</code>.</dd>
<dt><strong><code>intercept</code></strong> :&ensp;<code>float</code></dt>
<dd>Average prediction for <code>data</code>.</dd>
<dt><strong><code>path</code></strong> :&ensp;<code>list</code> of <code>int</code> or <code>'average'</code></dt>
<dd>Path for which the attributions will be plotted.</dd>
<dt><strong><code>B</code></strong> :&ensp;<code>int</code></dt>
<dd>Number of random paths to calculate variable attributions.</dd>
<dt><strong><code>keep_distributions</code></strong> :&ensp;<code>bool</code></dt>
<dd>Save the distribution of partial predictions.</dd>
<dt><strong><code>yhats_distributions</code></strong> :&ensp;<code>pd.DataFrame</code> or <code>None</code></dt>
<dd>The distribution of partial predictions.</dd>
<dt><strong><code>processes</code></strong> :&ensp;<code>int</code></dt>
<dd>Number of parallel processes to use in calculations. Iterated over <code>B</code>.</dd>
<dt><strong><code>random_state</code></strong> :&ensp;<code>int</code> or <code>None</code></dt>
<dd>Seed that was set for random number generator.</dd>
</dl>
<h2 id="notes">Notes</h2>
<ul>
<li><a href="https://pbiecek.github.io/ema/shapley.html">https://pbiecek.github.io/ema/shapley.html</a></li>
</ul></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Shap:
    &#34;&#34;&#34;Calculate predict-level variable attributions as Shapley Values

    Parameters
    -----------
    path : list of int, optional
        If specified, then attributions for this path will be plotted
        (default is `&#39;average&#39;`, which plots attribution means for `B` random paths).
    B : int, optional
        Number of random paths to calculate variable attributions (default is `25`).
    keep_distributions : bool, optional
        Save the distribution of partial predictions (default is `False`).
    processes : int, optional
        Number of parallel processes to use in calculations. Iterated over `B`
        (default is `1`, which means no parallel computation).
    random_state : int, optional
        Set seed for random number generator (default is random seed).

    Attributes
    -----------
    result : pd.DataFrame
        Main result attribute of an explanation.
    prediction : float
        Prediction for `new_observation`.
    intercept : float
        Average prediction for `data`.
    path : list of int or &#39;average&#39;
        Path for which the attributions will be plotted.
    B : int
        Number of random paths to calculate variable attributions.
    keep_distributions : bool
        Save the distribution of partial predictions.
    yhats_distributions : pd.DataFrame or None
        The distribution of partial predictions.
    processes : int
        Number of parallel processes to use in calculations. Iterated over `B`.
    random_state : int or None
        Seed that was set for random number generator.

    Notes
    --------
    - https://pbiecek.github.io/ema/shapley.html
    &#34;&#34;&#34;

    def __init__(self,
                 path=&#34;average&#34;,
                 B=25,
                 keep_distributions=False,
                 processes=1,
                 random_state=None):

        _path = checks.check_path(path)
        _processess = checks.check_processes(processes)
        _random_state = checks.check_random_state(random_state)

        self.path = _path
        self.keep_distributions = keep_distributions
        self.B = B
        self.result = None
        self.yhats_distributions = None
        self.prediction = None
        self.intercept = None
        self.processes = _processess
        self.random_state = _random_state

    def _repr_html_(self):
        return self.result._repr_html_()

    def fit(self,
            explainer,
            new_observation):
        &#34;&#34;&#34;Calculate the result of explanation

        Fit method makes calculations in place and changes the attributes.

        Parameters
        -----------
        explainer : Explainer object
            Model wrapper created using the Explainer class.
        new_observation : pd.Series or np.ndarray
            An observation for which a prediction needs to be explained.

        Returns
        -----------
        None
        &#34;&#34;&#34;

        _new_observation = checks.check_new_observation(new_observation, explainer)
        checks.check_columns_in_new_observation(_new_observation, explainer)
        self.result, self.prediction, self.intercept, self.yhats_distributions = utils.shap(
            explainer,
            _new_observation,
            self.path,
            self.keep_distributions,
            self.B,
            self.processes
        )

    def plot(self,
             objects=None,
             baseline=None,
             max_vars=10,
             digits=3,
             rounding_function=np.around,
             bar_width=16,
             min_max=None,
             vcolors=None,
             title=&#34;Shapley Values&#34;,
             vertical_spacing=None,
             show=True):
        &#34;&#34;&#34;Plot the Shapley Values explanation

        Parameters
        -----------
        objects : Shap object or array_like of Shap objects
            Additional objects to plot in subplots (default is `None`).
        baseline: float, optional
            Starting x point for bars (default is average prediction).
        max_vars : int, optional
            Maximum number of variables that will be presented for for each subplot
            (default is `10`).
        digits : int, optional
            Number of decimal places (`np.around`) to round contributions.
            See `rounding_function` parameter (default is `3`).
        rounding_function : function, optional
            A function that will be used for rounding numbers (default is `np.around`).
        bar_width : float, optional
            Width of bars in px (default is `16`).
        min_max : 2-tuple of float, optional
            Range of OX axis (default is `[min-0.15*(max-min), max+0.15*(max-min)]`).
        vcolors : 3-tuple of str, optional
            Color of bars (default is `[&#34;#8bdcbe&#34;, &#34;#f05a71&#34;]`).
        title : str, optional
            Title of the plot (default is `&#34;Shapley Values&#34;`).
        vertical_spacing : float &lt;0, 1&gt;, optional
            Ratio of vertical space between the plots (default is `0.2/number of rows`).
        show : bool, optional
            `True` shows the plot; `False` returns the plotly Figure object that can 
            be edited or saved using the `write_image()` method (default is `True`).

        Returns
        -----------
        None or plotly.graph_objects.Figure
            Return figure that can be edited or saved. See `show` parameter.
        &#34;&#34;&#34;

        # are there any other objects to plot?
        if objects is None:
            n = 1
            _result_list = [self.result.loc[self.result[&#39;B&#39;] == 0,].copy()]
            _intercept_list = [self.intercept]
            _prediction_list = [self.prediction]
        elif isinstance(objects, self.__class__):  # allow for objects to be a single element
            n = 2
            _result_list = [self.result.loc[self.result[&#39;B&#39;] == 0,].copy(),
                            objects.result.loc[objects.result[&#39;B&#39;] == 0,].copy()]
            _intercept_list = [self.intercept, objects.intercept]
            _prediction_list = [self.prediction, objects.prediction]
        elif isinstance(objects, (list, tuple)):  # objects as tuple or array
            n = len(objects) + 1
            _result_list = [self.result.loc[self.result[&#39;B&#39;] == 0,].copy()]
            _intercept_list = [self.intercept]
            _prediction_list = [self.prediction]
            for ob in objects:
                _global_checks.global_check_object_class(ob, self.__class__)
                _result_list += [ob.result.loc[ob.result[&#39;B&#39;] == 0,].copy()]
                _intercept_list += [ob.intercept]
                _prediction_list += [ob.prediction]
        else:
            _global_checks.global_raise_objects_class(objects, self.__class__)

        # TODO: add intercept and prediction list update for multi-class
        # deleted_indexes = []
        # for i in range(n):
        #     result = _result_list[i]
        #
        #     if len(result[&#39;label&#39;].unique()) &gt; 1:
        #         n += len(result[&#39;label&#39;].unique()) - 1
        #         # add new data frames to list
        #         _result_list += [v for k, v in result.groupby(&#39;label&#39;, sort=False)]
        #         deleted_indexes += [i]
        #
        # _result_list = [j for i, j in enumerate(_result_list) if i not in deleted_indexes]
        model_names = [result.iloc[0, result.columns.get_loc(&#34;label&#34;)] for result in _result_list]

        if vertical_spacing is None:
            vertical_spacing = 0.2 / n

        fig = make_subplots(rows=n, cols=1,
                            shared_xaxes=True, vertical_spacing=vertical_spacing,
                            x_title=&#39;contribution&#39;, subplot_titles=model_names)
        plot_height = 78 + 71

        if vcolors is None:
            vcolors = _theme.get_break_down_colors()

        if min_max is None:
            temp_min_max = [np.Inf, -np.Inf]
        else:
            temp_min_max = min_max

        for i, _result in enumerate(_result_list):
            if _result.shape[0] &lt;= max_vars:
                m = _result.shape[0]
            else:
                m = max_vars + 1

            if baseline is None:
                baseline = _intercept_list[i]
            prediction = _prediction_list[i]

            df = plot.prepare_data_for_shap_plot(_result, baseline, prediction, max_vars, rounding_function, digits)

            fig.add_shape(
                type=&#39;line&#39;,
                x0=baseline,
                x1=baseline,
                y0=-1,
                y1=m,
                yref=&#34;paper&#34;,
                xref=&#34;x&#34;,
                line={&#39;color&#39;: &#34;#371ea3&#34;, &#39;width&#39;: 1.5, &#39;dash&#39;: &#39;dot&#39;},
                row=i + 1, col=1
            )

            fig.add_bar(
                orientation=&#34;h&#34;,
                y=df[&#39;variable&#39;].tolist(),
                x=df[&#39;contribution&#39;].tolist(),
                textposition=&#34;outside&#34;,
                text=df[&#39;label_text&#39;].tolist(),
                marker_color=[vcolors[int(c)] for c in df[&#39;sign&#39;].tolist()],
                base=baseline,
                hovertext=df[&#39;tooltip_text&#39;].tolist(),
                hoverinfo=&#39;text&#39;,
                hoverlabel={&#39;bgcolor&#39;: &#39;rgba(0,0,0,0.8)&#39;},
                showlegend=False,
                row=i + 1, col=1
            )

            fig.update_yaxes({&#39;type&#39;: &#39;category&#39;, &#39;autorange&#39;: &#39;reversed&#39;, &#39;gridwidth&#39;: 2, &#39;automargin&#39;: True,
                              &#39;ticks&#39;: &#39;outside&#39;, &#39;tickcolor&#39;: &#39;white&#39;, &#39;ticklen&#39;: 10, &#39;fixedrange&#39;: True},
                             row=i + 1, col=1)

            fig.update_xaxes({&#39;type&#39;: &#39;linear&#39;, &#39;gridwidth&#39;: 2, &#39;zeroline&#39;: False, &#39;automargin&#39;: True,
                              &#39;ticks&#39;: &#34;outside&#34;, &#39;tickcolor&#39;: &#39;white&#39;, &#39;ticklen&#39;: 3, &#39;fixedrange&#39;: True},
                             row=i + 1, col=1)

            plot_height += m * bar_width + (m + 1) * bar_width / 4

            if min_max is None:
                cum = df.contribution.values + baseline
                min_max_margin = cum.ptp() * 0.15
                temp_min_max[0] = np.min([temp_min_max[0], cum.min() - min_max_margin])
                temp_min_max[1] = np.max([temp_min_max[1], cum.max() + min_max_margin])

        plot_height += (n - 1) * 70

        fig.update_xaxes({&#39;range&#39;: temp_min_max})
        fig.update_layout(title_text=title, title_x=0.15, font={&#39;color&#39;: &#34;#371ea3&#34;}, template=&#34;none&#34;,
                          height=plot_height, margin={&#39;t&#39;: 78, &#39;b&#39;: 71, &#39;r&#39;: 30})

        if show:
            fig.show(config=_theme.get_default_config())
        else:
            return fig</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="dalex.predict_explanations.Shap.fit"><code class="name flex">
<span>def <span class="ident">fit</span></span>(<span>self, explainer, new_observation)</span>
</code></dt>
<dd>
<div class="desc"><p>Calculate the result of explanation</p>
<p>Fit method makes calculations in place and changes the attributes.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>explainer</code></strong> :&ensp;<code>Explainer object</code></dt>
<dd>Model wrapper created using the Explainer class.</dd>
<dt><strong><code>new_observation</code></strong> :&ensp;<code>pd.Series</code> or <code>np.ndarray</code></dt>
<dd>An observation for which a prediction needs to be explained.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>None</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def fit(self,
        explainer,
        new_observation):
    &#34;&#34;&#34;Calculate the result of explanation

    Fit method makes calculations in place and changes the attributes.

    Parameters
    -----------
    explainer : Explainer object
        Model wrapper created using the Explainer class.
    new_observation : pd.Series or np.ndarray
        An observation for which a prediction needs to be explained.

    Returns
    -----------
    None
    &#34;&#34;&#34;

    _new_observation = checks.check_new_observation(new_observation, explainer)
    checks.check_columns_in_new_observation(_new_observation, explainer)
    self.result, self.prediction, self.intercept, self.yhats_distributions = utils.shap(
        explainer,
        _new_observation,
        self.path,
        self.keep_distributions,
        self.B,
        self.processes
    )</code></pre>
</details>
</dd>
<dt id="dalex.predict_explanations.Shap.plot"><code class="name flex">
<span>def <span class="ident">plot</span></span>(<span>self, objects=None, baseline=None, max_vars=10, digits=3, rounding_function=&lt;function around&gt;, bar_width=16, min_max=None, vcolors=None, title='Shapley Values', vertical_spacing=None, show=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Plot the Shapley Values explanation</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>objects</code></strong> :&ensp;<code><a title="dalex.predict_explanations.Shap" href="#dalex.predict_explanations.Shap">Shap</a> object</code> or <code>array_like</code> of <code><a title="dalex.predict_explanations.Shap" href="#dalex.predict_explanations.Shap">Shap</a> objects</code></dt>
<dd>Additional objects to plot in subplots (default is <code>None</code>).</dd>
<dt><strong><code>baseline</code></strong> :&ensp;<code>float</code>, optional</dt>
<dd>Starting x point for bars (default is average prediction).</dd>
<dt><strong><code>max_vars</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>Maximum number of variables that will be presented for for each subplot
(default is <code>10</code>).</dd>
<dt><strong><code>digits</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>Number of decimal places (<code>np.around</code>) to round contributions.
See <code>rounding_function</code> parameter (default is <code>3</code>).</dd>
<dt><strong><code>rounding_function</code></strong> :&ensp;<code>function</code>, optional</dt>
<dd>A function that will be used for rounding numbers (default is <code>np.around</code>).</dd>
<dt><strong><code>bar_width</code></strong> :&ensp;<code>float</code>, optional</dt>
<dd>Width of bars in px (default is <code>16</code>).</dd>
<dt><strong><code>min_max</code></strong> :&ensp;<code>2-tuple</code> of <code>float</code>, optional</dt>
<dd>Range of OX axis (default is <code>[min-0.15*(max-min), max+0.15*(max-min)]</code>).</dd>
<dt><strong><code>vcolors</code></strong> :&ensp;<code>3-tuple</code> of <code>str</code>, optional</dt>
<dd>Color of bars (default is <code>["#8bdcbe", "#f05a71"]</code>).</dd>
<dt><strong><code>title</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>Title of the plot (default is <code>"Shapley Values"</code>).</dd>
<dt><strong><code>vertical_spacing</code></strong> :&ensp;<code>float &lt;0, 1&gt;</code>, optional</dt>
<dd>Ratio of vertical space between the plots (default is <code>0.2/number of rows</code>).</dd>
<dt><strong><code>show</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd><code>True</code> shows the plot; <code>False</code> returns the plotly Figure object that can
be edited or saved using the <code>write_image()</code> method (default is <code>True</code>).</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>None</code> or <code>plotly.graph_objects.Figure</code></dt>
<dd>Return figure that can be edited or saved. See <code>show</code> parameter.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def plot(self,
         objects=None,
         baseline=None,
         max_vars=10,
         digits=3,
         rounding_function=np.around,
         bar_width=16,
         min_max=None,
         vcolors=None,
         title=&#34;Shapley Values&#34;,
         vertical_spacing=None,
         show=True):
    &#34;&#34;&#34;Plot the Shapley Values explanation

    Parameters
    -----------
    objects : Shap object or array_like of Shap objects
        Additional objects to plot in subplots (default is `None`).
    baseline: float, optional
        Starting x point for bars (default is average prediction).
    max_vars : int, optional
        Maximum number of variables that will be presented for for each subplot
        (default is `10`).
    digits : int, optional
        Number of decimal places (`np.around`) to round contributions.
        See `rounding_function` parameter (default is `3`).
    rounding_function : function, optional
        A function that will be used for rounding numbers (default is `np.around`).
    bar_width : float, optional
        Width of bars in px (default is `16`).
    min_max : 2-tuple of float, optional
        Range of OX axis (default is `[min-0.15*(max-min), max+0.15*(max-min)]`).
    vcolors : 3-tuple of str, optional
        Color of bars (default is `[&#34;#8bdcbe&#34;, &#34;#f05a71&#34;]`).
    title : str, optional
        Title of the plot (default is `&#34;Shapley Values&#34;`).
    vertical_spacing : float &lt;0, 1&gt;, optional
        Ratio of vertical space between the plots (default is `0.2/number of rows`).
    show : bool, optional
        `True` shows the plot; `False` returns the plotly Figure object that can 
        be edited or saved using the `write_image()` method (default is `True`).

    Returns
    -----------
    None or plotly.graph_objects.Figure
        Return figure that can be edited or saved. See `show` parameter.
    &#34;&#34;&#34;

    # are there any other objects to plot?
    if objects is None:
        n = 1
        _result_list = [self.result.loc[self.result[&#39;B&#39;] == 0,].copy()]
        _intercept_list = [self.intercept]
        _prediction_list = [self.prediction]
    elif isinstance(objects, self.__class__):  # allow for objects to be a single element
        n = 2
        _result_list = [self.result.loc[self.result[&#39;B&#39;] == 0,].copy(),
                        objects.result.loc[objects.result[&#39;B&#39;] == 0,].copy()]
        _intercept_list = [self.intercept, objects.intercept]
        _prediction_list = [self.prediction, objects.prediction]
    elif isinstance(objects, (list, tuple)):  # objects as tuple or array
        n = len(objects) + 1
        _result_list = [self.result.loc[self.result[&#39;B&#39;] == 0,].copy()]
        _intercept_list = [self.intercept]
        _prediction_list = [self.prediction]
        for ob in objects:
            _global_checks.global_check_object_class(ob, self.__class__)
            _result_list += [ob.result.loc[ob.result[&#39;B&#39;] == 0,].copy()]
            _intercept_list += [ob.intercept]
            _prediction_list += [ob.prediction]
    else:
        _global_checks.global_raise_objects_class(objects, self.__class__)

    # TODO: add intercept and prediction list update for multi-class
    # deleted_indexes = []
    # for i in range(n):
    #     result = _result_list[i]
    #
    #     if len(result[&#39;label&#39;].unique()) &gt; 1:
    #         n += len(result[&#39;label&#39;].unique()) - 1
    #         # add new data frames to list
    #         _result_list += [v for k, v in result.groupby(&#39;label&#39;, sort=False)]
    #         deleted_indexes += [i]
    #
    # _result_list = [j for i, j in enumerate(_result_list) if i not in deleted_indexes]
    model_names = [result.iloc[0, result.columns.get_loc(&#34;label&#34;)] for result in _result_list]

    if vertical_spacing is None:
        vertical_spacing = 0.2 / n

    fig = make_subplots(rows=n, cols=1,
                        shared_xaxes=True, vertical_spacing=vertical_spacing,
                        x_title=&#39;contribution&#39;, subplot_titles=model_names)
    plot_height = 78 + 71

    if vcolors is None:
        vcolors = _theme.get_break_down_colors()

    if min_max is None:
        temp_min_max = [np.Inf, -np.Inf]
    else:
        temp_min_max = min_max

    for i, _result in enumerate(_result_list):
        if _result.shape[0] &lt;= max_vars:
            m = _result.shape[0]
        else:
            m = max_vars + 1

        if baseline is None:
            baseline = _intercept_list[i]
        prediction = _prediction_list[i]

        df = plot.prepare_data_for_shap_plot(_result, baseline, prediction, max_vars, rounding_function, digits)

        fig.add_shape(
            type=&#39;line&#39;,
            x0=baseline,
            x1=baseline,
            y0=-1,
            y1=m,
            yref=&#34;paper&#34;,
            xref=&#34;x&#34;,
            line={&#39;color&#39;: &#34;#371ea3&#34;, &#39;width&#39;: 1.5, &#39;dash&#39;: &#39;dot&#39;},
            row=i + 1, col=1
        )

        fig.add_bar(
            orientation=&#34;h&#34;,
            y=df[&#39;variable&#39;].tolist(),
            x=df[&#39;contribution&#39;].tolist(),
            textposition=&#34;outside&#34;,
            text=df[&#39;label_text&#39;].tolist(),
            marker_color=[vcolors[int(c)] for c in df[&#39;sign&#39;].tolist()],
            base=baseline,
            hovertext=df[&#39;tooltip_text&#39;].tolist(),
            hoverinfo=&#39;text&#39;,
            hoverlabel={&#39;bgcolor&#39;: &#39;rgba(0,0,0,0.8)&#39;},
            showlegend=False,
            row=i + 1, col=1
        )

        fig.update_yaxes({&#39;type&#39;: &#39;category&#39;, &#39;autorange&#39;: &#39;reversed&#39;, &#39;gridwidth&#39;: 2, &#39;automargin&#39;: True,
                          &#39;ticks&#39;: &#39;outside&#39;, &#39;tickcolor&#39;: &#39;white&#39;, &#39;ticklen&#39;: 10, &#39;fixedrange&#39;: True},
                         row=i + 1, col=1)

        fig.update_xaxes({&#39;type&#39;: &#39;linear&#39;, &#39;gridwidth&#39;: 2, &#39;zeroline&#39;: False, &#39;automargin&#39;: True,
                          &#39;ticks&#39;: &#34;outside&#34;, &#39;tickcolor&#39;: &#39;white&#39;, &#39;ticklen&#39;: 3, &#39;fixedrange&#39;: True},
                         row=i + 1, col=1)

        plot_height += m * bar_width + (m + 1) * bar_width / 4

        if min_max is None:
            cum = df.contribution.values + baseline
            min_max_margin = cum.ptp() * 0.15
            temp_min_max[0] = np.min([temp_min_max[0], cum.min() - min_max_margin])
            temp_min_max[1] = np.max([temp_min_max[1], cum.max() + min_max_margin])

    plot_height += (n - 1) * 70

    fig.update_xaxes({&#39;range&#39;: temp_min_max})
    fig.update_layout(title_text=title, title_x=0.15, font={&#39;color&#39;: &#34;#371ea3&#34;}, template=&#34;none&#34;,
                      height=plot_height, margin={&#39;t&#39;: 78, &#39;b&#39;: 71, &#39;r&#39;: 30})

    if show:
        fig.show(config=_theme.get_default_config())
    else:
        return fig</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<header>
<a class="homelink" rel="home" title="pdoc Home" href="https://dalex.drwhy.ai/">
<img src="https://raw.githubusercontent.com/ModelOriented/DALEX-docs/master/docs/misc/dalex_even.png" alt="">
</a>
</header>
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="dalex" href="../index.html">dalex</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="dalex.predict_explanations.BreakDown" href="#dalex.predict_explanations.BreakDown">BreakDown</a></code></h4>
<ul class="">
<li><code><a title="dalex.predict_explanations.BreakDown.fit" href="#dalex.predict_explanations.BreakDown.fit">fit</a></code></li>
<li><code><a title="dalex.predict_explanations.BreakDown.plot" href="#dalex.predict_explanations.BreakDown.plot">plot</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="dalex.predict_explanations.CeterisParibus" href="#dalex.predict_explanations.CeterisParibus">CeterisParibus</a></code></h4>
<ul class="">
<li><code><a title="dalex.predict_explanations.CeterisParibus.fit" href="#dalex.predict_explanations.CeterisParibus.fit">fit</a></code></li>
<li><code><a title="dalex.predict_explanations.CeterisParibus.plot" href="#dalex.predict_explanations.CeterisParibus.plot">plot</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="dalex.predict_explanations.Shap" href="#dalex.predict_explanations.Shap">Shap</a></code></h4>
<ul class="">
<li><code><a title="dalex.predict_explanations.Shap.fit" href="#dalex.predict_explanations.Shap.fit">fit</a></code></li>
<li><code><a title="dalex.predict_explanations.Shap.plot" href="#dalex.predict_explanations.Shap.plot">plot</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.1</a>.</p>
</footer>
</body>
</html>