<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta property="og:title" content="DALEX: Descriptive mAchine Learning EXplanations" />
<meta property="og:type" content="book" />


<meta property="og:description" content="Do not trust a black-box model. Unless it explains itself." />
<meta name="github-repo" content="rstudio/bookdown-demo" />

<meta name="author" content="Przemysław Biecek" />

<meta name="date" content="2018-08-11" />

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>

<meta name="description" content="Do not trust a black-box model. Unless it explains itself.">

<title>DALEX: Descriptive mAchine Learning EXplanations</title>

<link href="libs/tufte-css-2015.12.29/tufte-fonts.css" rel="stylesheet" />
<link href="libs/tufte-css-2015.12.29/tufte-background.css" rel="stylesheet" />
<link href="libs/tufte-css-2015.12.29/tufte-italics.css" rel="stylesheet" />
<link href="libs/tufte-css-2015.12.29/tufte.css" rel="stylesheet" />


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; position: absolute; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; }
pre.numberSource a.sourceLine:empty
  { position: absolute; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: absolute; left: -5em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="toc.css" type="text/css" />

</head>

<body>



<div class="row">
<div class="col-sm-12">
<div id="TOC">
<ul>
<li class="has-sub"><a href="index.html#introduction"><span class="toc-section-number">1</span> Introduction</a><ul>
<li class="has-sub"><a href="1-1-motivation.html#motivation"><span class="toc-section-number">1.1</span> Motivation</a><ul>
<li><a href="1-1-motivation.html#why-dalex"><span class="toc-section-number">1.1.1</span> Why DALEX?</a></li>
<li><a href="1-1-motivation.html#to-validate"><span class="toc-section-number">1.1.2</span> To validate</a></li>
<li><a href="1-1-motivation.html#to-understand"><span class="toc-section-number">1.1.3</span> To understand</a></li>
<li><a href="1-1-motivation.html#to-improve"><span class="toc-section-number">1.1.4</span> To improve</a></li>
</ul></li>
<li><a href="1-2-trivia.html#trivia"><span class="toc-section-number">1.2</span> Trivia</a></li>
</ul></li>
<li class="has-sub"><a href="2-architecture.html#architecture"><span class="toc-section-number">2</span> Architecture of DALEX</a><ul>
<li><a href="2-1-explainFunction.html#explainFunction"><span class="toc-section-number">2.1</span> The <code>explain()</code> function</a></li>
<li class="has-sub"><a href="2-2-useCaseApartmetns.html#useCaseApartmetns"><span class="toc-section-number">2.2</span> Use case: Regression. Apartment prices in Warsaw</a><ul>
<li><a href="2-2-useCaseApartmetns.html#model-1-linear-regression"><span class="toc-section-number">2.2.1</span> Model 1: Linear regression</a></li>
<li><a href="2-2-useCaseApartmetns.html#model-2-random-forest"><span class="toc-section-number">2.2.2</span> Model 2: Random forest</a></li>
</ul></li>
</ul></li>
<li class="has-sub"><a href="3-modelUnderstanding.html#modelUnderstanding"><span class="toc-section-number">3</span> Model understanding</a><ul>
<li><a href="3-1-modelPerformance.html#modelPerformance"><span class="toc-section-number">3.1</span> Model performance</a></li>
<li class="has-sub"><a href="3-2-featureImportance.html#featureImportance"><span class="toc-section-number">3.2</span> Feature importance</a><ul>
<li><a href="3-2-featureImportance.html#modelAgnostic"><span class="toc-section-number">3.2.1</span> Model agnostic</a></li>
<li><a href="3-2-featureImportance.html#modelSpecific"><span class="toc-section-number">3.2.2</span> Model specific</a></li>
</ul></li>
<li class="has-sub"><a href="3-3-variableResponse.html#variableResponse"><span class="toc-section-number">3.3</span> Variable response</a><ul>
<li><a href="3-3-variableResponse.html#pdpchapter"><span class="toc-section-number">3.3.1</span> Partial Dependence Plot</a></li>
<li><a href="3-3-variableResponse.html#accumulatedLocalEffects"><span class="toc-section-number">3.3.2</span> Accumulated Local Effects Plot</a></li>
<li><a href="3-3-variableResponse.html#mergingPathPlot"><span class="toc-section-number">3.3.3</span> Mering Path Plot</a></li>
</ul></li>
</ul></li>
<li class="has-sub"><a href="4-predictionUnderstanding.html#predictionUnderstanding"><span class="toc-section-number">4</span> Prediction understanding</a><ul>
<li><a href="4-1-outlierDetection.html#outlierDetection"><span class="toc-section-number">4.1</span> Outlier detection</a></li>
<li><a href="4-2-predictionBreakdown.html#predictionBreakdown"><span class="toc-section-number">4.2</span> Prediction breakDown</a></li>
</ul></li>
<li class="has-sub"><a href="5-ceterisParibus.html#ceterisParibus"><span class="toc-section-number">5</span> Ceteris Paribus Profiles</a><ul>
<li><a href="5-1-cetParSingleObseSingleModel.html#cetParSingleObseSingleModel"><span class="toc-section-number">5.1</span> Ceteris Paribus profiles for a single observation</a></li>
<li><a href="5-2-cetParLocalObseSingleModel.html#cetParLocalObseSingleModel"><span class="toc-section-number">5.2</span> Exploration of local structure with Ceteris Paribus profiles</a></li>
<li><a href="5-3-cetParGlobalObseSingleModel.html#cetParGlobalObseSingleModel"><span class="toc-section-number">5.3</span> Exploration of global structure with Ceteris Paribus profiles</a></li>
<li><a href="5-4-cetParSingleObseManyModel.html#cetParSingleObseManyModel"><span class="toc-section-number">5.4</span> What-If scenarios: Single Observation and Multiple Models</a></li>
<li><a href="5-5-cetParLocalMulticlass.html#cetParLocalMulticlass"><span class="toc-section-number">5.5</span> Exploration of multiclass classification models</a></li>
<li><a href="5-6-cetParGlobalObseMultipleModels.html#cetParGlobalObseMultipleModels"><span class="toc-section-number">5.6</span> Global Structure and Multiple Models</a></li>
</ul></li>
<li><a href="6-epilogue.html#epilogue"><span class="toc-section-number">6</span> Epilogue</a></li>
<li><a href="7-exercises.html#exercises"><span class="toc-section-number">7</span> Exercises</a></li>
</ul>
</div>
</div>
</div>
<div class="row">
<div class="col-sm-12">
<div id="featureImportance" class="section level2">
<h2><span class="header-section-number">3.2</span> Feature importance</h2>
<p>Explainers presented in this section are designed to better understand which variables are important.</p>
<p>Some models, such as linear regression or random forest, have a build-in <em>model specific</em> methods to calculate and visualize variable importance. They will be presented in Section <a href="3-2-featureImportance.html#modelSpecific">3.2.2</a>.</p>
<p>Section <a href="3-2-featureImportance.html#modelAgnostic">3.2.1</a> presents a model agnostic approach on the basis of permutations. The advantage of this approach is that different models can be compared within a single setup.</p>
<div id="modelAgnostic" class="section level3">
<h3><span class="header-section-number">3.2.1</span> Model agnostic</h3>
<p>Model agnostic variable importance is calculated by means of permutations.
We simply substract the loss function calculated for validation dataset with permuted values for a single variable from the loss function calculated for validation dataset. This concept and some extensions are described in <span class="citation">(Fisher, Rudin, and Dominici <label for="tufte-mn-16" class="margin-toggle">&#8853;</label><input type="checkbox" id="tufte-mn-16" class="margin-toggle">2018<span class="marginnote">Fisher, Aaron, Cynthia Rudin, and Francesca Dominici. 2018. “Model Class Reliance: Variable Importance Measures for Any Machine Learning Model Class, from the ’Rashomon’ Perspective.” <em>Journal of Computational and Graphical Statistics</em>. <a href="http://arxiv.org/abs/1801.01489" class="uri">http://arxiv.org/abs/1801.01489</a>.</span>)</span>.</p>
<p>This method is implemented in the <code>variable_importance()</code> function. The loss function is calculated for:</p>
<ul>
<li>the original validation <code>data</code>. It is an estimate of a model performance and will be denoted as <code>_full_model_</code>,</li>
<li>validation data with resampled <code>y</code> labels. It is a kind of <em>worst case</em> loss when model are compared against random labels. It will be denoted as <code>_baseline_</code>,</li>
<li>validation data with single variable being resampled. It tells us how much is gone from the model performance after the selected variable is blinded.</li>
</ul>
<p>Let’s see how this function works for a random forest model.</p>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb25-1" data-line-number="1">vi_rf &lt;-<span class="st"> </span><span class="kw">variable_importance</span>(explainer_rf, <span class="dt">loss_function =</span> loss_root_mean_square)</a>
<a class="sourceLine" id="cb25-2" data-line-number="2">vi_rf</a></code></pre></div>
<pre><code>##            variable dropout_loss        label
## 1      _full_model_     285.1355 randomForest
## 2          no.rooms     391.0710 randomForest
## 3 construction.year     410.5866 randomForest
## 4             floor     445.2164 randomForest
## 5           surface     480.1431 randomForest
## 6          district     843.6519 randomForest
## 7        _baseline_    1081.3710 randomForest</code></pre>
<p>
<span class="marginnote">Here the <code>loss_root_mean_square()</code> function is defined as square root from averaged squared differences between labels and model predictions.
</span>
The same method may be applied to a linear model. Since we are using the same loss function and the same method for variable permutations, the losses calculated with both methods can be directly compared.
</p>
<div class="sourceCode" id="cb27"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb27-1" data-line-number="1">vi_lm &lt;-<span class="st"> </span><span class="kw">variable_importance</span>(explainer_lm, <span class="dt">loss_function =</span> loss_root_mean_square)</a>
<a class="sourceLine" id="cb27-2" data-line-number="2">vi_lm</a></code></pre></div>
<pre><code>##            variable dropout_loss label
## 1      _full_model_     284.2788    lm
## 2 construction.year     284.2638    lm
## 3          no.rooms     295.5020    lm
## 4             floor     495.7685    lm
## 5           surface     600.4308    lm
## 6          district    1025.7208    lm
## 7        _baseline_    1232.6798    lm</code></pre>
<p>It is much easier to compare both models when these values are plotted close to each other.
The generic <code>plot()</code> function may handle both models.</p>
<div class="sourceCode" id="cb29"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb29-1" data-line-number="1"><span class="kw">plot</span>(vi_lm, vi_rf)</a></code></pre></div>
<div class="figure"><span id="fig:modelImportanceRaw"></span>
<p class="caption marginnote shownote">
Figure 3.1: Model agnostic variable importance plot. Right edges correspond to loss function after permutation of a single variable. Left edges correspond to loss of a full model
</p>
<img src="DALEX_files/figure-html/modelImportanceRaw-1.png" alt="Model agnostic variable importance plot. Right edges correspond to loss function after permutation of a single variable. Left edges correspond to loss of a full model" width="672"  />
</div>
<p>What we can read out of this plot?</p>
<ul>
<li>left edges of intervals start in <code>_full_model_</code> for a given model. As we can see. the performances are similar for both models,</li>
<li>length of the interval corresponds to variable importance. In both models the most important variables are <code>district</code> and <code>surface</code>,</li>
<li>in the random forest model the <code>construction_year</code> variable has some importance, while its importance for linear model is almost equal to zero,</li>
<li>the variable <code>no.rooms</code> (which is correlated with <code>surface</code>) has some importance in the random forest model but not in the linear model.</li>
</ul>
<p>We may be interested in variables that behave differently between models (like <code>construction_year</code>) or variables that are important in both models (like <code>district</code> or <code>surface</code>). In the next section we introduce explainers for further investigation of these variables.</p>
<p><em>NOTE:</em> If you want variable importance hooked at 0, just add <code>type = &quot;difference&quot;</code> parameter to <code>variable_importance()</code>.</p>
<div class="sourceCode" id="cb30"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb30-1" data-line-number="1">vi_lm &lt;-<span class="st"> </span><span class="kw">variable_importance</span>(explainer_lm, <span class="dt">loss_function =</span> loss_root_mean_square, <span class="dt">type =</span> <span class="st">&quot;difference&quot;</span>)</a>
<a class="sourceLine" id="cb30-2" data-line-number="2">vi_rf &lt;-<span class="st"> </span><span class="kw">variable_importance</span>(explainer_rf, <span class="dt">loss_function =</span> loss_root_mean_square, <span class="dt">type =</span> <span class="st">&quot;difference&quot;</span>)</a>
<a class="sourceLine" id="cb30-3" data-line-number="3"><span class="kw">plot</span>(vi_lm, vi_rf)</a></code></pre></div>
<div class="figure"><span id="fig:modelImportanceDifference"></span>
<p class="caption marginnote shownote">
Figure 3.2: Model agnostic variable importance plot. Right edges correspond to difference between loss after permutation of a single variable and loss of a full model
</p>
<img src="DALEX_files/figure-html/modelImportanceDifference-1.png" alt="Model agnostic variable importance plot. Right edges correspond to difference between loss after permutation of a single variable and loss of a full model" width="672"  />
</div>
</div>
<div id="modelSpecific" class="section level3">
<h3><span class="header-section-number">3.2.2</span> Model specific</h3>
<p>Some models have build-in tools for calculation of variable importance.
Random forest uses two different measures - one based on out-of-bag data and second one based on gains in nodes. Read more about this approach in <span class="citation">(Liaw and Wiener <label for="tufte-mn-17" class="margin-toggle">&#8853;</label><input type="checkbox" id="tufte-mn-17" class="margin-toggle">2002<span class="marginnote">Liaw, Andy, and Matthew Wiener. 2002. “Classification and Regression by randomForest.” <em>R News</em> 2 (3):18–22. <a href="http://CRAN.R-project.org/doc/Rnews/" class="uri">http://CRAN.R-project.org/doc/Rnews/</a>.</span>)</span>.</p>
<p>Below we show an example of a dot plot that summarizes default importance measure for a random forest. The <code>varImpPlot()</code> function is available in the <code>randomForest</code> package.</p>
<div class="sourceCode" id="cb31"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb31-1" data-line-number="1"><span class="kw">varImpPlot</span>(apartments_rf_model)</a></code></pre></div>
<div class="figure"><span id="fig:modelImportanceRF"></span>
<p class="caption marginnote shownote">
Figure 3.3: Built-in variable importance plot for random forest
</p>
<img src="DALEX_files/figure-html/modelImportanceRF-1.png" alt="Built-in variable importance plot for random forest" width="672"  />
</div>
<p>It is easy to assess variable importance for linear models and generalized models, since model coefficients have direct interpretation.</p>
<p><a href="https://en.wikipedia.org/wiki/Forest_plot">Forest plots</a> were initially used in the meta analysis to visualize effects in different studies. . At present, however, they are frequently used to present summary characteristics for models with linear structure / created with <code>lm</code> or <code>glm</code> functions.</p>
<p>There are various implementations of forest plots in R. In the package <code>forestmodel</code> (see <span class="citation">(Kennedy <label for="tufte-mn-18" class="margin-toggle">&#8853;</label><input type="checkbox" id="tufte-mn-18" class="margin-toggle">2017<span class="marginnote">Kennedy, Nick. 2017. <em>Forestmodel: Forest Plots from Regression Models</em>. <a href="https://CRAN.R-project.org/package=forestmodel" class="uri">https://CRAN.R-project.org/package=forestmodel</a>.</span>)</span>) one can use <code>forest_model()</code> function to draw a forest plot. This package is based on the <code>broom</code> package (see <span class="citation">(Robinson <label for="tufte-mn-19" class="margin-toggle">&#8853;</label><input type="checkbox" id="tufte-mn-19" class="margin-toggle">2017<span class="marginnote">Robinson, David. 2017. <em>Broom: Convert Statistical Analysis Objects into Tidy Data Frames</em>. <a href="https://CRAN.R-project.org/package=broom" class="uri">https://CRAN.R-project.org/package=broom</a>.</span>)</span>) and this is why it handles a large variety of different regression models.</p>
<div class="sourceCode" id="cb32"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb32-1" data-line-number="1"><span class="kw">library</span>(<span class="st">&quot;forestmodel&quot;</span>)</a>
<a class="sourceLine" id="cb32-2" data-line-number="2"><span class="kw">forest_model</span>(apartments_lm_model)</a></code></pre></div>
<div class="figure"><span id="fig:forestmodel"></span>
<p class="caption marginnote shownote">
Figure 3.4: Forest plot created with <code>forestmodel</code> package
</p>
<img src="DALEX_files/figure-html/forestmodel-1.png" alt="Forest plot created with `forestmodel` package" width="960"  />
</div>
<p>In the package <code>sjPlot</code> (see <span class="citation">(Lüdecke <label for="tufte-mn-20" class="margin-toggle">&#8853;</label><input type="checkbox" id="tufte-mn-20" class="margin-toggle">2017<span class="marginnote">Lüdecke, Daniel. 2017. <em>SjPlot: Data Visualization for Statistics in Social Science</em>. <a href="https://CRAN.R-project.org/package=sjPlot" class="uri">https://CRAN.R-project.org/package=sjPlot</a>.</span>)</span>) one can find <code>sjp.xyz()</code> function to visualize coefficients of a <code>xyz</code> model (like <code>sjp.glm()</code> for <code>glm</code> models) or a generic wrapper <code>plot_model()</code>.</p>
<div class="sourceCode" id="cb33"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb33-1" data-line-number="1"><span class="kw">library</span>(<span class="st">&quot;sjPlot&quot;</span>)</a>
<a class="sourceLine" id="cb33-2" data-line-number="2"><span class="kw">plot_model</span>(apartments_lm_model, <span class="dt">type =</span> <span class="st">&quot;est&quot;</span>, <span class="dt">sort.est =</span> <span class="ot">TRUE</span>)</a></code></pre></div>
<div class="figure"><span id="fig:sjpglm"></span>
<p class="caption marginnote shownote">
Figure 3.5: Model coefficients plotted with sjPlot package
</p>
<img src="DALEX_files/figure-html/sjpglm-1.png" alt="Model coefficients plotted  with sjPlot package" width="768"  />
</div>
<p><strong>Note!</strong></p>
<p>The <code>forestmodel</code> package handles factor variables in a better way while the plots from <code>sjPlot</code> are easier to read.</p>
</div>
</div>
<p style="text-align: center;">
<a href="3-1-modelPerformance.html"><button class="btn btn-default">Previous</button></a>
<a href="https://github.com/pbiecek/DALEX/edit/master/02-global.Rmd"><button class="btn btn-default">Edit</button></a>
<a href="3-3-variableResponse.html"><button class="btn btn-default">Next</button></a>
</p>
</div>
</div>



</body>
</html>
