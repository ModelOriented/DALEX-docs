<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.1" />
<title>dalex.datasets API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
<style>.homelink{display:block;font-size:2em;font-weight:bold;color:#555;padding-bottom:.5em;border-bottom:1px solid silver}.homelink:hover{color:inherit}.homelink img{max-width:50%;max-height:10em;margin:auto}</style>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>dalex.datasets</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">from ._load import load_titanic, load_fifa, load_apartments, load_apartments_test, \
    load_dragons, load_dragons_test, load_hr, load_hr_test, load_german

__all__ = [
    &#34;load_titanic&#34;,
    &#34;load_fifa&#34;,
    &#34;load_apartments&#34;,
    &#34;load_apartments_test&#34;,
    &#34;load_dragons&#34;,
    &#34;load_dragons_test&#34;,
    &#34;load_hr&#34;,
    &#34;load_hr_test&#34;,
    &#34;load_german&#34;
]</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="dalex.datasets.load_apartments"><code class="name flex">
<span>def <span class="ident">load_apartments</span></span>(<span>)</span>
</code></dt>
<dd>
<div class="desc"><p>Loads the artificial 'apartments' dataset</p>
<p>Datasets 'apartments' and 'apartments_test' are artificial, generated
from the same model. Structure of the dataset is copied from the real
dataset from the PBImisc R package, but they were generated in a way
to mimic the effect of Anscombe quartet for complex black-box models.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>pd.DataFrame</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load_apartments():
    &#34;&#34;&#34;Loads the artificial &#39;apartments&#39; dataset

    Datasets &#39;apartments&#39; and &#39;apartments_test&#39; are artificial, generated
    from the same model. Structure of the dataset is copied from the real
    dataset from the PBImisc R package, but they were generated in a way
    to mimic the effect of Anscombe quartet for complex black-box models.

    Returns
    -----------
    pd.DataFrame
    &#34;&#34;&#34;

    abs_dir_path = os.path.dirname(os.path.abspath(__file__))
    abs_datasets_path = os.path.join(abs_dir_path, &#39;data&#39;, &#39;apartments.csv&#39;)

    dataset = pd.read_csv(abs_datasets_path, index_col=0)  # use 1:1000 as index

    return dataset</code></pre>
</details>
</dd>
<dt id="dalex.datasets.load_apartments_test"><code class="name flex">
<span>def <span class="ident">load_apartments_test</span></span>(<span>)</span>
</code></dt>
<dd>
<div class="desc"><p>Loads the artificial 'apartments_test' dataset</p>
<p>Datasets 'apartments' and 'apartments_test' are artificial, generated
from the same model. Structure of the dataset is copied from the real
dataset from the PBImisc R package, but they were generated in a way
to mimic the effect of Anscombe quartet for complex black-box models.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>pd.DataFrame</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load_apartments_test():
    &#34;&#34;&#34;Loads the artificial &#39;apartments_test&#39; dataset

    Datasets &#39;apartments&#39; and &#39;apartments_test&#39; are artificial, generated
    from the same model. Structure of the dataset is copied from the real
    dataset from the PBImisc R package, but they were generated in a way
    to mimic the effect of Anscombe quartet for complex black-box models.

    Returns
    -----------
    pd.DataFrame
    &#34;&#34;&#34;

    abs_dir_path = os.path.dirname(os.path.abspath(__file__))
    abs_datasets_path = os.path.join(abs_dir_path, &#39;data&#39;, &#39;apartments_test.csv&#39;)

    dataset = pd.read_csv(abs_datasets_path, index_col=0)  # use 1001:9000 as index

    return dataset</code></pre>
</details>
</dd>
<dt id="dalex.datasets.load_dragons"><code class="name flex">
<span>def <span class="ident">load_dragons</span></span>(<span>)</span>
</code></dt>
<dd>
<div class="desc"><p>Load the artificial 'dragons' dataset</p>
<p>Datasets 'dragons' and 'dragons_test' are artificial,
generated from the same ground truth model,
but with sometimes different data distridution.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>pd.DataFrame</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load_dragons():
    &#34;&#34;&#34;Load the artificial &#39;dragons&#39; dataset

    Datasets &#39;dragons&#39; and &#39;dragons_test&#39; are artificial,
    generated from the same ground truth model,
    but with sometimes different data distridution.

    Returns
    -----------
    pd.DataFrame
    &#34;&#34;&#34;

    abs_dir_path = os.path.dirname(os.path.abspath(__file__))
    abs_datasets_path = os.path.join(abs_dir_path, &#39;data&#39;, &#39;dragons.csv&#39;)

    dataset = pd.read_csv(abs_datasets_path, index_col=0)  # use 1:n as index

    return dataset</code></pre>
</details>
</dd>
<dt id="dalex.datasets.load_dragons_test"><code class="name flex">
<span>def <span class="ident">load_dragons_test</span></span>(<span>)</span>
</code></dt>
<dd>
<div class="desc"><p>Load the artificial 'dragons_test' dataset</p>
<p>Datasets 'dragons' and 'dragons_test' are artificial,
generated from the same ground truth model,
but with sometimes different data distridution.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>pd.DataFrame</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load_dragons_test():
    &#34;&#34;&#34;Load the artificial &#39;dragons_test&#39; dataset

    Datasets &#39;dragons&#39; and &#39;dragons_test&#39; are artificial,
    generated from the same ground truth model,
    but with sometimes different data distridution.

    Returns
    -----------
    pd.DataFrame
    &#34;&#34;&#34;

    abs_dir_path = os.path.dirname(os.path.abspath(__file__))
    abs_datasets_path = os.path.join(abs_dir_path, &#39;data&#39;, &#39;dragons_test.csv&#39;)

    dataset = pd.read_csv(abs_datasets_path, index_col=0)  # use 1:n as index

    return dataset</code></pre>
</details>
</dd>
<dt id="dalex.datasets.load_fifa"><code class="name flex">
<span>def <span class="ident">load_fifa</span></span>(<span>)</span>
</code></dt>
<dd>
<div class="desc"><p>Load the preprocessed 'players_20' dataset</p>
<p>Load 'fifa', the preprocessed 'players_20.csv' dataset which comes as
a part of 'FIFA 20 complete player dataset' at 'Kaggle'.
It contains 5000 'overall' best players and 43 variables. These are:
- short_name (index)
- nationality of the player (not used in modeling)
- overall, potential, value_eur, wage_eur (4 potential target variables)
- age, height, weight, attacking skills, defending skills, goalkeeping skills (37 variables)</p>
<p>It is advised to leave only one target variable for modeling.</p>
<p>Format: pd.DataFrame with 5000 rows, 42 columns and index</p>
<p>Source: <a href="https://www.kaggle.com/stefanoleone992/fifa-20-complete-player-dataset#players_20.csv">https://www.kaggle.com/stefanoleone992/fifa-20-complete-player-dataset#players_20.csv</a> January 1, 2020</p>
<p>License: see file ./data/LICENSE-DATA.txt</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>pd.DataFrame</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load_fifa():
    &#34;&#34;&#34;Load the preprocessed &#39;players_20&#39; dataset

    Load &#39;fifa&#39;, the preprocessed &#39;players_20.csv&#39; dataset which comes as
    a part of &#39;FIFA 20 complete player dataset&#39; at &#39;Kaggle&#39;.
    It contains 5000 &#39;overall&#39; best players and 43 variables. These are:
    - short_name (index)
    - nationality of the player (not used in modeling)
    - overall, potential, value_eur, wage_eur (4 potential target variables)
    - age, height, weight, attacking skills, defending skills, goalkeeping skills (37 variables)

    It is advised to leave only one target variable for modeling.

    Format: pd.DataFrame with 5000 rows, 42 columns and index
    
    Source: https://www.kaggle.com/stefanoleone992/fifa-20-complete-player-dataset#players_20.csv January 1, 2020
    
    License: see file ./data/LICENSE-DATA.txt

    Returns
    -----------
    pd.DataFrame
    &#34;&#34;&#34;

    abs_dir_path = os.path.dirname(os.path.abspath(__file__))
    abs_datasets_path = os.path.join(abs_dir_path, &#39;data&#39;, &#39;fifa.csv&#39;)

    dataset = pd.read_csv(abs_datasets_path, index_col=0)  # use short_name as index

    return dataset</code></pre>
</details>
</dd>
<dt id="dalex.datasets.load_german"><code class="name flex">
<span>def <span class="ident">load_german</span></span>(<span>)</span>
</code></dt>
<dd>
<div class="desc"><p>Load the preprocessed 'German Credit' dataset</p>
<p>Dataset 'german' contains information about people and their credit risk.
On the base of age, purpose, credit amount, job, sex, etc. the model should
predict the target - risk. risk tells if the credit rate will be good (1) or bad (0).
This data contains some bias and it can be detected using the dalex.fairness module.</p>
<p>Format: pd.DataFrame with 1000 rows and 10 columns</p>
<p>Source: <a href="https://archive.ics.uci.edu/ml/datasets/Statlog+(German+Credit+Data)">https://archive.ics.uci.edu/ml/datasets/Statlog+(German+Credit+Data)</a></p>
<p>Kaggle: <a href="https://www.kaggle.com/kabure/german-credit-data-with-risk/">https://www.kaggle.com/kabure/german-credit-data-with-risk/</a></p>
<p>License: see file ./data/LICENSE-DATA.txt</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>pd.DataFrame</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load_german():
    &#34;&#34;&#34;Load the preprocessed &#39;German Credit&#39; dataset

    Dataset &#39;german&#39; contains information about people and their credit risk.
    On the base of age, purpose, credit amount, job, sex, etc. the model should
    predict the target - risk. risk tells if the credit rate will be good (1) or bad (0).
    This data contains some bias and it can be detected using the dalex.fairness module.

    Format: pd.DataFrame with 1000 rows and 10 columns

    Source: https://archive.ics.uci.edu/ml/datasets/Statlog+(German+Credit+Data)
    
    Kaggle: https://www.kaggle.com/kabure/german-credit-data-with-risk/
    
    License: see file ./data/LICENSE-DATA.txt
    
    Returns
    -----------
    pd.DataFrame
    &#34;&#34;&#34;

    abs_dir_path = os.path.dirname(os.path.abspath(__file__))
    abs_datasets_path = os.path.join(abs_dir_path, &#39;data&#39;, &#39;german.csv&#39;)

    dataset = pd.read_csv(abs_datasets_path, index_col=False)

    return dataset</code></pre>
</details>
</dd>
<dt id="dalex.datasets.load_hr"><code class="name flex">
<span>def <span class="ident">load_hr</span></span>(<span>)</span>
</code></dt>
<dd>
<div class="desc"><p>Load the artificial 'HR' dataset</p>
<p>Datasets 'HR' and 'HR_test' are artificial, generated from the same model.
Structure of the dataset is based on the real data from the Human Resources
department containing information about which employees were promoted or fired.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>pd.DataFrame</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load_hr():
    &#34;&#34;&#34;Load the artificial &#39;HR&#39; dataset

    Datasets &#39;HR&#39; and &#39;HR_test&#39; are artificial, generated from the same model.
    Structure of the dataset is based on the real data from the Human Resources
    department containing information about which employees were promoted or fired.

    Returns
    -----------
    pd.DataFrame
    &#34;&#34;&#34;

    abs_dir_path = os.path.dirname(os.path.abspath(__file__))
    abs_datasets_path = os.path.join(abs_dir_path, &#39;data&#39;, &#39;hr.csv&#39;)

    dataset = pd.read_csv(abs_datasets_path, index_col=0)  # use 7847 numbers from 1:n as index

    return dataset</code></pre>
</details>
</dd>
<dt id="dalex.datasets.load_hr_test"><code class="name flex">
<span>def <span class="ident">load_hr_test</span></span>(<span>)</span>
</code></dt>
<dd>
<div class="desc"><p>Load the artificial 'HR_test' dataset</p>
<p>Datasets 'HR' and 'HR_test' are artificial, generated from the same model.
Structure of the dataset is based on the real data from the Human Resources
department containing information about which employees were promoted or fired.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>pd.DataFrame</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load_hr_test():
    &#34;&#34;&#34;Load the artificial &#39;HR_test&#39; dataset

    Datasets &#39;HR&#39; and &#39;HR_test&#39; are artificial, generated from the same model.
    Structure of the dataset is based on the real data from the Human Resources
    department containing information about which employees were promoted or fired.

    Returns
    -----------
    pd.DataFrame
    &#34;&#34;&#34;

    abs_dir_path = os.path.dirname(os.path.abspath(__file__))
    abs_datasets_path = os.path.join(abs_dir_path, &#39;data&#39;, &#39;hr_test.csv&#39;)

    dataset = pd.read_csv(abs_datasets_path, index_col=0)  # use 7847 numbers from 1:n as index

    return dataset</code></pre>
</details>
</dd>
<dt id="dalex.datasets.load_titanic"><code class="name flex">
<span>def <span class="ident">load_titanic</span></span>(<span>)</span>
</code></dt>
<dd>
<div class="desc"><p>Load the preprocessed 'titanic' dataset</p>
<p>Details: <a href="https://modeloriented.github.io/DALEX/reference/titanic.html">https://modeloriented.github.io/DALEX/reference/titanic.html</a></p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>pd.DataFrame</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load_titanic():
    &#34;&#34;&#34;Load the preprocessed &#39;titanic&#39; dataset
    
    Details: https://modeloriented.github.io/DALEX/reference/titanic.html

    Returns
    -----------
    pd.DataFrame
    &#34;&#34;&#34;

    abs_dir_path = os.path.dirname(os.path.abspath(__file__))
    abs_datasets_path = os.path.join(abs_dir_path, &#39;data&#39;, &#39;titanic.csv&#39;)

    dataset = pd.read_csv(abs_datasets_path)

    return dataset</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<header>
<a class="homelink" rel="home" title="pdoc Home" href="https://dalex.drwhy.ai/">
<img src="https://raw.githubusercontent.com/ModelOriented/DALEX-docs/master/docs/misc/dalex_even.png" alt="">
</a>
</header>
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="dalex" href="../index.html">dalex</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="two-column">
<li><code><a title="dalex.datasets.load_apartments" href="#dalex.datasets.load_apartments">load_apartments</a></code></li>
<li><code><a title="dalex.datasets.load_apartments_test" href="#dalex.datasets.load_apartments_test">load_apartments_test</a></code></li>
<li><code><a title="dalex.datasets.load_dragons" href="#dalex.datasets.load_dragons">load_dragons</a></code></li>
<li><code><a title="dalex.datasets.load_dragons_test" href="#dalex.datasets.load_dragons_test">load_dragons_test</a></code></li>
<li><code><a title="dalex.datasets.load_fifa" href="#dalex.datasets.load_fifa">load_fifa</a></code></li>
<li><code><a title="dalex.datasets.load_german" href="#dalex.datasets.load_german">load_german</a></code></li>
<li><code><a title="dalex.datasets.load_hr" href="#dalex.datasets.load_hr">load_hr</a></code></li>
<li><code><a title="dalex.datasets.load_hr_test" href="#dalex.datasets.load_hr_test">load_hr_test</a></code></li>
<li><code><a title="dalex.datasets.load_titanic" href="#dalex.datasets.load_titanic">load_titanic</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.1</a>.</p>
</footer>
</body>
</html>