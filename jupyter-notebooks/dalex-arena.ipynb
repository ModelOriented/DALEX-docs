{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "rubber-attribute",
   "metadata": {},
   "source": [
    "# Arena for Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "changing-train",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "capable-cornell",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.4.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dalex as dx\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "dx.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "still-update",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = dx.datasets.load_apartments()\n",
    "test = dx.datasets.load_apartments_test()\n",
    "\n",
    "X_train = train.drop(columns='m2_price')\n",
    "y_train = train[\"m2_price\"]\n",
    "\n",
    "X_test= test.drop(columns='m2_price')\n",
    "y_test = test[\"m2_price\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latter-stupid",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "hidden-cause",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "numerical_features = X_train.select_dtypes(exclude=[object]).columns\n",
    "numerical_transformer = Pipeline(\n",
    "    steps=[\n",
    "        ('scaler', StandardScaler())\n",
    "    ]\n",
    ")\n",
    "\n",
    "categorical_features = X_train.select_dtypes(include=[object]).columns\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "streaming-namibia",
   "metadata": {},
   "source": [
    "## Fit models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "particular-reader",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('num',\n",
       "                                                  Pipeline(steps=[('scaler',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  Index(['construction_year', 'surface', 'floor', 'no_rooms'], dtype='object')),\n",
       "                                                 ('cat',\n",
       "                                                  Pipeline(steps=[('onehot',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                  Index(['district'], dtype='object'))])),\n",
       "                ('model', DecisionTreeRegressor())])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "model_elastic_net = Pipeline(\n",
    "    steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', ElasticNet(alpha=0.2))\n",
    "    ]\n",
    ")\n",
    "model_elastic_net.fit(X=X_train, y=y_train)\n",
    "\n",
    "model_decision_tree = Pipeline(\n",
    "    steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', DecisionTreeRegressor())\n",
    "    ]\n",
    ")\n",
    "model_decision_tree.fit(X=X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "visible-sculpture",
   "metadata": {},
   "source": [
    "## Create dalex Explainer for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "secure-orientation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparation of a new explainer is initiated\n",
      "\n",
      "  -> data              : 9000 rows 5 cols\n",
      "  -> target variable   : Parameter 'y' was a pandas.Series. Converted to a numpy.ndarray.\n",
      "  -> target variable   : 9000 values\n",
      "  -> model_class       : sklearn.linear_model._coordinate_descent.ElasticNet (default)\n",
      "  -> label             : Not specified, model's class short name will be used. (default)\n",
      "  -> predict function  : <function yhat_default at 0x000001B510407EE0> will be used (default)\n",
      "  -> predict function  : Accepts only pandas.DataFrame, numpy.ndarray causes problems.\n",
      "  -> predicted values  : min = 2.08e+03, mean = 3.5e+03, max = 5.4e+03\n",
      "  -> model type        : regression will be used (default)\n",
      "  -> residual function : difference between y and yhat (default)\n",
      "  -> residuals         : min = -5.9e+02, mean = 6.8, max = 1.39e+03\n",
      "  -> model_info        : package sklearn\n",
      "\n",
      "A new explainer has been created!\n",
      "Preparation of a new explainer is initiated\n",
      "\n",
      "  -> data              : 9000 rows 5 cols\n",
      "  -> target variable   : Parameter 'y' was a pandas.Series. Converted to a numpy.ndarray.\n",
      "  -> target variable   : 9000 values\n",
      "  -> model_class       : sklearn.tree._classes.DecisionTreeRegressor (default)\n",
      "  -> label             : Not specified, model's class short name will be used. (default)\n",
      "  -> predict function  : <function yhat_default at 0x000001B510407EE0> will be used (default)\n",
      "  -> predict function  : Accepts only pandas.DataFrame, numpy.ndarray causes problems.\n",
      "  -> predicted values  : min = 1.62e+03, mean = 3.51e+03, max = 6.6e+03\n",
      "  -> model type        : regression will be used (default)\n",
      "  -> residual function : difference between y and yhat (default)\n",
      "  -> residuals         : min = -1.19e+03, mean = 5.9, max = 1.09e+03\n",
      "  -> model_info        : package sklearn\n",
      "\n",
      "A new explainer has been created!\n"
     ]
    }
   ],
   "source": [
    "exp_elastic_net = dx.Explainer(model_elastic_net, data=X_test, y=y_test)\n",
    "exp_decision_tree = dx.Explainer(model_decision_tree, data=X_test, y=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "considerable-alert",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mse</th>\n",
       "      <th>rmse</th>\n",
       "      <th>r2</th>\n",
       "      <th>mae</th>\n",
       "      <th>mad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ElasticNet</th>\n",
       "      <td>197572.651052</td>\n",
       "      <td>444.491452</td>\n",
       "      <td>0.756325</td>\n",
       "      <td>358.637412</td>\n",
       "      <td>393.033877</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "<dalex.model_explanations._model_performance.object.ModelPerformance at 0x1b520c9ceb0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_elastic_net.model_performance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "virtual-twist",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mse</th>\n",
       "      <th>rmse</th>\n",
       "      <th>r2</th>\n",
       "      <th>mae</th>\n",
       "      <th>mad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>53504.216</td>\n",
       "      <td>231.309784</td>\n",
       "      <td>0.934011</td>\n",
       "      <td>148.770222</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "<dalex.model_explanations._model_performance.object.ModelPerformance at 0x1b5210ba310>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_decision_tree.model_performance()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impaired-friendly",
   "metadata": {},
   "source": [
    "## Arena features\n",
    "\n",
    "### Live mode using all available observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "manual-campbell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://arena.drwhy.ai/?data=http://127.0.0.1:9294/\n"
     ]
    }
   ],
   "source": [
    "# create empty Arena\n",
    "arena = dx.Arena()\n",
    "# push created explainer\n",
    "arena.push_model(exp_elastic_net)\n",
    "# push whole test dataset (including target column)\n",
    "arena.push_observations(test)\n",
    "# run server on port 9294\n",
    "arena.run_server(port=9294)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metallic-consortium",
   "metadata": {},
   "source": [
    "The server is updating automatically. One can add the second model while it is running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "enhanced-arena",
   "metadata": {},
   "outputs": [],
   "source": [
    "arena.push_model(exp_decision_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prerequisite-stanford",
   "metadata": {},
   "source": [
    "And a third one!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "offshore-software",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparation of a new explainer is initiated\n",
      "\n",
      "  -> data              : 9000 rows 5 cols\n",
      "  -> target variable   : Parameter 'y' was a pandas.Series. Converted to a numpy.ndarray.\n",
      "  -> target variable   : 9000 values\n",
      "  -> model_class       : lightgbm.sklearn.LGBMRegressor (default)\n",
      "  -> label             : Not specified, model's class short name will be used. (default)\n",
      "  -> predict function  : <function yhat_default at 0x000001B510407EE0> will be used (default)\n",
      "  -> predict function  : Accepts only pandas.DataFrame, numpy.ndarray causes problems.\n",
      "  -> predicted values  : min = 1.63e+03, mean = 3.5e+03, max = 6.43e+03\n",
      "  -> model type        : regression will be used (default)\n",
      "  -> residual function : difference between y and yhat (default)\n",
      "  -> residuals         : min = -5.02e+02, mean = 8.94, max = 7.27e+02\n",
      "  -> model_info        : package sklearn\n",
      "\n",
      "A new explainer has been created!\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "model_gbm = Pipeline(\n",
    "    steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', LGBMRegressor())\n",
    "    ]\n",
    ")\n",
    "model_gbm.fit(X=X_train, y=y_train)\n",
    "exp_gbm = dx.Explainer(model_gbm, data=X_test, y=y_test)\n",
    "arena.push_model(exp_gbm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chemical-single",
   "metadata": {},
   "source": [
    "Stop the server using this method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "behind-prompt",
   "metadata": {},
   "outputs": [],
   "source": [
    "arena.stop_server()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cellular-determination",
   "metadata": {},
   "source": [
    "### Static mode using a subset of observations\n",
    "\n",
    "Create an Arena exacly the same way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cooked-adoption",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Shapley Values: 100%|██████████| 6/6 [02:03<00:00, 20.54s/it]\n",
      "Variable Importance: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]\n",
      "Partial Dependence: 100%|██████████| 10/10 [00:00<00:00, 10.41it/s]\n",
      "Accumulated Dependence: 100%|██████████| 10/10 [00:02<00:00,  4.66it/s]\n",
      "Ceteris Paribus: 100%|██████████| 30/30 [00:00<00:00, 50.68it/s]\n",
      "Break Down: 100%|██████████| 6/6 [00:01<00:00,  4.34it/s]\n",
      "Metrics: 100%|██████████| 2/2 [00:00<00:00, 333.37it/s]\n",
      "Shapley Values Dependence: 100%|██████████| 10/10 [01:19<00:00,  7.92s/it]\n",
      "Shapley Variable Importance: 100%|██████████| 2/2 [00:00<00:00, 22.99it/s]\n"
     ]
    }
   ],
   "source": [
    "# create empty Arena\n",
    "arena = dx.Arena()\n",
    "# this takes too long to compute\n",
    "arena.set_option('DatasetShapleyValues', 'N', 10) \n",
    "# push created explainers\n",
    "arena.push_model(exp_gbm)\n",
    "arena.push_model(exp_decision_tree)\n",
    "# push first 3 rows of tasting dataset\n",
    "arena.push_observations(test.iloc[0:3])\n",
    "# save arena to file\n",
    "arena.save(\"data.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "offensive-legislation",
   "metadata": {},
   "source": [
    "You can automatically upload this data source to the GitHub Gist service. By default, OAuth is used, but you can provide a Personal Access Token using the token argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "twelve-stuff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Shapley Values: 100%|██████████| 6/6 [00:00<?, ?it/s]\n",
      "Variable Importance: 100%|██████████| 2/2 [00:00<00:00, 999.24it/s]\n",
      "Partial Dependence: 100%|██████████| 10/10 [00:00<00:00, 9993.58it/s]\n",
      "Accumulated Dependence: 100%|██████████| 10/10 [00:00<00:00, 10000.72it/s]\n",
      "Ceteris Paribus: 100%|██████████| 30/30 [00:00<00:00, 30073.88it/s]\n",
      "Break Down: 100%|██████████| 6/6 [00:00<00:00, 6013.34it/s]\n",
      "Metrics: 100%|██████████| 2/2 [00:00<?, ?it/s]\n",
      "Shapley Values Dependence: 100%|██████████| 10/10 [00:00<00:00, 9953.26it/s]\n",
      "Shapley Variable Importance: 100%|██████████| 2/2 [00:00<00:00, 2004.45it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://arena.drwhy.ai/?data=https://gist.githubusercontent.com/hbaniecki/ceb167ab41142b29c09b5a5b399c12a8/raw/57b2cad7e82fda8abdd7edcbe8afa3ace858e3d9/datasource.json'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arena.upload(open_browser=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gothic-archive",
   "metadata": {},
   "source": [
    "### Chart options\n",
    "\n",
    "Options are described for each plot in the official Arena's Guide:\n",
    "- https://arena.drwhy.ai/docs/guide/observation-level\n",
    "- https://arena.drwhy.ai/docs/guide/dataset-level\n",
    "- https://arena.drwhy.ai/docs/guide/fairness\n",
    "- https://arena.drwhy.ai/docs/guide/model-performance\n",
    "- https://arena.drwhy.ai/docs/guide/eda-charts\n",
    "\n",
    "Short description are available using the `print_options` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "invisible-stack",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://arena.drwhy.ai/?data=http://127.0.0.1:9294/\n",
      "\n",
      "\u001b[1mShapleyValues\u001b[0m\n",
      "---------------------------------\n",
      "B: 20   #Number of random paths\n",
      "cpus: 4   #Number of parallel processes\n",
      "\n",
      "\u001b[1mVariableImportance\u001b[0m\n",
      "---------------------------------\n",
      "N: None   #Number of observations to use. None for all.\n",
      "B: 10   #Number of permutation rounds to perform each variable\n",
      "\n",
      "\u001b[1mPartialDependence\u001b[0m\n",
      "---------------------------------\n",
      "grid_type: quantile   #grid type \"quantile\" or \"uniform\"\n",
      "grid_points: 101   #Maximum number of points for profile\n",
      "N: 500   #Number of observations to use. None for all.\n",
      "\n",
      "\u001b[1mAccumulatedDependence\u001b[0m\n",
      "---------------------------------\n",
      "grid_type: quantile   #grid type \"quantile\" or \"uniform\"\n",
      "grid_points: 101   #Maximum number of points for profile\n",
      "N: 500   #Number of observations to use. None for all.\n",
      "\n",
      "\u001b[1mCeterisParibus\u001b[0m\n",
      "---------------------------------\n",
      "grid_points: 101   #Maximum number of points for profile\n",
      "grid_type: quantile   #grid type \"quantile\" or \"uniform\"\n",
      "\n",
      "\u001b[1mROC\u001b[0m\n",
      "---------------------------------\n",
      "grid_points: 101   #Maximum number of points for ROC curve\n",
      "\n",
      "\u001b[1mFairness\u001b[0m\n",
      "---------------------------------\n",
      "cutoffs: [0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95]   #List of tested cutoff levels\n",
      "\n",
      "\u001b[1mDatasetShapleyValues\u001b[0m\n",
      "---------------------------------\n",
      "B: 4   #Number of random paths\n",
      "N: 500   #Number of randomly sampled rows from dataset\n",
      "cpus: 4   #Number of parallel processes\n"
     ]
    }
   ],
   "source": [
    "arena=dx.Arena()\n",
    "arena.push_model(exp_decision_tree)\n",
    "arena.push_observations(test)\n",
    "arena.run_server(port=9294)\n",
    "\n",
    "arena.print_options()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collaborative-jesus",
   "metadata": {},
   "source": [
    "You can easily change options for charts and the dashboard will be automatically refreshed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "matched-marble",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chart-specific\n",
    "arena.set_option('CeterisParibus', 'grid_type', 'uniform')\n",
    "# For all charts\n",
    "arena.set_option(None, 'grid_points', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "stylish-suicide",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1mShapleyValues\u001b[0m\n",
      "---------------------------------\n",
      "B: 20   #Number of random paths\n",
      "cpus: 4   #Number of parallel processes\n",
      "\n",
      "\u001b[1mVariableImportance\u001b[0m\n",
      "---------------------------------\n",
      "N: None   #Number of observations to use. None for all.\n",
      "B: 10   #Number of permutation rounds to perform each variable\n",
      "\n",
      "\u001b[1mPartialDependence\u001b[0m\n",
      "---------------------------------\n",
      "grid_type: quantile   #grid type \"quantile\" or \"uniform\"\n",
      "grid_points: 200   #Maximum number of points for profile\n",
      "N: 500   #Number of observations to use. None for all.\n",
      "\n",
      "\u001b[1mAccumulatedDependence\u001b[0m\n",
      "---------------------------------\n",
      "grid_type: quantile   #grid type \"quantile\" or \"uniform\"\n",
      "grid_points: 200   #Maximum number of points for profile\n",
      "N: 500   #Number of observations to use. None for all.\n",
      "\n",
      "\u001b[1mCeterisParibus\u001b[0m\n",
      "---------------------------------\n",
      "grid_points: 200   #Maximum number of points for profile\n",
      "grid_type: uniform   #grid type \"quantile\" or \"uniform\"\n",
      "\n",
      "\u001b[1mROC\u001b[0m\n",
      "---------------------------------\n",
      "grid_points: 200   #Maximum number of points for ROC curve\n",
      "\n",
      "\u001b[1mFairness\u001b[0m\n",
      "---------------------------------\n",
      "cutoffs: [0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95]   #List of tested cutoff levels\n",
      "\n",
      "\u001b[1mDatasetShapleyValues\u001b[0m\n",
      "---------------------------------\n",
      "B: 4   #Number of random paths\n",
      "N: 500   #Number of randomly sampled rows from dataset\n",
      "cpus: 4   #Number of parallel processes\n"
     ]
    }
   ],
   "source": [
    "arena.print_options()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complicated-permit",
   "metadata": {},
   "source": [
    "# Plots\n",
    "\n",
    "This package uses [plotly](https://plotly.com/python/) to render the plots:\n",
    "\n",
    "* Install extentions to use `plotly` in **JupyterLab**:&emsp;[Getting Started](https://plot.ly/python/getting-started/#jupyterlab-support-python-35)&emsp;[Troubleshooting](https://plot.ly/python/troubleshooting/#jupyterlab-problems)\n",
    "* Use `show=False` parameter in `plot` method to return `plotly Figure` object\n",
    "* It is possible to [edit the figures](https://plotly.com/python/#fundamentals) and [save them](https://plotly.com/python/static-image-export/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "foster-indian",
   "metadata": {},
   "source": [
    "# Resources - https://dalex.drwhy.ai/python\n",
    "\n",
    "* Introduction to the `dalex` package: [Titanic: tutorial and examples](http://dalex.drwhy.ai/python-dalex-titanic.html)\n",
    "* Key features explained: [FIFA20: explain default vs tuned model with dalex](http://dalex.drwhy.ai/python-dalex-fifa.html)\n",
    "* How to use dalex with: [xgboost](http://dalex.drwhy.ai/python-dalex-xgboost.html), [tensorflow](http://dalex.drwhy.ai/python-dalex-tensorflow.html), [h2o (feat. autokeras, catboost, lightgbm)](http://dalex.drwhy.ai/python-dalex-h2o.html)\n",
    "* More explanations: [residuals, shap, lime](http://dalex.drwhy.ai/python-dalex-new.html)\n",
    "* Introduction to the [Fairness module in dalex](http://dalex.drwhy.ai/python-dalex-fairness.html)\n",
    "* Introduction to the [Aspect module in dalex](http://dalex.drwhy.ai/python-dalex-aspect.html)\n",
    "* Introduction to [Arena: interactive dashboard for model exploration](http://dalex.drwhy.ai/python-dalex-arena.html)\n",
    "\n",
    "\n",
    "* Code in the form of [jupyter notebook](https://github.com/ModelOriented/DALEX-docs/tree/master/jupyter-notebooks)\n",
    "* Changelog: [NEWS](https://github.com/ModelOriented/DALEX/blob/master/python/dalex/NEWS.md)\n",
    "* Theoretical introduction to the plots: [Explanatory Model Analysis: Explore, Explain, and Examine Predictive Models](https://pbiecek.github.io/ema)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6ab6057dad60620dec75a45f968cfcb183b6d526d8d16dda8af77d690bdae944"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
