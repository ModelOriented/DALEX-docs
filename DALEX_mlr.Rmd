---
title: "How to use DALEX with mlr"
author: 
  - Aleksandra Grudziąż, Anna Kozak
date: First created on April 28, 2018. Updated on Nov 07, 2020.
output: 
  html_document:
    toc: true  
    toc_float: true
    number_sections: true
    theme: flatly
    highlight: kate
    fig_caption: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```

# Introduction

DALEX is designed to work with various black-box models like tree ensembles, linear models, neural networks etc. Unfortunately R packages that create such models are very inconsistent. Different tools use different interfaces to train, validate and use models. 

In this vignette we will show explanations for models from [mlr](https://mlr-org.github.io/mlr/reference/index.html) (Bischl et al. 2016).


# Regression use case - apartments data

```{r}
library(DALEX)
library(DALEXtra)
library(mlr)
library(breakDown)

```

To illustrate applications of *DALEX* to regression problems we will use an artificial dataset `apartments` available in the *DALEX* package. Our goal is to predict the price per square meter of an apartment based on selected features such as construction year, surface, floor, number of rooms, district. It should be noted that four of these variables are continuous while the fifth one is a categorical one. Prices are given in Euro.

```{r}
data(apartments)
head(apartments)
```

## The explain() function

The first step of using the *DALEX* package is to wrap-up the black-box model with meta-data that unifies model interfacing. To work with mlr models we use the *DALEXtra* package, ectension to *DALEX* package.

In this vignette we will use 3 models: random forest, gradient boosting machine model, and neutral network for regression.

According to the semantics of the *mlr* package at the beginning we have to make our regression task using function `makeRegrTask()` and build learners for our models using the `makeLearner()` function. 
```{r, results="hide"}
set.seed(123)
regr_task <- makeRegrTask(id = "ap", data = apartments, target = "m2.price")
regr_lrn_rf <- makeLearner("regr.randomForest")
regr_lrn_nn <- makeLearner("regr.nnet")
regr_lrn_gbm <- makeLearner("regr.gbm", par.vals = list(n.trees = 500))

```

Additionally, for the neural network model we set additional parameters and do the data preprocessing. 
```{r, results="hide"}
regr_lrn_nn <- setHyperPars(regr_lrn_nn, par.vals = list(maxit=500, size=2))
regr_lrn_nn <- makePreprocWrapperCaret(regr_lrn_nn, ppc.scale=TRUE, ppc.center=TRUE)
```

Below, we use the *mlr* function `train()` to fit our models.
```{r, results="hide"}
regr_rf <- train(regr_lrn_rf, regr_task)
regr_nn <- train(regr_lrn_nn, regr_task)
regr_gbm <- train(regr_lrn_gbm, regr_task)
```


To create an explainer for these models it is enough to use `explain_mlr()` function with the *model*, *data* and *y* parameters. 
Validation dataset for the models is `apartmentsTest` data from the *DALEX* package. 
For the models created by *mlr* package we have to provide custom predict function which takes two arguments: *model* and *newdata* and returns a numeric vector with predictions because function `predict()` from *mlr* returns not only predictions but an object with more information.
```{r}
data(apartmentsTest)
explainer_regr_rf <- DALEXtra::explain_mlr(regr_rf, data=apartmentsTest, y=apartmentsTest$m2.price, 
                                           label="rf", verbose = FALSE)
explainer_regr_nn <- DALEXtra::explain_mlr(regr_nn, data=apartmentsTest, y=apartmentsTest$m2.price,
                                           label="nn", verobose = FALSE)
explainer_regr_gbm <- DALEXtra::explain_mlr(regr_gbm, data=apartmentsTest, y=apartmentsTest$m2.price,
                                            label="gbm", verbose = FALSE)

```


## Model performance

Function `model_performance()` calculates predictions and residuals for validation dataset.

```{r}
mp_regr_rf <- model_performance(explainer_regr_rf)
mp_regr_gbm <- model_performance(explainer_regr_gbm)
mp_regr_nn <- model_performance(explainer_regr_nn)
```

Generic function `print()` returns quantiles for residuals.

```{r}
mp_regr_rf
```

Generic function `plot()` shows reversed empirical cumulative distribution function for absolute values from residuals. Plots can be generated for one or more models.

```{r}
plot(mp_regr_rf, mp_regr_nn, mp_regr_gbm)
```

The figure above shows that majority of residuals for random forest are smaller than residuals for the neural network and gbm.

We are also able to use the `plot()` function to get an alternative comparison of residuals. 
Setting the `geom = "boxplot"` parameter we can compare the distribution of residuals for selected models.

```{r}
plot(mp_regr_rf, mp_regr_nn, mp_regr_gbm, geom = "boxplot")
```


## Variable importance

Using he DALEX package we are able to better understand which variables are important.

Model agnostic variable importance is calculated by means of permutations. We simply substract the loss function calculated for validation dataset with permuted values for a single variable from the loss function calculated for validation dataset. 

This method is implemented in the `model_parts()` function.

```{r}
vi_regr_rf <- model_parts(explainer_regr_rf, loss_function = loss_root_mean_square)
vi_regr_gbm <- model_parts(explainer_regr_gbm, loss_function = loss_root_mean_square)
vi_regr_nn <- model_parts(explainer_regr_nn, loss_function = loss_root_mean_square)

```

We can compare all models using the generic `plot()` function.

```{r}
plot(vi_regr_rf, vi_regr_gbm, vi_regr_nn)
```

Length of the interval coresponds to a variable importance. Longer interval means larger loss, so the variable is more important.

For better comparison of the models we can hook the variabe importance at 0 using the `type=difference`.

```{r}
vi_regr_rf <- model_parts(explainer_regr_rf, loss_function = loss_root_mean_square, type = "difference")
vi_regr_gbm <- model_parts(explainer_regr_gbm, loss_function = loss_root_mean_square, type = "difference")
vi_regr_nn <- model_parts(explainer_regr_nn, loss_function = loss_root_mean_square, type = "difference")

plot(vi_regr_rf, vi_regr_gbm, vi_regr_nn)

```

We see that in random forest and gbm model the most important variable is `district`.

## Model profile

Explainers presented in this section are designed to better understand the relation between a variable and model output.

For more details of methods desribed in this section see:
- [Partial-dependence Profiles](https://pbiecek.github.io/ema/partialDependenceProfiles.html)
- [Local-dependence and Accumulated-local Profiles](https://pbiecek.github.io/ema/accumulatedLocalProfiles.html)


### Partial Dependence Plot

Partial Dependence Plots (PDP) are one of the most popular methods for exploration of the relation between a continuous variable and the model outcome.

Function `model_profile()` with the parameter `type = "partial"` to calculate PDP response.

```{r}
pdp_regr_rf  <- model_profile(explainer_regr_rf, variable =  "construction.year", type = "partial")
pdp_regr_gbm  <- model_profile(explainer_regr_gbm, variable =  "construction.year", type = "partial")
pdp_regr_nn  <- model_profile(explainer_regr_nn, variable =  "construction.year", type = "partial")

plot(pdp_regr_rf, pdp_regr_gbm, pdp_regr_nn)
```

We use PDP plots to compare our 3 models. As we can see above performance of random forest may tell us that we have non-linear relation in the data. It looks like the neural network and gbm don't captured that relation.

### Acumulated Local Effects plot

Acumulated Local Effects (ALE) plot is the extension of PDP, that is more suited for highly correlated variables.

Function `model_profile()` with the parameter `type = "accumulated"` to calculate the ALE curve for the variable `construction.year`.

```{r}
ale_regr_rf  <- model_profile(explainer_regr_rf, variable =  "construction.year", type = "accumulated")
ale_regr_gbm  <- model_profile(explainer_regr_gbm, variable =  "construction.year", type = "accumulated")
ale_regr_nn  <- model_profile(explainer_regr_nn, variable =  "construction.year", type = "accumulated")

plot(ale_regr_rf, ale_regr_gbm, ale_regr_nn)
```




### Partial Dependence Profile for categorical variable

Function `model_profile()` with the parameter `type = "partial"` for categorical variable.

```{r, fig.height = 10, fig.width= 7}
mpp_regr_rf  <- model_profile(explainer_regr_rf, variable =  "district", type = "partial")
mpp_regr_gbm  <- model_profile(explainer_regr_gbm, variable =  "district", type = "partial")
mpp_regr_nn  <- model_profile(explainer_regr_nn, variable =  "district", type = "partial")

plot(mpp_regr_rf, mpp_regr_gbm, mpp_regr_nn)
```

We can note some kind of three clusters: the city center (Srodmiescie), districts well communicated with city center (Ochota, Mokotow, Zoliborz - for the random forest and gbm) and other districts closer to city boundaries.

# Classification use case - wine data

To illustrate applications of *DALEX* to classification problems we will use a wine dataset available in the *breakDown* package. We want to classify the quality of wine. Originally this variable has 7 levels but in our example, it will be reduced to the binary classification. Our classification will be based on eleven features from this data set.

White wine quality data is related to variants of the Portuguese "Vinho Verde" wine. For more details, consult: http://www.vinhoverde.pt/en/.

```{r}
data(wine)
wine$quality <- ifelse(wine$quality>5, 1, 0)
```

First, we create a train and test indexes which ones are needed to train the *mlr* models when we don't have an additional test set - `wineTest`.
```{r}
wine$quality <- factor(wine$quality)
train_index <- sample(1:nrow(wine), 0.6 * nrow(wine))
test_index <- setdiff(1:nrow(wine), train_index)

wineTest <- wine[test_index,]

```

In this vignette we will use 3 models: random forest, logistic regression and support vector machines for classification.

According to the semantics of the *mlr* package at the beginning we have to make our classification task using function `makeClassifTask()` and build learners for our models using the `makeLearner()` function with the parameter `predict.type=prob`.

```{r, results = 'hide'}
classif_task <- makeClassifTask(id = "ap", data = wine, target = "quality")
classif_lrn_rf <- makeLearner("classif.randomForest", predict.type = "prob")
classif_lrn_glm <- makeLearner("classif.binomial", predict.type = "prob")
classif_lrn_svm <- makeLearner("classif.ksvm", predict.type = "prob")
```


Next, we use `train()` to fit 3 our models.

```{r classif_models, results = 'hide'}
classif_rf <- train(classif_lrn_rf, classif_task, subset=train_index)
classif_glm <- train(classif_lrn_glm, classif_task, subset=train_index)
classif_svm <- train(classif_lrn_svm, classif_task, subset=train_index)
```

As previously, to create an explainer for these models we use `explain()` function.
Validation dataset for the models is `wineTest`.

In this case we consider the differences between observed class and predicted probabilities to be residuals. So, we have to provide custom predict function which takes two arguments: *model* and *newdata* and returns a numeric vector with probabilities.

```{r}

y_test <- as.numeric(as.character(wineTest$quality))

explainer_classif_rf <- DALEXtra::explain_mlr(classif_rf, data = wineTest, y = y_test, 
                                              label= "rf", verbose = FALSE)
explainer_classif_glm <- DALEXtra::explain_mlr(classif_glm, data = wineTest, y = y_test,
                                               label = "glm", verbose = FALSE)
explainer_classif_svm <- DALEXtra::explain_mlr(classif_svm, data = wineTest, y = y_test,
                                               label = "svm", verbose = FALSE)

```

## Model performance

Function `model_performance()` calculates predictions and residuals for validation dataset `wineTest`.

We use the generic `plot()` function to get a comparison of models.

```{r}
mp_classif_rf <- model_performance(explainer_classif_rf)
mp_classif_glm <- model_performance(explainer_classif_glm)
mp_classif_svm <- model_performance(explainer_classif_svm)

plot(mp_classif_rf, mp_classif_glm, mp_classif_svm)
```



Setting the `geom = "boxplot"` parameter we can compare the distribution of residuals for selected models.

```{r}
plot(mp_classif_rf, mp_classif_glm, mp_classif_svm, geom = "boxplot")
```


## Variable importance

Function `variable_importance()` computes variable importances which may be plotted.

```{r}
vi_classif_rf <- model_parts(explainer_classif_rf, loss_function = loss_root_mean_square)
vi_classif_glm <- model_parts(explainer_classif_glm, loss_function = loss_root_mean_square)
vi_classif_svm <- model_parts(explainer_classif_svm, loss_function = loss_root_mean_square)

plot(vi_classif_rf, vi_classif_glm, vi_classif_svm)
```

Left edges of intervals start in full model. Length of the interval coresponds to a variable importance. Longer interval means larger loss, so the variable is more important.


## Model profile

As previously we create explainers which are designed to better understand the relation between a variable and model output: PDP plots and ALE plots.

For more details of methods desribed in this section see:
- [Partial-dependence Profiles](https://pbiecek.github.io/ema/partialDependenceProfiles.html)
- [Local-dependence and Accumulated-local Profiles](https://pbiecek.github.io/ema/accumulatedLocalProfiles.html)

### Partial Depedence Plot

```{r}
pdp_classif_rf  <- model_profile(explainer_classif_rf, variable = "pH", type = "partial")
pdp_classif_glm  <- model_profile(explainer_classif_glm, variable = "pH", type = "partial")
pdp_classif_svm  <- model_profile(explainer_classif_svm, variable = "pH", type = "partial")

plot(pdp_classif_rf, pdp_classif_glm, pdp_classif_svm)
```

### Acumulated Local Effects plot

```{r}
ale_classif_rf  <- model_profile(explainer_classif_rf, variable = "alcohol", type = "accumulated")
ale_classif_glm  <- model_profile(explainer_classif_glm, variable = "alcohol", type = "accumulated")
ale_classif_svm  <- model_profile(explainer_classif_svm, variable = "alcohol", type = "accumulated")

plot(ale_classif_rf, ale_classif_glm, ale_classif_svm)
```

# Session info

```{r}
sessionInfo()
```
